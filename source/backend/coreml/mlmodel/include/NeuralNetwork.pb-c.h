/* Generated by the protocol buffer compiler.  DO NOT EDIT! */
/* Generated from: NeuralNetwork.proto */

#ifndef PROTOBUF_C_NeuralNetwork_2eproto__INCLUDED
#define PROTOBUF_C_NeuralNetwork_2eproto__INCLUDED

#include <protobuf-c/protobuf-c.h>

PROTOBUF_C__BEGIN_DECLS

#if PROTOBUF_C_VERSION_NUMBER < 1003000
# error This file was generated by a newer version of protoc-c which is incompatible with your libprotobuf-c headers. Please update your headers.
#elif 1003003 < PROTOBUF_C_MIN_COMPILER_VERSION
# error This file was generated by an older version of protoc-c which is incompatible with your libprotobuf-c headers. Please regenerate this file with a newer version of protoc-c.
#endif

#include "DataStructures.pb-c.h"
#include "Parameters.pb-c.h"

typedef struct _CoreML__Specification__NeuralNetwork CoreML__Specification__NeuralNetwork;
typedef struct _CoreML__Specification__NeuralNetworkImageScaler CoreML__Specification__NeuralNetworkImageScaler;
typedef struct _CoreML__Specification__NeuralNetworkMeanImage CoreML__Specification__NeuralNetworkMeanImage;
typedef struct _CoreML__Specification__NeuralNetworkPreprocessing CoreML__Specification__NeuralNetworkPreprocessing;
typedef struct _CoreML__Specification__ActivationReLU CoreML__Specification__ActivationReLU;
typedef struct _CoreML__Specification__ActivationLeakyReLU CoreML__Specification__ActivationLeakyReLU;
typedef struct _CoreML__Specification__ActivationTanh CoreML__Specification__ActivationTanh;
typedef struct _CoreML__Specification__ActivationScaledTanh CoreML__Specification__ActivationScaledTanh;
typedef struct _CoreML__Specification__ActivationSigmoid CoreML__Specification__ActivationSigmoid;
typedef struct _CoreML__Specification__ActivationLinear CoreML__Specification__ActivationLinear;
typedef struct _CoreML__Specification__ActivationSigmoidHard CoreML__Specification__ActivationSigmoidHard;
typedef struct _CoreML__Specification__ActivationPReLU CoreML__Specification__ActivationPReLU;
typedef struct _CoreML__Specification__ActivationELU CoreML__Specification__ActivationELU;
typedef struct _CoreML__Specification__ActivationThresholdedReLU CoreML__Specification__ActivationThresholdedReLU;
typedef struct _CoreML__Specification__ActivationSoftsign CoreML__Specification__ActivationSoftsign;
typedef struct _CoreML__Specification__ActivationSoftplus CoreML__Specification__ActivationSoftplus;
typedef struct _CoreML__Specification__ActivationParametricSoftplus CoreML__Specification__ActivationParametricSoftplus;
typedef struct _CoreML__Specification__ActivationParams CoreML__Specification__ActivationParams;
typedef struct _CoreML__Specification__Tensor CoreML__Specification__Tensor;
typedef struct _CoreML__Specification__NeuralNetworkLayer CoreML__Specification__NeuralNetworkLayer;
typedef struct _CoreML__Specification__BranchLayerParams CoreML__Specification__BranchLayerParams;
typedef struct _CoreML__Specification__LoopLayerParams CoreML__Specification__LoopLayerParams;
typedef struct _CoreML__Specification__LoopBreakLayerParams CoreML__Specification__LoopBreakLayerParams;
typedef struct _CoreML__Specification__LoopContinueLayerParams CoreML__Specification__LoopContinueLayerParams;
typedef struct _CoreML__Specification__CopyLayerParams CoreML__Specification__CopyLayerParams;
typedef struct _CoreML__Specification__GreaterThanLayerParams CoreML__Specification__GreaterThanLayerParams;
typedef struct _CoreML__Specification__GreaterEqualLayerParams CoreML__Specification__GreaterEqualLayerParams;
typedef struct _CoreML__Specification__LessThanLayerParams CoreML__Specification__LessThanLayerParams;
typedef struct _CoreML__Specification__LessEqualLayerParams CoreML__Specification__LessEqualLayerParams;
typedef struct _CoreML__Specification__EqualLayerParams CoreML__Specification__EqualLayerParams;
typedef struct _CoreML__Specification__NotEqualLayerParams CoreML__Specification__NotEqualLayerParams;
typedef struct _CoreML__Specification__LogicalAndLayerParams CoreML__Specification__LogicalAndLayerParams;
typedef struct _CoreML__Specification__LogicalOrLayerParams CoreML__Specification__LogicalOrLayerParams;
typedef struct _CoreML__Specification__LogicalXorLayerParams CoreML__Specification__LogicalXorLayerParams;
typedef struct _CoreML__Specification__LogicalNotLayerParams CoreML__Specification__LogicalNotLayerParams;
typedef struct _CoreML__Specification__BorderAmounts CoreML__Specification__BorderAmounts;
typedef struct _CoreML__Specification__BorderAmounts__EdgeSizes CoreML__Specification__BorderAmounts__EdgeSizes;
typedef struct _CoreML__Specification__ValidPadding CoreML__Specification__ValidPadding;
typedef struct _CoreML__Specification__SamePadding CoreML__Specification__SamePadding;
typedef struct _CoreML__Specification__SamplingMode CoreML__Specification__SamplingMode;
typedef struct _CoreML__Specification__BoxCoordinatesMode CoreML__Specification__BoxCoordinatesMode;
typedef struct _CoreML__Specification__WeightParams CoreML__Specification__WeightParams;
typedef struct _CoreML__Specification__QuantizationParams CoreML__Specification__QuantizationParams;
typedef struct _CoreML__Specification__LinearQuantizationParams CoreML__Specification__LinearQuantizationParams;
typedef struct _CoreML__Specification__LookUpTableQuantizationParams CoreML__Specification__LookUpTableQuantizationParams;
typedef struct _CoreML__Specification__ConvolutionLayerParams CoreML__Specification__ConvolutionLayerParams;
typedef struct _CoreML__Specification__Convolution3DLayerParams CoreML__Specification__Convolution3DLayerParams;
typedef struct _CoreML__Specification__InnerProductLayerParams CoreML__Specification__InnerProductLayerParams;
typedef struct _CoreML__Specification__EmbeddingLayerParams CoreML__Specification__EmbeddingLayerParams;
typedef struct _CoreML__Specification__EmbeddingNDLayerParams CoreML__Specification__EmbeddingNDLayerParams;
typedef struct _CoreML__Specification__BatchnormLayerParams CoreML__Specification__BatchnormLayerParams;
typedef struct _CoreML__Specification__PoolingLayerParams CoreML__Specification__PoolingLayerParams;
typedef struct _CoreML__Specification__PoolingLayerParams__ValidCompletePadding CoreML__Specification__PoolingLayerParams__ValidCompletePadding;
typedef struct _CoreML__Specification__Pooling3DLayerParams CoreML__Specification__Pooling3DLayerParams;
typedef struct _CoreML__Specification__GlobalPooling3DLayerParams CoreML__Specification__GlobalPooling3DLayerParams;
typedef struct _CoreML__Specification__PaddingLayerParams CoreML__Specification__PaddingLayerParams;
typedef struct _CoreML__Specification__PaddingLayerParams__PaddingConstant CoreML__Specification__PaddingLayerParams__PaddingConstant;
typedef struct _CoreML__Specification__PaddingLayerParams__PaddingReflection CoreML__Specification__PaddingLayerParams__PaddingReflection;
typedef struct _CoreML__Specification__PaddingLayerParams__PaddingReplication CoreML__Specification__PaddingLayerParams__PaddingReplication;
typedef struct _CoreML__Specification__ConcatLayerParams CoreML__Specification__ConcatLayerParams;
typedef struct _CoreML__Specification__LRNLayerParams CoreML__Specification__LRNLayerParams;
typedef struct _CoreML__Specification__SoftmaxLayerParams CoreML__Specification__SoftmaxLayerParams;
typedef struct _CoreML__Specification__SplitLayerParams CoreML__Specification__SplitLayerParams;
typedef struct _CoreML__Specification__AddLayerParams CoreML__Specification__AddLayerParams;
typedef struct _CoreML__Specification__MultiplyLayerParams CoreML__Specification__MultiplyLayerParams;
typedef struct _CoreML__Specification__UnaryFunctionLayerParams CoreML__Specification__UnaryFunctionLayerParams;
typedef struct _CoreML__Specification__UpsampleLayerParams CoreML__Specification__UpsampleLayerParams;
typedef struct _CoreML__Specification__ResizeBilinearLayerParams CoreML__Specification__ResizeBilinearLayerParams;
typedef struct _CoreML__Specification__CropResizeLayerParams CoreML__Specification__CropResizeLayerParams;
typedef struct _CoreML__Specification__BiasLayerParams CoreML__Specification__BiasLayerParams;
typedef struct _CoreML__Specification__ScaleLayerParams CoreML__Specification__ScaleLayerParams;
typedef struct _CoreML__Specification__LoadConstantLayerParams CoreML__Specification__LoadConstantLayerParams;
typedef struct _CoreML__Specification__L2NormalizeLayerParams CoreML__Specification__L2NormalizeLayerParams;
typedef struct _CoreML__Specification__FlattenLayerParams CoreML__Specification__FlattenLayerParams;
typedef struct _CoreML__Specification__ReshapeLayerParams CoreML__Specification__ReshapeLayerParams;
typedef struct _CoreML__Specification__PermuteLayerParams CoreML__Specification__PermuteLayerParams;
typedef struct _CoreML__Specification__ReorganizeDataLayerParams CoreML__Specification__ReorganizeDataLayerParams;
typedef struct _CoreML__Specification__SliceLayerParams CoreML__Specification__SliceLayerParams;
typedef struct _CoreML__Specification__ReduceLayerParams CoreML__Specification__ReduceLayerParams;
typedef struct _CoreML__Specification__CropLayerParams CoreML__Specification__CropLayerParams;
typedef struct _CoreML__Specification__AverageLayerParams CoreML__Specification__AverageLayerParams;
typedef struct _CoreML__Specification__MaxLayerParams CoreML__Specification__MaxLayerParams;
typedef struct _CoreML__Specification__MinLayerParams CoreML__Specification__MinLayerParams;
typedef struct _CoreML__Specification__DotProductLayerParams CoreML__Specification__DotProductLayerParams;
typedef struct _CoreML__Specification__MeanVarianceNormalizeLayerParams CoreML__Specification__MeanVarianceNormalizeLayerParams;
typedef struct _CoreML__Specification__SequenceRepeatLayerParams CoreML__Specification__SequenceRepeatLayerParams;
typedef struct _CoreML__Specification__SimpleRecurrentLayerParams CoreML__Specification__SimpleRecurrentLayerParams;
typedef struct _CoreML__Specification__GRULayerParams CoreML__Specification__GRULayerParams;
typedef struct _CoreML__Specification__LSTMParams CoreML__Specification__LSTMParams;
typedef struct _CoreML__Specification__LSTMWeightParams CoreML__Specification__LSTMWeightParams;
typedef struct _CoreML__Specification__UniDirectionalLSTMLayerParams CoreML__Specification__UniDirectionalLSTMLayerParams;
typedef struct _CoreML__Specification__BiDirectionalLSTMLayerParams CoreML__Specification__BiDirectionalLSTMLayerParams;
typedef struct _CoreML__Specification__CustomLayerParams CoreML__Specification__CustomLayerParams;
typedef struct _CoreML__Specification__CustomLayerParams__CustomLayerParamValue CoreML__Specification__CustomLayerParams__CustomLayerParamValue;
typedef struct _CoreML__Specification__CustomLayerParams__ParametersEntry CoreML__Specification__CustomLayerParams__ParametersEntry;
typedef struct _CoreML__Specification__TransposeLayerParams CoreML__Specification__TransposeLayerParams;
typedef struct _CoreML__Specification__BatchedMatMulLayerParams CoreML__Specification__BatchedMatMulLayerParams;
typedef struct _CoreML__Specification__ConcatNDLayerParams CoreML__Specification__ConcatNDLayerParams;
typedef struct _CoreML__Specification__SoftmaxNDLayerParams CoreML__Specification__SoftmaxNDLayerParams;
typedef struct _CoreML__Specification__ReverseLayerParams CoreML__Specification__ReverseLayerParams;
typedef struct _CoreML__Specification__ReverseSeqLayerParams CoreML__Specification__ReverseSeqLayerParams;
typedef struct _CoreML__Specification__LoadConstantNDLayerParams CoreML__Specification__LoadConstantNDLayerParams;
typedef struct _CoreML__Specification__FillLikeLayerParams CoreML__Specification__FillLikeLayerParams;
typedef struct _CoreML__Specification__FillStaticLayerParams CoreML__Specification__FillStaticLayerParams;
typedef struct _CoreML__Specification__FillDynamicLayerParams CoreML__Specification__FillDynamicLayerParams;
typedef struct _CoreML__Specification__WhereBroadcastableLayerParams CoreML__Specification__WhereBroadcastableLayerParams;
typedef struct _CoreML__Specification__SinLayerParams CoreML__Specification__SinLayerParams;
typedef struct _CoreML__Specification__CosLayerParams CoreML__Specification__CosLayerParams;
typedef struct _CoreML__Specification__TanLayerParams CoreML__Specification__TanLayerParams;
typedef struct _CoreML__Specification__AsinLayerParams CoreML__Specification__AsinLayerParams;
typedef struct _CoreML__Specification__AcosLayerParams CoreML__Specification__AcosLayerParams;
typedef struct _CoreML__Specification__AtanLayerParams CoreML__Specification__AtanLayerParams;
typedef struct _CoreML__Specification__SinhLayerParams CoreML__Specification__SinhLayerParams;
typedef struct _CoreML__Specification__CoshLayerParams CoreML__Specification__CoshLayerParams;
typedef struct _CoreML__Specification__TanhLayerParams CoreML__Specification__TanhLayerParams;
typedef struct _CoreML__Specification__AsinhLayerParams CoreML__Specification__AsinhLayerParams;
typedef struct _CoreML__Specification__AcoshLayerParams CoreML__Specification__AcoshLayerParams;
typedef struct _CoreML__Specification__AtanhLayerParams CoreML__Specification__AtanhLayerParams;
typedef struct _CoreML__Specification__PowBroadcastableLayerParams CoreML__Specification__PowBroadcastableLayerParams;
typedef struct _CoreML__Specification__Exp2LayerParams CoreML__Specification__Exp2LayerParams;
typedef struct _CoreML__Specification__WhereNonZeroLayerParams CoreML__Specification__WhereNonZeroLayerParams;
typedef struct _CoreML__Specification__MatrixBandPartLayerParams CoreML__Specification__MatrixBandPartLayerParams;
typedef struct _CoreML__Specification__UpperTriangularLayerParams CoreML__Specification__UpperTriangularLayerParams;
typedef struct _CoreML__Specification__LowerTriangularLayerParams CoreML__Specification__LowerTriangularLayerParams;
typedef struct _CoreML__Specification__BroadcastToLikeLayerParams CoreML__Specification__BroadcastToLikeLayerParams;
typedef struct _CoreML__Specification__BroadcastToStaticLayerParams CoreML__Specification__BroadcastToStaticLayerParams;
typedef struct _CoreML__Specification__BroadcastToDynamicLayerParams CoreML__Specification__BroadcastToDynamicLayerParams;
typedef struct _CoreML__Specification__AddBroadcastableLayerParams CoreML__Specification__AddBroadcastableLayerParams;
typedef struct _CoreML__Specification__MaxBroadcastableLayerParams CoreML__Specification__MaxBroadcastableLayerParams;
typedef struct _CoreML__Specification__MinBroadcastableLayerParams CoreML__Specification__MinBroadcastableLayerParams;
typedef struct _CoreML__Specification__ModBroadcastableLayerParams CoreML__Specification__ModBroadcastableLayerParams;
typedef struct _CoreML__Specification__FloorDivBroadcastableLayerParams CoreML__Specification__FloorDivBroadcastableLayerParams;
typedef struct _CoreML__Specification__SubtractBroadcastableLayerParams CoreML__Specification__SubtractBroadcastableLayerParams;
typedef struct _CoreML__Specification__MultiplyBroadcastableLayerParams CoreML__Specification__MultiplyBroadcastableLayerParams;
typedef struct _CoreML__Specification__DivideBroadcastableLayerParams CoreML__Specification__DivideBroadcastableLayerParams;
typedef struct _CoreML__Specification__GatherLayerParams CoreML__Specification__GatherLayerParams;
typedef struct _CoreML__Specification__ScatterLayerParams CoreML__Specification__ScatterLayerParams;
typedef struct _CoreML__Specification__GatherNDLayerParams CoreML__Specification__GatherNDLayerParams;
typedef struct _CoreML__Specification__ScatterNDLayerParams CoreML__Specification__ScatterNDLayerParams;
typedef struct _CoreML__Specification__GatherAlongAxisLayerParams CoreML__Specification__GatherAlongAxisLayerParams;
typedef struct _CoreML__Specification__ScatterAlongAxisLayerParams CoreML__Specification__ScatterAlongAxisLayerParams;
typedef struct _CoreML__Specification__StackLayerParams CoreML__Specification__StackLayerParams;
typedef struct _CoreML__Specification__RankPreservingReshapeLayerParams CoreML__Specification__RankPreservingReshapeLayerParams;
typedef struct _CoreML__Specification__ConstantPaddingLayerParams CoreML__Specification__ConstantPaddingLayerParams;
typedef struct _CoreML__Specification__RandomNormalLikeLayerParams CoreML__Specification__RandomNormalLikeLayerParams;
typedef struct _CoreML__Specification__RandomNormalStaticLayerParams CoreML__Specification__RandomNormalStaticLayerParams;
typedef struct _CoreML__Specification__RandomNormalDynamicLayerParams CoreML__Specification__RandomNormalDynamicLayerParams;
typedef struct _CoreML__Specification__RandomUniformLikeLayerParams CoreML__Specification__RandomUniformLikeLayerParams;
typedef struct _CoreML__Specification__RandomUniformStaticLayerParams CoreML__Specification__RandomUniformStaticLayerParams;
typedef struct _CoreML__Specification__RandomUniformDynamicLayerParams CoreML__Specification__RandomUniformDynamicLayerParams;
typedef struct _CoreML__Specification__RandomBernoulliLikeLayerParams CoreML__Specification__RandomBernoulliLikeLayerParams;
typedef struct _CoreML__Specification__RandomBernoulliStaticLayerParams CoreML__Specification__RandomBernoulliStaticLayerParams;
typedef struct _CoreML__Specification__RandomBernoulliDynamicLayerParams CoreML__Specification__RandomBernoulliDynamicLayerParams;
typedef struct _CoreML__Specification__CategoricalDistributionLayerParams CoreML__Specification__CategoricalDistributionLayerParams;
typedef struct _CoreML__Specification__ReduceL1LayerParams CoreML__Specification__ReduceL1LayerParams;
typedef struct _CoreML__Specification__ReduceL2LayerParams CoreML__Specification__ReduceL2LayerParams;
typedef struct _CoreML__Specification__ReduceMaxLayerParams CoreML__Specification__ReduceMaxLayerParams;
typedef struct _CoreML__Specification__ReduceMinLayerParams CoreML__Specification__ReduceMinLayerParams;
typedef struct _CoreML__Specification__ReduceSumLayerParams CoreML__Specification__ReduceSumLayerParams;
typedef struct _CoreML__Specification__ReduceProdLayerParams CoreML__Specification__ReduceProdLayerParams;
typedef struct _CoreML__Specification__ReduceMeanLayerParams CoreML__Specification__ReduceMeanLayerParams;
typedef struct _CoreML__Specification__ReduceLogSumLayerParams CoreML__Specification__ReduceLogSumLayerParams;
typedef struct _CoreML__Specification__ReduceSumSquareLayerParams CoreML__Specification__ReduceSumSquareLayerParams;
typedef struct _CoreML__Specification__ReduceLogSumExpLayerParams CoreML__Specification__ReduceLogSumExpLayerParams;
typedef struct _CoreML__Specification__ExpandDimsLayerParams CoreML__Specification__ExpandDimsLayerParams;
typedef struct _CoreML__Specification__FlattenTo2DLayerParams CoreML__Specification__FlattenTo2DLayerParams;
typedef struct _CoreML__Specification__ReshapeStaticLayerParams CoreML__Specification__ReshapeStaticLayerParams;
typedef struct _CoreML__Specification__ReshapeLikeLayerParams CoreML__Specification__ReshapeLikeLayerParams;
typedef struct _CoreML__Specification__ReshapeDynamicLayerParams CoreML__Specification__ReshapeDynamicLayerParams;
typedef struct _CoreML__Specification__SqueezeLayerParams CoreML__Specification__SqueezeLayerParams;
typedef struct _CoreML__Specification__TopKLayerParams CoreML__Specification__TopKLayerParams;
typedef struct _CoreML__Specification__ArgMaxLayerParams CoreML__Specification__ArgMaxLayerParams;
typedef struct _CoreML__Specification__ArgMinLayerParams CoreML__Specification__ArgMinLayerParams;
typedef struct _CoreML__Specification__SplitNDLayerParams CoreML__Specification__SplitNDLayerParams;
typedef struct _CoreML__Specification__CeilLayerParams CoreML__Specification__CeilLayerParams;
typedef struct _CoreML__Specification__RoundLayerParams CoreML__Specification__RoundLayerParams;
typedef struct _CoreML__Specification__FloorLayerParams CoreML__Specification__FloorLayerParams;
typedef struct _CoreML__Specification__SignLayerParams CoreML__Specification__SignLayerParams;
typedef struct _CoreML__Specification__ClipLayerParams CoreML__Specification__ClipLayerParams;
typedef struct _CoreML__Specification__SliceStaticLayerParams CoreML__Specification__SliceStaticLayerParams;
typedef struct _CoreML__Specification__SliceDynamicLayerParams CoreML__Specification__SliceDynamicLayerParams;
typedef struct _CoreML__Specification__TileLayerParams CoreML__Specification__TileLayerParams;
typedef struct _CoreML__Specification__GetShapeLayerParams CoreML__Specification__GetShapeLayerParams;
typedef struct _CoreML__Specification__ErfLayerParams CoreML__Specification__ErfLayerParams;
typedef struct _CoreML__Specification__GeluLayerParams CoreML__Specification__GeluLayerParams;
typedef struct _CoreML__Specification__RangeStaticLayerParams CoreML__Specification__RangeStaticLayerParams;
typedef struct _CoreML__Specification__RangeDynamicLayerParams CoreML__Specification__RangeDynamicLayerParams;
typedef struct _CoreML__Specification__SlidingWindowsLayerParams CoreML__Specification__SlidingWindowsLayerParams;
typedef struct _CoreML__Specification__LayerNormalizationLayerParams CoreML__Specification__LayerNormalizationLayerParams;
typedef struct _CoreML__Specification__NonMaximumSuppressionLayerParams CoreML__Specification__NonMaximumSuppressionLayerParams;
typedef struct _CoreML__Specification__ClampedReLULayerParams CoreML__Specification__ClampedReLULayerParams;
typedef struct _CoreML__Specification__ArgSortLayerParams CoreML__Specification__ArgSortLayerParams;
typedef struct _CoreML__Specification__SliceBySizeLayerParams CoreML__Specification__SliceBySizeLayerParams;
typedef struct _CoreML__Specification__NeuralNetworkClassifier CoreML__Specification__NeuralNetworkClassifier;
typedef struct _CoreML__Specification__OneHotLayerParams CoreML__Specification__OneHotLayerParams;
typedef struct _CoreML__Specification__CumSumLayerParams CoreML__Specification__CumSumLayerParams;
typedef struct _CoreML__Specification__NeuralNetworkRegressor CoreML__Specification__NeuralNetworkRegressor;
typedef struct _CoreML__Specification__NetworkUpdateParameters CoreML__Specification__NetworkUpdateParameters;
typedef struct _CoreML__Specification__LossLayer CoreML__Specification__LossLayer;
typedef struct _CoreML__Specification__CategoricalCrossEntropyLossLayer CoreML__Specification__CategoricalCrossEntropyLossLayer;
typedef struct _CoreML__Specification__MeanSquaredErrorLossLayer CoreML__Specification__MeanSquaredErrorLossLayer;
typedef struct _CoreML__Specification__Optimizer CoreML__Specification__Optimizer;
typedef struct _CoreML__Specification__SGDOptimizer CoreML__Specification__SGDOptimizer;
typedef struct _CoreML__Specification__AdamOptimizer CoreML__Specification__AdamOptimizer;


/* --- enums --- */

typedef enum _CoreML__Specification__SamePadding__SamePaddingMode {
  CORE_ML__SPECIFICATION__SAME_PADDING__SAME_PADDING_MODE__BOTTOM_RIGHT_HEAVY = 0,
  CORE_ML__SPECIFICATION__SAME_PADDING__SAME_PADDING_MODE__TOP_LEFT_HEAVY = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__SAME_PADDING__SAME_PADDING_MODE)
} CoreML__Specification__SamePadding__SamePaddingMode;
typedef enum _CoreML__Specification__SamplingMode__Method {
  /*
   **
   * start = 0, end = X-1
   * grid points = numpy.linspace(start, end)
   */
  CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD__STRICT_ALIGN_ENDPOINTS_MODE = 0,
  /*
   **
   * if N == 1: start = end = (X-1)/2
   * otherwise, start = 0, end = X-1
   * grid points = numpy.linspace(start, end)
   */
  CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD__ALIGN_ENDPOINTS_MODE = 1,
  /*
   **
   * start = 0, end = X - X/N
   * grid points = min(X-1, numpy.linspace(start, end))
   * This is same as the mode used in the upsample layer in this specification, when used with bilinear interpolation. In that case N/X = upsample ratio.
   */
  CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD__UPSAMPLE_MODE = 2,
  /*
   **
   * spacing = max(1, X-1)/N
   * start = 0.5 * spacing
   * end = start + (N-1) * spacing
   * grid points = min(X-1, numpy.linspace(start, end))
   */
  CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD__ROI_ALIGN_MODE = 3
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD)
} CoreML__Specification__SamplingMode__Method;
typedef enum _CoreML__Specification__BoxCoordinatesMode__Coordinates {
  /*
   **
   * [h_start, w_start, h_end, w_end]
   */
  CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES__CORNERS_HEIGHT_FIRST = 0,
  /*
   **
   * [w_start, h_start, w_end, h_end]
   */
  CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES__CORNERS_WIDTH_FIRST = 1,
  /*
   **
   * [h_center, w_center, box_height, box_width]
   */
  CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES__CENTER_SIZE_HEIGHT_FIRST = 2,
  /*
   **
   * [w_center, h_center, box_width, box_height]
   */
  CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES__CENTER_SIZE_WIDTH_FIRST = 3
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES)
} CoreML__Specification__BoxCoordinatesMode__Coordinates;
/*
 **
 * The type of padding.
 * All padding types pad the input shape with zeros.
 * CUSTOM padding will add the custom padding values specified below to their respective
 * dimensions, e.g., `customPaddingFront` number of zeros will be added to one side of the
 * input's depth dimension and `customPaddingBack` number of zeros will be added to the other
 * side of the input's depth dimension.
 * VALID padding adds no padding to any dimension. In this case, the last convolution along
 * each dimension will be dropped if the input dimension and the kernel size, stride, and
 * dilation do not match.
 * SAME padding adds enough padding to each dimension such that the output of the convolution
 * has size ``Ceiling(inputShape / stride)``. Padding is added evenly to both sides of each
 * dimension unless the total padding to add is odd, in which case it is added to the
 * back/bottom/right side of the respective dimension. For example, if the total padding needed
 * in the depth dimension is 3, 1 zero will be added to the front side of the depth dimension
 * and 2 zeros will be added to the back side.
 */
typedef enum _CoreML__Specification__Convolution3DLayerParams__PaddingType {
  CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__PADDING_TYPE__CUSTOM = 0,
  CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__PADDING_TYPE__VALID = 1,
  CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__PADDING_TYPE__SAME = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__PADDING_TYPE)
} CoreML__Specification__Convolution3DLayerParams__PaddingType;
typedef enum _CoreML__Specification__PoolingLayerParams__PoolingType {
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_TYPE__MAX = 0,
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_TYPE__AVERAGE = 1,
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_TYPE__L2 = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_TYPE)
} CoreML__Specification__PoolingLayerParams__PoolingType;
typedef enum _CoreML__Specification__Pooling3DLayerParams__PoolingType3D {
  CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING_TYPE3_D__MAX = 0,
  CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING_TYPE3_D__AVERAGE = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING_TYPE3_D)
} CoreML__Specification__Pooling3DLayerParams__PoolingType3D;
/*
 **
 * The type of padding.
 * All padding types pad the input shape with zeros.
 * CUSTOM padding will add the custom padding values specified below to their respective
 * dimensions, e.g., `customPaddingFront` number of zeros will be added to one side of the
 * input's depth dimension and `customPaddingBack` number of zeros will be added to the other
 * side of the input's depth dimension.
 * VALID padding adds no padding to any dimension. In this case, the last pool along
 * each dimension will be dropped if the input dimension and the kernel size, and stride do not match.
 * SAME padding adds enough padding to each dimension such that the output
 * has the same spatial dimensions as the input. Padding is added evenly to both
 * sides of each dimension unless the total padding to add is odd, in which case the extra padding
 * is added to the back/bottom/right side of the respective dimension.  For example, if the
 * total horizontal padding is 3, then there will be 1 padding on the left, and 2 padding on the right.
 */
typedef enum _CoreML__Specification__Pooling3DLayerParams__Pooling3DPaddingType {
  CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING3_DPADDING_TYPE__CUSTOM = 0,
  CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING3_DPADDING_TYPE__VALID = 1,
  CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING3_DPADDING_TYPE__SAME = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING3_DPADDING_TYPE)
} CoreML__Specification__Pooling3DLayerParams__Pooling3DPaddingType;
typedef enum _CoreML__Specification__GlobalPooling3DLayerParams__GlobalPoolingType3D {
  CORE_ML__SPECIFICATION__GLOBAL_POOLING3_DLAYER_PARAMS__GLOBAL_POOLING_TYPE3_D__MAX = 0,
  CORE_ML__SPECIFICATION__GLOBAL_POOLING3_DLAYER_PARAMS__GLOBAL_POOLING_TYPE3_D__AVERAGE = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__GLOBAL_POOLING3_DLAYER_PARAMS__GLOBAL_POOLING_TYPE3_D)
} CoreML__Specification__GlobalPooling3DLayerParams__GlobalPoolingType3D;
/*
 **
 * A unary operator.
 * The following functions are supported:
 * ``SQRT``
 *     .. math:: f(x) = \sqrt{x}
 * ``RSQRT``
 *     .. math:: f(x) = \dfrac{1}{\sqrt{x + \epsilon}}
 * ``INVERSE``
 *     .. math:: f(x) = \dfrac{1}{x + \epsilon}
 * ``POWER``
 *     .. math:: f(x) = x^\alpha
 * ``EXP``
 *     .. math:: f(x) = e^x
 * ``LOG``
 *     .. math:: f(x) = \log x
 * ``ABS``
 *     .. math:: f(x) = |x|
 * ``THRESHOLD``
 *     .. math:: f(x) = \text{max}(\alpha, x)
 */
typedef enum _CoreML__Specification__UnaryFunctionLayerParams__Operation {
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__SQRT = 0,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__RSQRT = 1,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__INVERSE = 2,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__POWER = 3,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__EXP = 4,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__LOG = 5,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__ABS = 6,
  CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__THRESHOLD = 7
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION)
} CoreML__Specification__UnaryFunctionLayerParams__Operation;
/*
 * Overall mode for interpolating new elements when upsampling.
 * NN - Nearest Neighbors - simply pick the nearest true value for interpolated values.
 * BILINEAR - Use bilinear interpolation. See LinearUpsamplingMode for behavior.
 */
typedef enum _CoreML__Specification__UpsampleLayerParams__InterpolationMode {
  /*
   * / Nearest Neighbour
   */
  CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__INTERPOLATION_MODE__NN = 0,
  /*
   * / Bilinear
   */
  CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__INTERPOLATION_MODE__BILINEAR = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__INTERPOLATION_MODE)
} CoreML__Specification__UpsampleLayerParams__InterpolationMode;
/*
 **
 * LinearUpsampleMode specifies the behavior for linear upsampling. Only valid when Interpolation Mode is BILINEAR.
 * If input grid is [0, Xin-1] (corresponding to an input size of Xin), and if the output size is Xout,
 * then the grid points are sampled in the following manner:
 * DEFAULT:
 *   spacing = (Xin-Xin/Xout) / (Xout-1)
 *   grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
 * ALIGN_CORNERS_TRUE:
 *   spacing = (Xin-1) / (Xout-1)
 *   grid_point[i] = min(Xin-1, max(0, i * spacing)), for i = 0,1,2,….,Xout-1
 * ALIGN_CORNERS_FALSE:
 *   spacing = Xin / Xout
 *   grid_point[i] = min(Xin-1, max(0, i * spacing + 0.5 * spacing - 0.5)), for i = 0,1,2,….,Xout-1
 */
typedef enum _CoreML__Specification__UpsampleLayerParams__LinearUpsampleMode {
  CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__LINEAR_UPSAMPLE_MODE__DEFAULT = 0,
  CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__LINEAR_UPSAMPLE_MODE__ALIGN_CORNERS_TRUE = 1,
  CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__LINEAR_UPSAMPLE_MODE__ALIGN_CORNERS_FALSE = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__LINEAR_UPSAMPLE_MODE)
} CoreML__Specification__UpsampleLayerParams__LinearUpsampleMode;
typedef enum _CoreML__Specification__FlattenLayerParams__FlattenOrder {
  CORE_ML__SPECIFICATION__FLATTEN_LAYER_PARAMS__FLATTEN_ORDER__CHANNEL_FIRST = 0,
  CORE_ML__SPECIFICATION__FLATTEN_LAYER_PARAMS__FLATTEN_ORDER__CHANNEL_LAST = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__FLATTEN_LAYER_PARAMS__FLATTEN_ORDER)
} CoreML__Specification__FlattenLayerParams__FlattenOrder;
typedef enum _CoreML__Specification__ReshapeLayerParams__ReshapeOrder {
  CORE_ML__SPECIFICATION__RESHAPE_LAYER_PARAMS__RESHAPE_ORDER__CHANNEL_FIRST = 0,
  CORE_ML__SPECIFICATION__RESHAPE_LAYER_PARAMS__RESHAPE_ORDER__CHANNEL_LAST = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__RESHAPE_LAYER_PARAMS__RESHAPE_ORDER)
} CoreML__Specification__ReshapeLayerParams__ReshapeOrder;
typedef enum _CoreML__Specification__ReorganizeDataLayerParams__ReorganizationType {
  CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__REORGANIZATION_TYPE__SPACE_TO_DEPTH = 0,
  CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__REORGANIZATION_TYPE__DEPTH_TO_SPACE = 1,
  CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__REORGANIZATION_TYPE__PIXEL_SHUFFLE = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__REORGANIZATION_TYPE)
} CoreML__Specification__ReorganizeDataLayerParams__ReorganizationType;
typedef enum _CoreML__Specification__SliceLayerParams__SliceAxis {
  CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__SLICE_AXIS__CHANNEL_AXIS = 0,
  CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__SLICE_AXIS__HEIGHT_AXIS = 1,
  CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__SLICE_AXIS__WIDTH_AXIS = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__SLICE_AXIS)
} CoreML__Specification__SliceLayerParams__SliceAxis;
/*
 * The following reduction operations are supported
 * and are applied on the specified axis of the input array:
 * ``SUM``
 *     Sum of all elements
 *     .. math:: \sum{x_i}
 * ``AVG``
 *     Sum of all elements divided by the number of elements
 *     .. math:: \dfrac{\sum^n{x_i}}{n}
 * ``PROD``
 *     Product of all elements
 *     .. math:: \prod{x_i}
 * ``LOGSUM``
 *     Sum of the natural logarithm of all elements
 *     .. math:: \sum{\ln{(x_i + \epsilon)}}
 * ``SUMSQUARE``
 *     Sum of squares of all elements
 *     .. math:: \sum{x^2}
 * ``L1``
 *     L1 normalization of all elements
 *     .. math:: ||x||_1 = \sum{|x_i|}
 * ``L2``
 *     L2 normalization of all elements
 *     .. math:: ||x||_2 = \sqrt{\sum{x_i^2}}
 * ``MAX``
 *     Maximum of all elements
 *     .. math:: \text{max}(x_i)
 * ``MIN``
 *     Minumum of all elements
 *     .. math:: \text{min}(x_i)
 * ``ARGMAX``
 *     Argument of the maximum of all elements
 *     .. math:: \text{argmax}(x_i)
 */
typedef enum _CoreML__Specification__ReduceLayerParams__ReduceOperation {
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__SUM = 0,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__AVG = 1,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__PROD = 2,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__LOGSUM = 3,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__SUMSQUARE = 4,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__L1 = 5,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__L2 = 6,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__MAX = 7,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__MIN = 8,
  /*
   * / only supported with axis = C, H or W.
   */
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__ARGMAX = 9
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION)
} CoreML__Specification__ReduceLayerParams__ReduceOperation;
typedef enum _CoreML__Specification__ReduceLayerParams__ReduceAxis {
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__CHW = 0,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__HW = 1,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__C = 2,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__H = 3,
  CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__W = 4
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS)
} CoreML__Specification__ReduceLayerParams__ReduceAxis;
typedef enum _CoreML__Specification__GeluLayerParams__GeluMode {
  CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__GELU_MODE__EXACT = 0,
  CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__GELU_MODE__TANH_APPROXIMATION = 1,
  CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__GELU_MODE__SIGMOID_APPROXIMATION = 2
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__GELU_MODE)
} CoreML__Specification__GeluLayerParams__GeluMode;
typedef enum _CoreML__Specification__NeuralNetworkMultiArrayShapeMapping {
  /*
   * Default legacy value. Only supported for Core ML Specification version <= 3.
   * The default legacy shape mapping resolves all input shapes to a rank 5 equivalent
   * with axis notation of [Seq, Batch, Channel, Height, Width].
   * When this enum value is selected,
   * the repeated shape field in the message "ArrayFeatureType" in feature types proto,
   * must be either length 1 or length 3.
   * The following rule is used to map the values in the shape field to the actual tensor shape:
   * rank 1 shape is mapped to shape [1,1,C,1,1]
   * rank 3 shape is mapped to shape [1,1,C,H,W]
   * At runtime, the first two dimensions (Seq or Batch) can be presented as well, with non-1 values.
   * It is invalid to use this enum value if any of the layers added
   * Specification version 4 (iOS >= 13, macOS >= 10.15) onwards are used in the network.
   * Validator will raise an error in that case.
   */
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING__RANK5_ARRAY_MAPPING = 0,
  /*
   * The exact shape and rank (i.e. number of dimensions in the shape) of the input,
   * as specified in the message "ArrayFeatureType", is passed through to the layers.
   * Supported only for Specification version >= 4 (iOS >= 13, macOS >= 10.15).
   */
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING__EXACT_ARRAY_MAPPING = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING)
} CoreML__Specification__NeuralNetworkMultiArrayShapeMapping;
typedef enum _CoreML__Specification__NeuralNetworkImageShapeMapping {
  /*
   * In this case, image input is mapped to a rank 5 tensor.
   * For Color images, input tensor is shaped as [1,1,3,H,W].
   * For Gray images, input tensor is shaped as [1,1,1,H,W].
   */
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING__RANK5_IMAGE_MAPPING = 0,
  /*
   * For Color images, input tensor is shaped as [1,3,H,W].
   * For Gray images, input tensor is shaped as [1,1,H,W].
   * Supported only for Specification version >= 4 (iOS >= 13, macOS >= 10.15).
   */
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING__RANK4_IMAGE_MAPPING = 1
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING)
} CoreML__Specification__NeuralNetworkImageShapeMapping;
/*
 * Scatter accumulation mode.
 */
typedef enum _CoreML__Specification__ScatterMode {
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_UPDATE = 0,
  /*
   * / add
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_ADD = 1,
  /*
   * / subtract
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_SUB = 2,
  /*
   * / multiply
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_MUL = 3,
  /*
   * / divide
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_DIV = 4,
  /*
   * / maximum
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_MAX = 5,
  /*
   * / minimum
   */
  CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_MIN = 6
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__SCATTER_MODE)
} CoreML__Specification__ScatterMode;

/* --- messages --- */

/*
 **
 *A neural network.
 */
struct  _CoreML__Specification__NeuralNetwork
{
  ProtobufCMessage base;
  size_t n_layers;
  CoreML__Specification__NeuralNetworkLayer **layers;
  size_t n_preprocessing;
  CoreML__Specification__NeuralNetworkPreprocessing **preprocessing;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
   */
  CoreML__Specification__NeuralNetworkMultiArrayShapeMapping arrayinputshapemapping;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for image inputs
   */
  CoreML__Specification__NeuralNetworkImageShapeMapping imageinputshapemapping;
  CoreML__Specification__NetworkUpdateParameters *updateparams;
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network__descriptor) \
    , 0,NULL, 0,NULL, CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING__RANK5_ARRAY_MAPPING, CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING__RANK5_IMAGE_MAPPING, NULL }


/*
 **
 * A neural network preprocessor that
 * performs a scalar multiplication of an image
 * followed by addition of scalar biases to the channels.
 * Input: X
 *    An image in BGR or RGB format with shape ``[3, H, W]``
 *    or in grayscale format with shape ``[1, H, W]``.
 * Output: Y
 *    An image with format and shape corresponding to the input.
 * If the input image is in BGR format:
 * .. code::
 *     Y[0, :, :] = channelScale * X[0, :, :] + blueBias
 *     Y[1, :, :] = channelScale * X[1, :, :] + greenBias
 *     Y[2, :, :] = channelScale * X[2, :, :] + redBias
 * If the input image is in RGB format:
 * .. code::
 *     Y[0, :, :] = channelScale * X[0, :, :] + redBias
 *     Y[1, :, :] = channelScale * X[1, :, :] + greenBias
 *     Y[2, :, :] = channelScale * X[2, :, :] + blueBias
 * If the input image is in grayscale format:
 * .. code::
 *     Y[0, :, :] = channelScale * X[0, :, :] + grayBias
 */
struct  _CoreML__Specification__NeuralNetworkImageScaler
{
  ProtobufCMessage base;
  /*
   * /Scalar to be multiplied.
   */
  float channelscale;
  /*
   * /Scalar blue bias to be added.
   */
  float bluebias;
  /*
   * /Scalar green bias to be added.
   */
  float greenbias;
  /*
   * /Scalar red bias to be added.
   */
  float redbias;
  /*
   * /Scalar bias to be added for grayscale images.
   */
  float graybias;
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SCALER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_image_scaler__descriptor) \
    , 0, 0, 0, 0, 0 }


/*
 **
 * A neural network preprocessor that
 * subtracts the provided mean image from the input image.
 * The mean image is subtracted from the input named
 * ``NeuralNetworkPreprocessing.featureName``.
 */
struct  _CoreML__Specification__NeuralNetworkMeanImage
{
  ProtobufCMessage base;
  /*
   **
   * Mean image stored as a flattened array of floats,
   * representing shape [Channel,Height,Width].
   */
  size_t n_meanimage;
  float *meanimage;
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_MEAN_IMAGE__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_mean_image__descriptor) \
    , 0,NULL }


typedef enum {
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__PREPROCESSOR__NOT_SET = 0,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__PREPROCESSOR_SCALER = 10,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__PREPROCESSOR_MEAN_IMAGE = 11
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__PREPROCESSOR)
} CoreML__Specification__NeuralNetworkPreprocessing__PreprocessorCase;

/*
 * / Preprocessing parameters for image inputs.
 */
struct  _CoreML__Specification__NeuralNetworkPreprocessing
{
  ProtobufCMessage base;
  /*
   * / must be equal to the input name to which the preprocessing is applied
   */
  char *featurename;
  CoreML__Specification__NeuralNetworkPreprocessing__PreprocessorCase preprocessor_case;
  union {
    CoreML__Specification__NeuralNetworkImageScaler *scaler;
    CoreML__Specification__NeuralNetworkMeanImage *meanimage;
  };
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_preprocessing__descriptor) \
    , (char *)protobuf_c_empty_string, CORE_ML__SPECIFICATION__NEURAL_NETWORK_PREPROCESSING__PREPROCESSOR__NOT_SET, {0} }


/*
 **
 * A rectified linear unit (ReLU) activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \text{max}(0, x)
 */
struct  _CoreML__Specification__ActivationReLU
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_RE_LU__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_re_lu__descriptor) \
     }


/*
 **
 * A leaky rectified linear unit (ReLU) activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \begin{cases}
 *             x      & \text{if } x \geq 0 \\
 *             \alpha x & \text{if } x < 0
 *            \end{cases}
 */
struct  _CoreML__Specification__ActivationLeakyReLU
{
  ProtobufCMessage base;
  /*
   *negative slope value for leakyReLU
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_LEAKY_RE_LU__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_leaky_re_lu__descriptor) \
    , 0 }


/*
 **
 * A hyperbolic tangent activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \dfrac{1 - e^{-2x}}{1 + e^{-2x}}
 */
struct  _CoreML__Specification__ActivationTanh
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_TANH__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_tanh__descriptor) \
     }


/*
 **
 * A scaled hyperbolic tangent activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \alpha \tanh(\beta x)
 */
struct  _CoreML__Specification__ActivationScaledTanh
{
  ProtobufCMessage base;
  float alpha;
  float beta;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_SCALED_TANH__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_scaled_tanh__descriptor) \
    , 0, 0 }


/*
 **
 * A sigmoid activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \dfrac{1}{1 + e^{-x}}
 */
struct  _CoreML__Specification__ActivationSigmoid
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_SIGMOID__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_sigmoid__descriptor) \
     }


/*
 **
 * A linear activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \alpha x + \beta
 */
struct  _CoreML__Specification__ActivationLinear
{
  ProtobufCMessage base;
  float alpha;
  float beta;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_LINEAR__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_linear__descriptor) \
    , 0, 0 }


/*
 **
 * A hard sigmoid activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \text{min}(\text{max}(\alpha x + \beta, 0), 1)
 */
struct  _CoreML__Specification__ActivationSigmoidHard
{
  ProtobufCMessage base;
  float alpha;
  float beta;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_SIGMOID_HARD__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_sigmoid_hard__descriptor) \
    , 0, 0 }


/*
 **
 * A parameterized rectified linear unit (PReLU) activation function.
 * Input must be at least rank 3. Axis = -3 is denoted by "C", or channels.
 * "alpha" parameter can be a vector of length C.
 * This function has the following formula:
 * .. math::
 *    f(x_i) = \begin{cases}
 *                 x_i          & \text{if } x_i \geq 0 \\
 *                 \alpha_i x_i & \text{if } x_i < 0
 *             \end{cases} \;,\;i=1,...,C
 */
struct  _CoreML__Specification__ActivationPReLU
{
  ProtobufCMessage base;
  /*
   * parameter of length C or 1.
   * If length is 1, same value is used for all channels
   */
  CoreML__Specification__WeightParams *alpha;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_PRE_LU__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_pre_lu__descriptor) \
    , NULL }


/*
 **
 * An exponential linear unit (ELU) activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \begin{cases}
 *             x              & \text{if } x \geq 0 \\
 *             \alpha (e^x - 1) & \text{if } x < 0
 *            \end{cases}
 */
struct  _CoreML__Specification__ActivationELU
{
  ProtobufCMessage base;
  float alpha;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_ELU__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_elu__descriptor) \
    , 0 }


/*
 **
 * A thresholded rectified linear unit (ReLU) activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \begin{cases}
 *             x & \text{if } x \geq \alpha \\
 *             0 & \text{if } x < \alpha
 *            \end{cases}
 */
struct  _CoreML__Specification__ActivationThresholdedReLU
{
  ProtobufCMessage base;
  float alpha;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_THRESHOLDED_RE_LU__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_thresholded_re_lu__descriptor) \
    , 0 }


/*
 **
 * A softsign activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \dfrac{x}{1 + |x|}
 */
struct  _CoreML__Specification__ActivationSoftsign
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_SOFTSIGN__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_softsign__descriptor) \
     }


/*
 **
 * A softplus activation function.
 * This function has the following formula:
 * .. math::
 *     f(x) = \text{log}(1 + e^x)
 */
struct  _CoreML__Specification__ActivationSoftplus
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_SOFTPLUS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_softplus__descriptor) \
     }


/*
 **
 * A parametric softplus activation function.
 * Input must be at least rank 3. axis = -3 is denoted by "C", or channels.
 * "alpha"/"beta" parameter can be a vector of length C.
 * This function has the following formula:
 * .. math::
 *     f(x_i) = \alpha_i \text{log}(1 + e^{\beta_i x_i}) \;,\;i=1,...,C
 */
struct  _CoreML__Specification__ActivationParametricSoftplus
{
  ProtobufCMessage base;
  /*
   * If length is 1, same value is used for all channels
   */
  /*
   *parameter of length C or 1
   */
  CoreML__Specification__WeightParams *alpha;
  /*
   *parameter of length C or 1
   */
  CoreML__Specification__WeightParams *beta;
};
#define CORE_ML__SPECIFICATION__ACTIVATION_PARAMETRIC_SOFTPLUS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_parametric_softplus__descriptor) \
    , NULL, NULL }


typedef enum {
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_LINEAR = 5,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_RE_LU = 10,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_LEAKY_RE_LU = 15,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_THRESHOLDED_RE_LU = 20,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_PRE_LU = 25,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_TANH = 30,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_SCALED_TANH = 31,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_SIGMOID = 40,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_SIGMOID_HARD = 41,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_ELU = 50,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_SOFTSIGN = 60,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_SOFTPLUS = 70,
  CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE_PARAMETRIC_SOFTPLUS = 71
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE)
} CoreML__Specification__ActivationParams__NonlinearityTypeCase;

struct  _CoreML__Specification__ActivationParams
{
  ProtobufCMessage base;
  CoreML__Specification__ActivationParams__NonlinearityTypeCase nonlinearity_type_case;
  union {
    CoreML__Specification__ActivationLinear *linear;
    CoreML__Specification__ActivationReLU *relu;
    CoreML__Specification__ActivationLeakyReLU *leakyrelu;
    CoreML__Specification__ActivationThresholdedReLU *thresholdedrelu;
    CoreML__Specification__ActivationPReLU *prelu;
    CoreML__Specification__ActivationTanh *tanh;
    CoreML__Specification__ActivationScaledTanh *scaledtanh;
    CoreML__Specification__ActivationSigmoid *sigmoid;
    CoreML__Specification__ActivationSigmoidHard *sigmoidhard;
    CoreML__Specification__ActivationELU *elu;
    CoreML__Specification__ActivationSoftsign *softsign;
    CoreML__Specification__ActivationSoftplus *softplus;
    CoreML__Specification__ActivationParametricSoftplus *parametricsoftplus;
  };
};
#define CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__activation_params__descriptor) \
    , CORE_ML__SPECIFICATION__ACTIVATION_PARAMS__NONLINEARITY_TYPE__NOT_SET, {0} }


/*
 **
 * Representation of the intermediate tensors
 */
struct  _CoreML__Specification__Tensor
{
  ProtobufCMessage base;
  /*
   * Number of dimensions in the tensor shape
   */
  uint32_t rank;
  /*
   * actual value of the tensor shape.
   * must be of length "rank". Can contain -1s for unknown dimensions.
   */
  size_t n_dimvalue;
  int64_t *dimvalue;
};
#define CORE_ML__SPECIFICATION__TENSOR__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__tensor__descriptor) \
    , 0, 0,NULL }


typedef enum {
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER__NOT_SET = 0,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CONVOLUTION = 100,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_POOLING = 120,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ACTIVATION = 130,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_INNER_PRODUCT = 140,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_EMBEDDING = 150,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BATCHNORM = 160,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MVN = 165,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_L2NORMALIZE = 170,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SOFTMAX = 175,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LRN = 180,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CROP = 190,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_PADDING = 200,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_UPSAMPLE = 210,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RESIZE_BILINEAR = 211,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CROP_RESIZE = 212,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_UNARY = 220,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ADD = 230,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MULTIPLY = 231,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_AVERAGE = 240,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SCALE = 245,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BIAS = 250,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MAX = 260,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MIN = 261,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_DOT = 270,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE = 280,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOAD_CONSTANT = 290,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RESHAPE = 300,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FLATTEN = 301,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_PERMUTE = 310,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CONCAT = 320,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SPLIT = 330,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SEQUENCE_REPEAT = 340,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REORGANIZE_DATA = 345,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SLICE = 350,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SIMPLE_RECURRENT = 400,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GRU = 410,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_UNI_DIRECTIONAL_LSTM = 420,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BI_DIRECTIONAL_LSTM = 430,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CUSTOM = 500,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_COPY = 600,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BRANCH = 605,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOOP = 615,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOOP_BREAK = 620,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOOP_CONTINUE = 625,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANGE_STATIC = 635,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANGE_DYNAMIC = 640,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CLIP = 660,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CEIL = 665,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FLOOR = 670,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SIGN = 680,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ROUND = 685,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_EXP2 = 700,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SIN = 710,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_COS = 715,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_TAN = 720,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ASIN = 730,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ACOS = 735,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ATAN = 740,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SINH = 750,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_COSH = 755,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_TANH = 760,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ASINH = 770,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ACOSH = 775,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ATANH = 780,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ERF = 790,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GELU = 795,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_EQUAL = 815,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_NOT_EQUAL = 820,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LESS_THAN = 825,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LESS_EQUAL = 827,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GREATER_THAN = 830,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GREATER_EQUAL = 832,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOGICAL_OR = 840,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOGICAL_XOR = 845,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOGICAL_NOT = 850,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOGICAL_AND = 855,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MOD_BROADCASTABLE = 865,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MIN_BROADCASTABLE = 870,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MAX_BROADCASTABLE = 875,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ADD_BROADCASTABLE = 880,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_POW_BROADCASTABLE = 885,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_DIVIDE_BROADCASTABLE = 890,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FLOOR_DIV_BROADCASTABLE = 895,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MULTIPLY_BROADCASTABLE = 900,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SUBTRACT_BROADCASTABLE = 905,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_TILE = 920,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_STACK = 925,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GATHER = 930,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SCATTER = 935,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GATHER_ND = 940,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SCATTER_ND = 945,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SOFTMAX_ND = 950,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GATHER_ALONG_AXIS = 952,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SCATTER_ALONG_AXIS = 954,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REVERSE = 960,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REVERSE_SEQ = 965,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SPLIT_ND = 975,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CONCAT_ND = 980,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_TRANSPOSE = 985,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SLICE_STATIC = 995,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SLICE_DYNAMIC = 1000,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SLIDING_WINDOWS = 1005,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_TOP_K = 1015,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ARG_MIN = 1020,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ARG_MAX = 1025,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_EMBEDDING_ND = 1040,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BATCHED_MATMUL = 1045,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GET_SHAPE = 1065,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOAD_CONSTANT_ND = 1070,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FILL_LIKE = 1080,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FILL_STATIC = 1085,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FILL_DYNAMIC = 1090,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BROADCAST_TO_LIKE = 1100,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BROADCAST_TO_STATIC = 1105,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_BROADCAST_TO_DYNAMIC = 1110,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SQUEEZE = 1120,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_EXPAND_DIMS = 1125,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_FLATTEN_TO2_D = 1130,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RESHAPE_LIKE = 1135,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RESHAPE_STATIC = 1140,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RESHAPE_DYNAMIC = 1145,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANK_PRESERVING_RESHAPE = 1150,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CONSTANT_PAD = 1155,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_NORMAL_LIKE = 1170,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_NORMAL_STATIC = 1175,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_NORMAL_DYNAMIC = 1180,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_UNIFORM_LIKE = 1190,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_UNIFORM_STATIC = 1195,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_UNIFORM_DYNAMIC = 1200,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_BERNOULLI_LIKE = 1210,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_BERNOULLI_STATIC = 1215,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_RANDOM_BERNOULLI_DYNAMIC = 1220,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CATEGORICAL_DISTRIBUTION = 1230,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_L1 = 1250,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_L2 = 1255,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_MAX = 1260,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_MIN = 1265,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_SUM = 1270,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_PROD = 1275,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_MEAN = 1280,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_LOG_SUM = 1285,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_SUM_SQUARE = 1290,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_REDUCE_LOG_SUM_EXP = 1295,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_WHERE_NON_ZERO = 1313,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_MATRIX_BAND_PART = 1315,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LOWER_TRIANGULAR = 1320,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_UPPER_TRIANGULAR = 1325,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_WHERE_BROADCASTABLE = 1330,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_LAYER_NORMALIZATION = 1350,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_NON_MAXIMUM_SUPPRESSION = 1400,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ONE_HOT = 1450,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CUM_SUM = 1455,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CLAMPED_RE_LU = 1460,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_ARG_SORT = 1461,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_POOLING3D = 1465,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_GLOBAL_POOLING3D = 1466,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_SLICE_BY_SIZE = 1470,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER_CONVOLUTION3D = 1471
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER)
} CoreML__Specification__NeuralNetworkLayer__LayerCase;

/*
 **
 * A single neural network layer.
 */
struct  _CoreML__Specification__NeuralNetworkLayer
{
  ProtobufCMessage base;
  /*
   *descriptive name of the layer
   */
  char *name;
  size_t n_input;
  char **input;
  size_t n_output;
  char **output;
  /*
   * must be the same length as the "input" field
   */
  size_t n_inputtensor;
  CoreML__Specification__Tensor **inputtensor;
  /*
   * must be the same length as the "output" field
   */
  size_t n_outputtensor;
  CoreML__Specification__Tensor **outputtensor;
  /*
   * Must be set to true to mark the layer as updatable.
   * If true, the weightParams in the layer's properties must also be set to updatable
   * If false, the value of the isUpdatable parameter within the layer's weights are ignored
   */
  protobuf_c_boolean isupdatable;
  CoreML__Specification__NeuralNetworkLayer__LayerCase layer_case;
  union {
    /*
     * Start at 100 here
     */
    CoreML__Specification__ConvolutionLayerParams *convolution;
    CoreML__Specification__PoolingLayerParams *pooling;
    CoreML__Specification__ActivationParams *activation;
    CoreML__Specification__InnerProductLayerParams *innerproduct;
    CoreML__Specification__EmbeddingLayerParams *embedding;
    /*
     * Normalization-related Layers
     */
    CoreML__Specification__BatchnormLayerParams *batchnorm;
    CoreML__Specification__MeanVarianceNormalizeLayerParams *mvn;
    CoreML__Specification__L2NormalizeLayerParams *l2normalize;
    CoreML__Specification__SoftmaxLayerParams *softmax;
    CoreML__Specification__LRNLayerParams *lrn;
    CoreML__Specification__CropLayerParams *crop;
    CoreML__Specification__PaddingLayerParams *padding;
    CoreML__Specification__UpsampleLayerParams *upsample;
    CoreML__Specification__ResizeBilinearLayerParams *resizebilinear;
    CoreML__Specification__CropResizeLayerParams *cropresize;
    CoreML__Specification__UnaryFunctionLayerParams *unary;
    /*
     * Element-wise Operations
     */
    CoreML__Specification__AddLayerParams *add;
    CoreML__Specification__MultiplyLayerParams *multiply;
    CoreML__Specification__AverageLayerParams *average;
    CoreML__Specification__ScaleLayerParams *scale;
    CoreML__Specification__BiasLayerParams *bias;
    CoreML__Specification__MaxLayerParams *max;
    CoreML__Specification__MinLayerParams *min;
    CoreML__Specification__DotProductLayerParams *dot;
    CoreML__Specification__ReduceLayerParams *reduce;
    CoreML__Specification__LoadConstantLayerParams *loadconstant;
    /*
     * Data Reorganization
     */
    CoreML__Specification__ReshapeLayerParams *reshape;
    CoreML__Specification__FlattenLayerParams *flatten;
    CoreML__Specification__PermuteLayerParams *permute;
    CoreML__Specification__ConcatLayerParams *concat;
    CoreML__Specification__SplitLayerParams *split;
    CoreML__Specification__SequenceRepeatLayerParams *sequencerepeat;
    CoreML__Specification__ReorganizeDataLayerParams *reorganizedata;
    CoreML__Specification__SliceLayerParams *slice;
    /*
     * Recurrent Layers
     */
    CoreML__Specification__SimpleRecurrentLayerParams *simplerecurrent;
    CoreML__Specification__GRULayerParams *gru;
    CoreML__Specification__UniDirectionalLSTMLayerParams *unidirectionallstm;
    CoreML__Specification__BiDirectionalLSTMLayerParams *bidirectionallstm;
    /*
     * Custom (user-implemented) Layer
     */
    CoreML__Specification__CustomLayerParams *custom;
    /*
     * Control Flow related Layers
     */
    CoreML__Specification__CopyLayerParams *copy;
    CoreML__Specification__BranchLayerParams *branch;
    CoreML__Specification__LoopLayerParams *loop;
    CoreML__Specification__LoopBreakLayerParams *loopbreak;
    CoreML__Specification__LoopContinueLayerParams *loopcontinue;
    CoreML__Specification__RangeStaticLayerParams *rangestatic;
    CoreML__Specification__RangeDynamicLayerParams *rangedynamic;
    /*
     * Element-wise Unary Layers
     */
    CoreML__Specification__ClipLayerParams *clip;
    CoreML__Specification__CeilLayerParams *ceil;
    CoreML__Specification__FloorLayerParams *floor;
    CoreML__Specification__SignLayerParams *sign;
    CoreML__Specification__RoundLayerParams *round;
    CoreML__Specification__Exp2LayerParams *exp2;
    CoreML__Specification__SinLayerParams *sin;
    CoreML__Specification__CosLayerParams *cos;
    CoreML__Specification__TanLayerParams *tan;
    CoreML__Specification__AsinLayerParams *asin;
    CoreML__Specification__AcosLayerParams *acos;
    CoreML__Specification__AtanLayerParams *atan;
    CoreML__Specification__SinhLayerParams *sinh;
    CoreML__Specification__CoshLayerParams *cosh;
    CoreML__Specification__TanhLayerParams *tanh;
    CoreML__Specification__AsinhLayerParams *asinh;
    CoreML__Specification__AcoshLayerParams *acosh;
    CoreML__Specification__AtanhLayerParams *atanh;
    CoreML__Specification__ErfLayerParams *erf;
    CoreML__Specification__GeluLayerParams *gelu;
    /*
     * Element-wise Binary with Broadcasting Support
     */
    CoreML__Specification__EqualLayerParams *equal;
    CoreML__Specification__NotEqualLayerParams *notequal;
    CoreML__Specification__LessThanLayerParams *lessthan;
    CoreML__Specification__LessEqualLayerParams *lessequal;
    CoreML__Specification__GreaterThanLayerParams *greaterthan;
    CoreML__Specification__GreaterEqualLayerParams *greaterequal;
    CoreML__Specification__LogicalOrLayerParams *logicalor;
    CoreML__Specification__LogicalXorLayerParams *logicalxor;
    CoreML__Specification__LogicalNotLayerParams *logicalnot;
    CoreML__Specification__LogicalAndLayerParams *logicaland;
    CoreML__Specification__ModBroadcastableLayerParams *modbroadcastable;
    CoreML__Specification__MinBroadcastableLayerParams *minbroadcastable;
    CoreML__Specification__MaxBroadcastableLayerParams *maxbroadcastable;
    CoreML__Specification__AddBroadcastableLayerParams *addbroadcastable;
    CoreML__Specification__PowBroadcastableLayerParams *powbroadcastable;
    CoreML__Specification__DivideBroadcastableLayerParams *dividebroadcastable;
    CoreML__Specification__FloorDivBroadcastableLayerParams *floordivbroadcastable;
    CoreML__Specification__MultiplyBroadcastableLayerParams *multiplybroadcastable;
    CoreML__Specification__SubtractBroadcastableLayerParams *subtractbroadcastable;
    /*
     * Tensor Manipulations
     */
    CoreML__Specification__TileLayerParams *tile;
    CoreML__Specification__StackLayerParams *stack;
    CoreML__Specification__GatherLayerParams *gather;
    CoreML__Specification__ScatterLayerParams *scatter;
    CoreML__Specification__GatherNDLayerParams *gathernd;
    CoreML__Specification__ScatterNDLayerParams *scatternd;
    CoreML__Specification__SoftmaxNDLayerParams *softmaxnd;
    CoreML__Specification__GatherAlongAxisLayerParams *gatheralongaxis;
    CoreML__Specification__ScatterAlongAxisLayerParams *scatteralongaxis;
    CoreML__Specification__ReverseLayerParams *reverse;
    CoreML__Specification__ReverseSeqLayerParams *reverseseq;
    CoreML__Specification__SplitNDLayerParams *splitnd;
    CoreML__Specification__ConcatNDLayerParams *concatnd;
    CoreML__Specification__TransposeLayerParams *transpose;
    CoreML__Specification__SliceStaticLayerParams *slicestatic;
    CoreML__Specification__SliceDynamicLayerParams *slicedynamic;
    CoreML__Specification__SlidingWindowsLayerParams *slidingwindows;
    CoreML__Specification__TopKLayerParams *topk;
    CoreML__Specification__ArgMinLayerParams *argmin;
    CoreML__Specification__ArgMaxLayerParams *argmax;
    CoreML__Specification__EmbeddingNDLayerParams *embeddingnd;
    CoreML__Specification__BatchedMatMulLayerParams *batchedmatmul;
    /*
     * Tensor Allocation / Reshape-related Operations
     */
    CoreML__Specification__GetShapeLayerParams *getshape;
    CoreML__Specification__LoadConstantNDLayerParams *loadconstantnd;
    CoreML__Specification__FillLikeLayerParams *filllike;
    CoreML__Specification__FillStaticLayerParams *fillstatic;
    CoreML__Specification__FillDynamicLayerParams *filldynamic;
    CoreML__Specification__BroadcastToLikeLayerParams *broadcasttolike;
    CoreML__Specification__BroadcastToStaticLayerParams *broadcasttostatic;
    CoreML__Specification__BroadcastToDynamicLayerParams *broadcasttodynamic;
    CoreML__Specification__SqueezeLayerParams *squeeze;
    CoreML__Specification__ExpandDimsLayerParams *expanddims;
    CoreML__Specification__FlattenTo2DLayerParams *flattento2d;
    CoreML__Specification__ReshapeLikeLayerParams *reshapelike;
    CoreML__Specification__ReshapeStaticLayerParams *reshapestatic;
    CoreML__Specification__ReshapeDynamicLayerParams *reshapedynamic;
    CoreML__Specification__RankPreservingReshapeLayerParams *rankpreservingreshape;
    CoreML__Specification__ConstantPaddingLayerParams *constantpad;
    /*
     * Random Distributions
     */
    CoreML__Specification__RandomNormalLikeLayerParams *randomnormallike;
    CoreML__Specification__RandomNormalStaticLayerParams *randomnormalstatic;
    CoreML__Specification__RandomNormalDynamicLayerParams *randomnormaldynamic;
    CoreML__Specification__RandomUniformLikeLayerParams *randomuniformlike;
    CoreML__Specification__RandomUniformStaticLayerParams *randomuniformstatic;
    CoreML__Specification__RandomUniformDynamicLayerParams *randomuniformdynamic;
    CoreML__Specification__RandomBernoulliLikeLayerParams *randombernoullilike;
    CoreML__Specification__RandomBernoulliStaticLayerParams *randombernoullistatic;
    CoreML__Specification__RandomBernoulliDynamicLayerParams *randombernoullidynamic;
    CoreML__Specification__CategoricalDistributionLayerParams *categoricaldistribution;
    /*
     * Reduction-related Layers:
     */
    CoreML__Specification__ReduceL1LayerParams *reducel1;
    CoreML__Specification__ReduceL2LayerParams *reducel2;
    CoreML__Specification__ReduceMaxLayerParams *reducemax;
    CoreML__Specification__ReduceMinLayerParams *reducemin;
    CoreML__Specification__ReduceSumLayerParams *reducesum;
    CoreML__Specification__ReduceProdLayerParams *reduceprod;
    CoreML__Specification__ReduceMeanLayerParams *reducemean;
    CoreML__Specification__ReduceLogSumLayerParams *reducelogsum;
    CoreML__Specification__ReduceSumSquareLayerParams *reducesumsquare;
    CoreML__Specification__ReduceLogSumExpLayerParams *reducelogsumexp;
    /*
     * Masking / Selection Layers
     */
    CoreML__Specification__WhereNonZeroLayerParams *wherenonzero;
    CoreML__Specification__MatrixBandPartLayerParams *matrixbandpart;
    CoreML__Specification__LowerTriangularLayerParams *lowertriangular;
    CoreML__Specification__UpperTriangularLayerParams *uppertriangular;
    CoreML__Specification__WhereBroadcastableLayerParams *wherebroadcastable;
    /*
     * Normalization Layers
     */
    CoreML__Specification__LayerNormalizationLayerParams *layernormalization;
    CoreML__Specification__NonMaximumSuppressionLayerParams *nonmaximumsuppression;
    /*
     * Following layers are available only after Core ML Specification
     * version >= 5 (iOS >= 14, macOS >= 11.0)
     */
    CoreML__Specification__OneHotLayerParams *onehot;
    CoreML__Specification__CumSumLayerParams *cumsum;
    CoreML__Specification__ClampedReLULayerParams *clampedrelu;
    CoreML__Specification__ArgSortLayerParams *argsort;
    CoreML__Specification__Pooling3DLayerParams *pooling3d;
    CoreML__Specification__GlobalPooling3DLayerParams *globalpooling3d;
    CoreML__Specification__SliceBySizeLayerParams *slicebysize;
    CoreML__Specification__Convolution3DLayerParams *convolution3d;
  };
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_layer__descriptor) \
    , (char *)protobuf_c_empty_string, 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0, CORE_ML__SPECIFICATION__NEURAL_NETWORK_LAYER__LAYER__NOT_SET, {0} }


/*
 **
 * Branching Layer
 * A layer that provides the functionality of branching or an If-Else block.
 * Must have 1 input. There are no outputs as the execution is transferred to either the
 * if or the else branch based on the value of the input.
 * Input is the condition predicate. Must be a scalar (length 1 tensor).
 */
struct  _CoreML__Specification__BranchLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * execute this graph if the absolute value of the input Tensor is greater than 1e-6
   * This must be present.
   */
  CoreML__Specification__NeuralNetwork *ifbranch;
  /*
   **
   * execute this graph if the absolute value of the input Tensor is less than 1e-6
   * This is optional.
   */
  CoreML__Specification__NeuralNetwork *elsebranch;
};
#define CORE_ML__SPECIFICATION__BRANCH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__branch_layer_params__descriptor) \
    , NULL, NULL }


/*
 **
 * Loop Layer
 * A layer that provides the functionality of a "for" loop or a "while" loop.
 * There are either no inputs or 1 input. When an input is present, it corresponds to the maximum loop count,
 * in that case the value of the "maxLoopIterations" field is ignored. Input must be a scalar.
 * (For description below, maxLoopIterations is assumed to be the value of the input, when its present)
 * No outputs are produced. Blobs produced by the condition or the body network are visible in the scope of the overall network.
 * "conditionNetwork" must produce a tensor with the name specified in the "conditionVar" field.
 * There are 3 possible cases for determining the termination condition:
 * Case 1:
 * If there is no "conditionNetwork", in this case the layer corresponds to a pure for loop, which is run "maxLoopIterations" number of times.
 * Equivalent pseudo-code:
 * for loopIterator = 0 : maxLoopIterations
 *      bodyNetwork()
 * Case 2:
 * "conditionNetwork" is present, and "maxLoopIterations" is 0 and there is no input,
 * in this case the layer corresponds to a while loop. Equivalent pseudo-code:
 * conditionVar = conditionNetwork()
 * while conditionVar:
 *      bodyNetwork()
 *      conditionVar = conditionNetwork()
 * Case 3:
 * "conditionNetwork" is provided, and "maxLoopIterations" is positive or there is an input,
 * in this case the layer corresponds to a while loop with a joint condition. Equivalent pseudo-code:
 * loopIterator = 0
 * conditionVar = conditionNetwork()
 * while (conditionVar and loopIterator < maxLoopIterations):
 *      bodyNetwork()
 *      loopIterator = loopIterator + 1
 *      conditionVar = conditionNetwork()
 */
struct  _CoreML__Specification__LoopLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * maximum number of iterations. Ignored if input is present.
   */
  uint64_t maxloopiterations;
  /*
   **
   * This field provides the name of the tensor which is produced by the conditionNetwork
   * and whose value is checked to start/continue/terminate the loop. Value close to 0.0f is treated as False.
   * This field is optional.
   * Must be a non empty string if and only if "conditionNetwork" is present.
   */
  char *conditionvar;
  /*
   **
   * Must generate a tensor with the name provided in the "conditionVar" field.
   * This field is optional.
   * Must be present if and only if "conditionVar" field is a non empty string.
   */
  CoreML__Specification__NeuralNetwork *conditionnetwork;
  /*
   **
   * Body of the loop.
   * This field must be present.
   */
  CoreML__Specification__NeuralNetwork *bodynetwork;
};
#define CORE_ML__SPECIFICATION__LOOP_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__loop_layer_params__descriptor) \
    , 0, (char *)protobuf_c_empty_string, NULL, NULL }


/*
 **
 * Loop break Layer
 * Terminate the loop that has this layer.
 * If present, it should always reside in the "bodyNetwork" of the loop layer
 * No inputs/outputs
 */
struct  _CoreML__Specification__LoopBreakLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOOP_BREAK_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__loop_break_layer_params__descriptor) \
     }


/*
 **
 * Loop Continue Layer
 * Stop the current loop iteration and continue on the next iteration.
 * If present, it should always reside in the "bodyNetwork" of the loop layer
 * No inputs/outputs
 */
struct  _CoreML__Specification__LoopContinueLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOOP_CONTINUE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__loop_continue_layer_params__descriptor) \
     }


/*
 **
 * Copy Layer
 * A layer that copies its input tensor to the output tensor.
 * Must have 1 input and 1 output, with distinct names.
 * This is the only layer that is allowed to re-generate an output that is already present in the neural network prior to this layer,
 * in which case it will overwrite the output tensor.
 */
struct  _CoreML__Specification__CopyLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__COPY_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__copy_layer_params__descriptor) \
     }


/*
 **
 * GreaterThan Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise greater than operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 > x2
 *          or
 *      y = x1 > alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__GreaterThanLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__GREATER_THAN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__greater_than_layer_params__descriptor) \
    , 0 }


/*
 **
 * GreaterEqual Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise greater equal operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 >= x2
 *          or
 *      y = x1 >= alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__GreaterEqualLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__GREATER_EQUAL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__greater_equal_layer_params__descriptor) \
    , 0 }


/*
 **
 * LessThan Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise less than operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 < x2
 *          or
 *      y = x1 < alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__LessThanLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__LESS_THAN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__less_than_layer_params__descriptor) \
    , 0 }


/*
 **
 * LessEqual Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise less equal operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 <= x2
 *          or
 *      y = x1 <= alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__LessEqualLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__LESS_EQUAL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__less_equal_layer_params__descriptor) \
    , 0 }


/*
 **
 * Equal Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise equal operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 == x2
 *          or
 *      y = x1 == alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__EqualLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__EQUAL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__equal_layer_params__descriptor) \
    , 0 }


/*
 **
 * NotEqual Layer
 * Either 1 or 2 inputs.
 * Produces 1 output.
 * Perform elementwise not equal operation.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = x1 != x2
 *          or
 *      y = x1 != alpha, if only one input is provided
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__NotEqualLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Compare to the scalar value provided here if there is 1 input
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__NOT_EQUAL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__not_equal_layer_params__descriptor) \
    , 0 }


/*
 **
 * LogicalAnd Layer
 * Must have 2 inputs, produces 1 output.
 * Perform elementwise logical AND operation.
 * Input is considered False if equal to 0.0f otherwise True.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = AND(x1, x2)
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__LogicalAndLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOGICAL_AND_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__logical_and_layer_params__descriptor) \
     }


/*
 **
 * LogicalOr Layer
 * Must have 2 inputs, produces 1 output.
 * Perform elementwise logical OR operation.
 * Input is considered False if equal to 0.0f otherwise True.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = OR(x1, x2)
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__LogicalOrLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOGICAL_OR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__logical_or_layer_params__descriptor) \
     }


/*
 **
 * LogicalXor Layer
 * Must have 2 inputs, produces 1 output.
 * Perform elementwise logical XOR operation.
 * Input is considered False if equal to 0.0f otherwise True.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = XOR(x1, x2)
 * Broadcasting is supported.
 */
struct  _CoreML__Specification__LogicalXorLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOGICAL_XOR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__logical_xor_layer_params__descriptor) \
     }


/*
 **
 * LogicalNot Layer
 * Must have 1 input, produces 1 output.
 * Perform elementwise logical NOT operation.
 * Input is considered False if equal to 0.0f otherwise True.
 * Output is 1.0f if the condition is true otherwise 0.0f.
 * .. code::
 *      y = NOT(x)
 */
struct  _CoreML__Specification__LogicalNotLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__LOGICAL_NOT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__logical_not_layer_params__descriptor) \
     }


struct  _CoreML__Specification__BorderAmounts__EdgeSizes
{
  ProtobufCMessage base;
  /*
   **
   * The amount to be padded or cropped from the beginning.
   */
  uint64_t startedgesize;
  /*
   **
   * The amount to be padded or cropped from the end.
   */
  uint64_t endedgesize;
};
#define CORE_ML__SPECIFICATION__BORDER_AMOUNTS__EDGE_SIZES__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__border_amounts__edge_sizes__descriptor) \
    , 0, 0 }


/*
 **
 * Specifies the amount of spatial border to be either padded or cropped.
 * For padding:
 * .. code::
 *     H_out = borderAmounts[0].startEdgeSize + H_in + borderAmounts[0].endEdgeSize
 *     W_out = borderAmounts[1].startEdgeSize + W_in + borderAmounts[1].endEdgeSize
 *     topPaddingAmount == Height startEdgeSize
 *     bottomPaddingAmount == Height endEdgeSize
 *     leftPaddingAmount == Width startEdgeSize
 *     rightPaddingAmount == Width endEdgeSize
 * For cropping:
 * .. code::
 *     H_out = (-borderAmounts[0].startEdgeSize) + H_in + (-borderAmounts[0].endEdgeSize)
 *     W_out = (-borderAmounts[1].startEdgeSize) + W_in + (-borderAmounts[1].endEdgeSize)
 *     topCropAmount == Height startEdgeSize
 *     bottomCropAmount == Height endEdgeSize
 *     leftCropAmount == Width startEdgeSize
 *     rightCropAmount == Width endEdgeSize
 */
struct  _CoreML__Specification__BorderAmounts
{
  ProtobufCMessage base;
  /*
   **
   * The border amounts.
   * This must be length 2 in the order ``[H, W]``.
   */
  size_t n_borderamounts;
  CoreML__Specification__BorderAmounts__EdgeSizes **borderamounts;
};
#define CORE_ML__SPECIFICATION__BORDER_AMOUNTS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__border_amounts__descriptor) \
    , 0,NULL }


/*
 **
 * Specifies the type of padding to be used with Convolution/Deconvolution and Pooling layers.
 * After padding, input spatial shape: ``[H_in, W_in]``, gets modified to the
 * output spatial shape ``[H_out, W_out]``.
 * .. code::
 *      topPaddingAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
 *      bottomPaddingAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
 *      leftPaddingAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
 *      rightPaddingAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
 * With Convolution or Pooling:
 * .. code::
 *    H_out = int_division_round_down((H_in + topPaddingAmount + bottomPaddingAmount - KernelSize[0]),stride[0]) + 1
 * which is same as:
 * .. code::
 *    H_out = int_division_round_up((H_in + topPaddingAmount + bottomPaddingAmount - KernelSize[0] + 1),stride[0])
 * With Deconvolution:
 * .. code::
 *    H_out = (H_in-1) * stride[0] + kernelSize[0] - (topPaddingAmount + bottomPaddingAmount)
 * The equivalent expressions hold true for ``W_out`` as well.
 * By default, the values of ``paddingAmounts`` are set to ``0``,
 * which results in a "true" valid padding.
 * If non-zero values are provided for ``paddingAmounts``,
 * "valid" convolution/pooling is performed within the spatially expanded input.
 */
struct  _CoreML__Specification__ValidPadding
{
  ProtobufCMessage base;
  CoreML__Specification__BorderAmounts *paddingamounts;
};
#define CORE_ML__SPECIFICATION__VALID_PADDING__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__valid_padding__descriptor) \
    , NULL }


/*
 **
 * Specifies the type of padding to be used with Convolution/Deconvolution and pooling layers.
 * After padding, input spatial shape: ``[H_in, W_in]``, gets modified to the
 * output spatial shape ``[H_out, W_out]``.
 * With Convolution or pooling:
 * .. code::
 *      H_out = int_division_round_up(H_in,stride[0])
 *      W_out = int_division_round_up(W_in,stride[1])
 * This is achieved by using the following padding amounts:
 * .. code::
 *     totalPaddingHeight = max(0,(H_out-1) * stride[0] + KernelSize[0] - Hin)
 *     totalPaddingWidth = max(0,(W_out-1) * stride[1] + KernelSize[1] - Win)
 * There are two modes of asymmetry:
 * ``BOTTOM_RIGHT_HEAVY``, and ``TOP_LEFT_HEAVY``.
 * If the mode is ``BOTTOM_RIGHT_HEAVY``:
 * .. code::
 *     topPaddingAmount = floor(totalPaddingHeight / 2)
 *     bottomPaddingAmount = totalPaddingHeight - topPaddingAmount
 *     leftPaddingAmount = floor(totalPaddingWidth / 2)
 *     rightPaddingAmount = totalPaddingWidth - leftPaddingAmount
 * If the mode is ``TOP_LEFT_HEAVY``:
 * .. code::
 *     bottomPaddingAmount = floor(totalPaddingHeight / 2)
 *     topPaddingAmount = totalPaddingHeight - bottomPaddingAmount
 *     rightPaddingAmount = floor(totalPaddingWidth / 2)
 *     leftPaddingAmount = totalPaddingWidth - rightPaddingAmount
 * With Deconvolution:
 * .. code::
 *    H_out = H_in * stride[0]
 *    W_out = W_in * stride[1]
 */
struct  _CoreML__Specification__SamePadding
{
  ProtobufCMessage base;
  CoreML__Specification__SamePadding__SamePaddingMode asymmetrymode;
};
#define CORE_ML__SPECIFICATION__SAME_PADDING__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__same_padding__descriptor) \
    , CORE_ML__SPECIFICATION__SAME_PADDING__SAME_PADDING_MODE__BOTTOM_RIGHT_HEAVY }


/*
 **
 * Specifies how grid points are sampled from an interval.
 * Without the loss of generality, assume the interval to be [0, X-1] from which N points are to be sampled.
 * Here X may correspond to an input image's height or width.
 * All the methods can be expressed in terms of numpy's linspace function, along with the constraint that grid points have to lie in the interval [0, X-1].
 * Note: numpy.linspace(start = start, end = end, num = N, endpoint = True) corresponds to sampling
 * N points uniformly from the interval [start, end], endpoints included.
 * The methods vary in how the ``start`` and ``end`` values are computed.
 */
struct  _CoreML__Specification__SamplingMode
{
  ProtobufCMessage base;
  CoreML__Specification__SamplingMode__Method samplingmethod;
};
#define CORE_ML__SPECIFICATION__SAMPLING_MODE__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sampling_mode__descriptor) \
    , CORE_ML__SPECIFICATION__SAMPLING_MODE__METHOD__STRICT_ALIGN_ENDPOINTS_MODE }


/*
 **
 * Specifies the convention used to specify four bounding box coordinates for an image of size (Height, Width).
 * The (0,0) coordinate corresponds to the top-left corner of the image.
 */
struct  _CoreML__Specification__BoxCoordinatesMode
{
  ProtobufCMessage base;
  CoreML__Specification__BoxCoordinatesMode__Coordinates boxmode;
};
#define CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__box_coordinates_mode__descriptor) \
    , CORE_ML__SPECIFICATION__BOX_COORDINATES_MODE__COORDINATES__CORNERS_HEIGHT_FIRST }


/*
 **
 * Weights for layer parameters.
 * Weights are stored as repeated floating point numbers
 * using row-major ordering
 * and can represent 1-, 2-, 3-, or 4-dimensional data.
 */
struct  _CoreML__Specification__WeightParams
{
  ProtobufCMessage base;
  /*
   **
   * Values specified in single / float / FP32 precision.
   */
  size_t n_floatvalue;
  float *floatvalue;
  /*
   **
   * Values in 16-bit half precision floating point.
   */
  ProtobufCBinaryData float16value;
  /*
   **
   * Raw value specification for quantized lower precisions.
   * This field is interpreted as uintN, where N is the number of bits in quantization.
   * E.g. if n=8, the field is interpreted as an array of UINT8.
   * Use this field for quantized parameters unless specifically noted to use
   * int8RawValue.
   */
  ProtobufCBinaryData rawvalue;
  /*
   **
   * Field to be used if int8DynamicQuantize is set in the parent layer.
   * Cannot be set if rawValue is also set.
   * The values in this field are interpreted as INT8.
   * If this field is set, following conditions must hold true:
   * * QuantizationType == LinearQuantizationParams, such that
   *   * size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
   */
  ProtobufCBinaryData int8rawvalue;
  /*
   **
   * Quantization related parameters.
   */
  CoreML__Specification__QuantizationParams *quantization;
  protobuf_c_boolean isupdatable;
};
#define CORE_ML__SPECIFICATION__WEIGHT_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__weight_params__descriptor) \
    , 0,NULL, {0,NULL}, {0,NULL}, {0,NULL}, NULL, 0 }


typedef enum {
  CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__QUANTIZATION_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__QUANTIZATION_TYPE_LINEAR_QUANTIZATION = 101,
  CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__QUANTIZATION_TYPE_LOOKUP_TABLE_QUANTIZATION = 102
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__QUANTIZATION_TYPE)
} CoreML__Specification__QuantizationParams__QuantizationTypeCase;

/*
 **
 * Quantization parameters.
 */
struct  _CoreML__Specification__QuantizationParams
{
  ProtobufCMessage base;
  uint64_t numberofbits;
  CoreML__Specification__QuantizationParams__QuantizationTypeCase quantization_type_case;
  union {
    CoreML__Specification__LinearQuantizationParams *linearquantization;
    CoreML__Specification__LookUpTableQuantizationParams *lookuptablequantization;
  };
};
#define CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__quantization_params__descriptor) \
    , 0, CORE_ML__SPECIFICATION__QUANTIZATION_PARAMS__QUANTIZATION_TYPE__NOT_SET, {0} }


struct  _CoreML__Specification__LinearQuantizationParams
{
  ProtobufCMessage base;
  /*
   **
   * Stores scale and bias values corresponding to the quantized weights.
   * Must be an array of 1 element, or an array of C elements, where C
   * is number of output channels. For recurrent layers it is equal to
   * the output vector size.
   * Relationship between quantized weights, unquantized weights, scale and bias:
   * W_unquantized = W_quantized * scale + bias
   */
  size_t n_scale;
  float *scale;
  size_t n_bias;
  float *bias;
};
#define CORE_ML__SPECIFICATION__LINEAR_QUANTIZATION_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__linear_quantization_params__descriptor) \
    , 0,NULL, 0,NULL }


struct  _CoreML__Specification__LookUpTableQuantizationParams
{
  ProtobufCMessage base;
  /*
   * Stores look-up table quantization values. Must be an array of
   *(2^numberOfBits) Elements.
   */
  size_t n_floatvalue;
  float *floatvalue;
};
#define CORE_ML__SPECIFICATION__LOOK_UP_TABLE_QUANTIZATION_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__look_up_table_quantization_params__descriptor) \
    , 0,NULL }


typedef enum {
  CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__CONVOLUTION_PADDING_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__CONVOLUTION_PADDING_TYPE_VALID = 50,
  CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__CONVOLUTION_PADDING_TYPE_SAME = 51
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__CONVOLUTION_PADDING_TYPE)
} CoreML__Specification__ConvolutionLayerParams__ConvolutionPaddingTypeCase;

/*
 **
 * A layer that performs spatial convolution or deconvolution.
 * .. code::
 *      y = ConvolutionLayer(x)
 * Requires 1 or 2 inputs and produces 1 output.
 * Input
 *    First Input:
 *      A blob with rank greater than or equal to 4.
 *      Rank 4 blob represents [Batch, channels, height, width].
 *      For ranks greater than 4, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 *     From Core ML specification version 4 onwards (iOS >= 13, macOS >= 10.15).
 *     convolution layer can have 2 inputs, in which case the second input is
 *     the blob representing the weights. This is allowed when "isDeconvolution" = False.
 *     The weight blob should have shape
 *     ``[outputChannels, kernelChannels, kernelHeight, kernelWidth]``,
 *     where kernelChannels == inputChannels / nGroups.
 * Output
 *   Rank is same as the input. e.g.: for rank 4 input, output shape is [B, C_out, H_out, W_out]
 * If ``dilationFactor`` is not 1, effective kernel size is
 * modified as follows:
 * .. code::
 *      KernelSize[0] <-- (kernelSize[0]-1) * dilationFactor[0] + 1
 *      KernelSize[1] <-- (kernelSize[1]-1) * dilationFactor[1] + 1
 * Type of padding can be ``valid`` or ``same``. Output spatial dimensions depend on the
 * the type of padding. For details, refer to the descriptions of the messages "ValidPadding"
 * and "SamePadding". Padded values are all zeros.
 * For Deconvolution, ``ConvolutionPaddingType`` (``valid`` or ``same``) is ignored when ``outputShape`` is set.
 */
struct  _CoreML__Specification__ConvolutionLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The number of kernels.
   * Same as ``C_out`` used in the layer description.
   */
  uint64_t outputchannels;
  /*
   **
   * Channel dimension of the kernels.
   * Must be equal to ``inputChannels / nGroups``, if isDeconvolution == False
   * Must be equal to ``inputChannels``, if isDeconvolution == True
   */
  uint64_t kernelchannels;
  /*
   **
   * Group convolution, i.e. weight reuse along channel axis.
   * Input and kernels are divided into g groups
   * and convolution / deconvolution is applied within the groups independently.
   * If not set or 0, it is set to the default value 1.
   */
  uint64_t ngroups;
  /*
   **
   * Must be length 2 in the order ``[H, W]``.
   * If not set, default value ``[3, 3]`` is used.
   */
  size_t n_kernelsize;
  uint64_t *kernelsize;
  /*
   **
   * Must be length 2 in the order ``[H, W]``.
   * If not set, default value ``[1, 1]`` is used.
   */
  size_t n_stride;
  uint64_t *stride;
  /*
   **
   * Must be length 2 in order ``[H, W]``.
   * If not set, default value ``[1, 1]`` is used.
   * It is ignored if ``isDeconvolution == true``.
   */
  size_t n_dilationfactor;
  uint64_t *dilationfactor;
  /*
   **
   * Flag to specify whether it is a deconvolution layer.
   */
  protobuf_c_boolean isdeconvolution;
  /*
   **
   * Flag to specify whether a bias is to be added or not.
   */
  protobuf_c_boolean hasbias;
  /*
   **
   * Weights associated with this layer.
   * If convolution (``isDeconvolution == false``), weights have the shape
   * ``[outputChannels, kernelChannels, kernelHeight, kernelWidth]``, where kernelChannels == inputChannels / nGroups
   * If deconvolution (``isDeconvolution == true``) weights have the shape
   * ``[kernelChannels, outputChannels / nGroups, kernelHeight, kernelWidth]``, where kernelChannels == inputChannels
   */
  CoreML__Specification__WeightParams *weights;
  /*
   * / Must be of size [outputChannels].
   */
  CoreML__Specification__WeightParams *bias;
  /*
   **
   * The output shape, which has length 2 ``[H_out, W_out]``.
   * This is used only for deconvolution (``isDeconvolution == true``).
   * If not set, the deconvolution output shape is calculated
   * based on ``ConvolutionPaddingType``.
   */
  size_t n_outputshape;
  uint64_t *outputshape;
  CoreML__Specification__ConvolutionLayerParams__ConvolutionPaddingTypeCase convolution_padding_type_case;
  union {
    CoreML__Specification__ValidPadding *valid;
    CoreML__Specification__SamePadding *same;
  };
};
#define CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__convolution_layer_params__descriptor) \
    , 0, 0, 0, 0,NULL, 0,NULL, 0,NULL, 0, 0, NULL, NULL, 0,NULL, CORE_ML__SPECIFICATION__CONVOLUTION_LAYER_PARAMS__CONVOLUTION_PADDING_TYPE__NOT_SET, {0} }


/*
 **
 * A layer that performs a 3-dimensional convolution.
 * .. code::
 *      y = Convolution3DLayer(x)
 * Input
 *    A blob of rank 5.
 *    The input blob's shape should be ``[batch, channels, depth, height, width]``.
 * Fields
 *   The bias field, if set, should have shape of ``[channelsOut]``.
 * Output
 *   A blob of rank 5.
 *   The output blob's shape is ``[batch, channelsOut, depthOut, heightOut, widthOut]``.
 * Type of padding can be ``custom``, ``valid``, or ``same``. Padded values are all zeros.
 * Output spatial dimensions depend on the type of padding. For details, refer to the
 * descriptions of the ``PaddingType`` field of this ``Convolution3DLayerParams`` message.
 * Example
 *   For example, given an input of size ``[1, 3, 3, 8, 8]``, a stride of 2 in each dimension,
 *   a kernel of 3 in each dimension, 2 output channels, and ``same`` padding, this layer will
 *   compute the total padding applied in the depth, height, and width dimensions to be 2, 1, and 1,
 *   respectively. The depth padding is even and will be applied equally to both sides of the depth
 *   dimension. Since the height and width padding values are odd, they'll be applied to the
 *   bottom/right of the height/width dimensions. Thus, the padding applied to the input will be
 *   ``[1, 1, 0, 1, 0, 1]`` (front, back, top, bottom, left, right). Finally, the output produced
 *   will have size ``[1, 2, 2, 4, 4]``.
 */
struct  _CoreML__Specification__Convolution3DLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The number of channels in the output (channelsOut). Must be a positive integer.
   */
  int32_t outputchannels;
  /*
   **
   * The number of channels in the input (channels). Must be a positive integer.
   */
  int32_t inputchannels;
  /*
   **
   * Group convolution, i.e., weight reuse along the channel axis.
   * It must evenly divide both the number of input and output channels and be at most the number
   * of input channels (a depthwise convolution).
   * Input and kernels are divided into g groups and convolution is applied within the groups
   * independently.
   */
  int32_t ngroups;
  /*
   * Depth of the convolution kernel. Must be a positive integer.
   */
  int32_t kerneldepth;
  /*
   * Height of the convolution kernel. Must be a positive integer.
   */
  int32_t kernelheight;
  /*
   * Width of the convolution kernel. Must be a positive integer.
   */
  int32_t kernelwidth;
  /*
   * Stride along the depth direction. Must be a positive integer.
   */
  int32_t stridedepth;
  /*
   * Stride along the height direction. Must be a positive integer.
   */
  int32_t strideheight;
  /*
   * Stride along the width direction. Must be a positive integer.
   */
  int32_t stridewidth;
  /*
   * Dilation along the depth direction. Must be a positive integer.
   */
  int32_t dilationdepth;
  /*
   * Dilation along the height direction. Must be a positive integer.
   */
  int32_t dilationheight;
  /*
   * Dilation along the width direction. Must be a positive integer.
   */
  int32_t dilationwidth;
  /*
   **
   * Flag to specify whether a bias is to be added or not.
   * If false, then no bias is added.
   */
  protobuf_c_boolean hasbias;
  /*
   **
   * Weights associated with this layer.
   * Weights have the shape
   * if deconvolution == False
   * ``[outputChannels, kernelChannels, kernelDepth, kernelHeight, kernelWidth]``, where
   * kernelChannels == inputChannels / nGroups
   * else if deconvolution == True
   * ``[outputChannels / nGroups, kernelChannels, kernelDepth, kernelHeight, kernelWidth]``, where
   */
  CoreML__Specification__WeightParams *weights;
  /*
   **
   * Must be of size ``[outputChannels]``.
   */
  CoreML__Specification__WeightParams *bias;
  CoreML__Specification__Convolution3DLayerParams__PaddingType paddingtype;
  /*
   * Padding before the input in the depth direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingfront;
  /*
   * Padding after the input in the depth direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingback;
  /*
   * Padding before the input in the height direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingtop;
  /*
   * Padding after the input in the height direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingbottom;
  /*
   * Padding before the input in the width direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingleft;
  /*
   * Padding after the input in the width direction. Must be zero or a positive integer.
   * Used when the `PaddingType` is `CustomPadding`, otherwise ignored by other padding types.
   */
  int32_t custompaddingright;
  /*
   * Flag to specify if this is Convolution Transpose or not.
   */
  protobuf_c_boolean isdeconvolution;
  /*
   * The output shape, which has length 3 ``[D_out, H_out, W_out]``.
   * This is used only for deconvolution (``isDeconvolution == true``).
   * If not set, the deconvolution output shape is calculated
   * based on ``PaddingType``.
   */
  size_t n_outputshape;
  uint64_t *outputshape;
};
#define CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__convolution3_dlayer_params__descriptor) \
    , 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NULL, NULL, CORE_ML__SPECIFICATION__CONVOLUTION3_DLAYER_PARAMS__PADDING_TYPE__CUSTOM, 0, 0, 0, 0, 0, 0, 0, 0,NULL }


/*
 **
 * A layer that performs a matrix-vector or matrix-matrix product.
 * This is equivalent to a fully-connected, or dense layer.
 * The weight parameters correspond to a matrix of dimensions (inputChannels, outputChannels) i.e. (C_in, C_out)
 * .. code::
 *      y = InnerProductLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *      Input can have rank 1 to rank 5. This is how it is reshaped in to the matrix (for rank > 1):
 *      rank 1 (x1) : in this case, the layer corresponds to a matrix-vector product. x1 must be equal to C_in
 *      rank 2 (x1, x2): x2 must be equal to C_in
 *      rank 3 (x1, x2, x3) --> (x1 * x2, x3). x3 must be equal to C_in
 *      rank 4 (x1, x2, x3, x4) ---> (x1, x2 * x3 * x4). x2 * x3 * x4 must be equal to C_in
 *      rank 5 (x1, x2, x3, x4, x5) ---> (x1 * x2, x3 * x4 * x5). x3 * x4 * x5 must be equal to C_in
 * Output
 *      Output rank is same as the input rank
 *      rank 1: (C_out)
 *      rank 2: (x1, C_out)
 *      rank 3: (x1, x2, C_out)
 *      rank 4: (x1, C_out, 1, 1)
 *      rank 5: (x1, x2, C_out, 1, 1)
 */
struct  _CoreML__Specification__InnerProductLayerParams
{
  ProtobufCMessage base;
  /*
   * / Input size: C_in.
   */
  uint64_t inputchannels;
  /*
   * / Output size: C_out.
   */
  uint64_t outputchannels;
  /*
   * / Whether a bias is added or not.
   */
  protobuf_c_boolean hasbias;
  /*
   * / Weight matrix [C_out, C_in].
   */
  CoreML__Specification__WeightParams *weights;
  /*
   * / Bias vector [C_out].
   */
  CoreML__Specification__WeightParams *bias;
  /*
   **
   * If set, this layer, at runtime, quantizes the floating point input blob to int8 before applying an
   * inner product using INT8 weight matrix parameters, as provided in weights->int8RawValue. The
   * result is then dequantized.
   * Requires:
   * * hasBias == false
   * * QuantizationType == LinearQuantizationParams, such that
   *   * size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
   * * numberOfBits == 8
   * * weights->rawValue_size to be empty
   */
  protobuf_c_boolean int8dynamicquantize;
};
#define CORE_ML__SPECIFICATION__INNER_PRODUCT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__inner_product_layer_params__descriptor) \
    , 0, 0, 0, NULL, NULL, 0 }


/*
 **
 * A layer that performs a matrix lookup and optionally adds a bias.
 * The weights matrix is stored with dimensions [outputChannels, inputDim].
 * .. code::
 *      y = EmbeddingLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     Input values must be in the range ``[0, inputDim - 1]``.
 *     Input must have rank equal to 4 or 5, such that the last 3 dimensions are all 1.
 *     rank 4: shape (x1, 1, 1, 1). x1 is effectively the batch/sequence length.
 *     rank 5: shape (x1, x2 , 1, 1, 1). x1 * x2 is effectively the combined batch/sequence length.
 * Output
 *      Output rank is same as the input rank. Please see input description above.
 *      rank 4: shape (x1, outputChannels, 1, 1)
 *      rank 5: shape (x1, x2, outputChannels, 1, 1)
 */
struct  _CoreML__Specification__EmbeddingLayerParams
{
  ProtobufCMessage base;
  /*
   * / Size of the input dictionary.
   */
  uint64_t inputdim;
  /*
   * / Size of the output vectors.
   */
  uint64_t outputchannels;
  /*
   * / Whether a bias is added or not.
   */
  protobuf_c_boolean hasbias;
  /*
   * / 2-D weights of dimensions [outputChannels, inputDim].
   */
  CoreML__Specification__WeightParams *weights;
  /*
   * / Bias of size [outputChannels].
   */
  CoreML__Specification__WeightParams *bias;
};
#define CORE_ML__SPECIFICATION__EMBEDDING_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__embedding_layer_params__descriptor) \
    , 0, 0, 0, NULL, NULL }


/*
 **
 * A layer that performs a matrix lookup and optionally adds a bias.
 * The weights matrix is stored with dimensions [embeddingSize, vocabSize].
 * .. code::
 *      y = EmbeddingNDLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     Input values must be in the range ``[0, vocabSize - 1]``.
 *     Input must have rank at least 2. The last dimension must always be 1.
 *     rank 2: shape (x1, 1). x1 is the batch/sequence length.
 *     rank 3: shape (x1, x2, 1). x1 * x2 is effectively the combined batch/sequence length.
 *     rank 4: shape (x1, x2, x3, 1). x1 * x2 * x2 is effectively the combined batch/sequence length.
 *     rank 5: shape (x1, x2 , x3, x4, 1). x1 * x2 * x3 * x4 is effectively the combined batch/sequence length.
 * Output
 *      Output rank is same as the input rank. Please see input description above.
 *      rank 2: shape (x1, embeddingSize)
 *      rank 3: shape (x1, x2, embeddingSize)
 *      rank 4: shape (x1, x2, x3, embeddingSize)
 *      rank 5: shape (x1, x2, x3, x4, embeddingSize)
 */
struct  _CoreML__Specification__EmbeddingNDLayerParams
{
  ProtobufCMessage base;
  /*
   * / Size of the input dictionary.
   */
  uint64_t vocabsize;
  /*
   * / Size of the output vectors.
   */
  uint64_t embeddingsize;
  /*
   * / Whether a bias is added or not.
   */
  protobuf_c_boolean hasbias;
  /*
   * / 2-D weights of dimensions [embeddingSize, vocabSize].
   */
  CoreML__Specification__WeightParams *weights;
  /*
   * / Bias of size [embeddingSize].
   */
  CoreML__Specification__WeightParams *bias;
};
#define CORE_ML__SPECIFICATION__EMBEDDING_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__embedding_ndlayer_params__descriptor) \
    , 0, 0, 0, NULL, NULL }


/*
 **
 * A layer that performs batch normalization,
 * which is performed along axis = -3,
 * and repeated along the other axes, if present.
 * .. code::
 *      y = BatchnormLayer(x)
 * Requires 1 input and produces 1 output.
 * This operation is described by the following formula:
 * .. math::
 *     y_i = \gamma_i \dfrac{ (x_i - \mu_i)}{\sqrt{\sigma_i^2 + \epsilon}} + \beta_i \;,\;i=1,....,C
 * Input
 *     A blob with rank greater than equal to 3.
 *     Example: Rank 4 blob represents [Batch, channels, height, width]
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 */
struct  _CoreML__Specification__BatchnormLayerParams
{
  ProtobufCMessage base;
  /*
   * / Size of the channel dimension in the input.
   */
  uint64_t channels;
  /*
   **
   * If ``computeMeanVar == true``,
   * the mean and variance are calculated from either
   * the single input instance, if ``instanceNormalization == true``,
   * or the whole batch, if ``instanceNormalization = false``.
   * and the values provided in parameters "mean" and "variance" are ignored.
   */
  protobuf_c_boolean computemeanvar;
  protobuf_c_boolean instancenormalization;
  /*
   **
   * A small constant to avoid division by 0 while normalizing by variance.
   * Defaults to ``1e-5`` if not set or set to ``0``.
   */
  float epsilon;
  /*
   * / Parameter of length [channels]
   */
  CoreML__Specification__WeightParams *gamma;
  /*
   * / Parameter of length [channels]
   */
  CoreML__Specification__WeightParams *beta;
  /*
   * / Parameter of length [channels]
   */
  CoreML__Specification__WeightParams *mean;
  /*
   * / Parameter of length [channels]
   */
  CoreML__Specification__WeightParams *variance;
};
#define CORE_ML__SPECIFICATION__BATCHNORM_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__batchnorm_layer_params__descriptor) \
    , 0, 0, 0, 0, NULL, NULL, NULL, NULL }


struct  _CoreML__Specification__PoolingLayerParams__ValidCompletePadding
{
  ProtobufCMessage base;
  /*
   **
   * Must be length 2 in order ``[H, W]``.
   * If not set, value ``[0, 0]`` is used.
   */
  size_t n_paddingamounts;
  uint64_t *paddingamounts;
};
#define CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__VALID_COMPLETE_PADDING__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__pooling_layer_params__valid_complete_padding__descriptor) \
    , 0,NULL }


typedef enum {
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE_VALID = 30,
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE_SAME = 31,
  CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE_INCLUDE_LAST_PIXEL = 32
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE)
} CoreML__Specification__PoolingLayerParams__PoolingPaddingTypeCase;

/*
 **
 * A spatial pooling layer.
 * .. code::
 *      y = PoolingLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank greater than equal to 4.
 *     Rank 4 blob represents [Batch, channels, height, width]
 *     For ranks greater than 4, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Rank is same as the input. e.g.: for rank 4 input, output shape is [B, C, H_out, W_out]
 * Padding options are similar to ``ConvolutionLayerParams``
 * with the additional option of ``ValidCompletePadding`` (``includeLastPixel``),
 * which ensures that the last application of the kernel
 * always includes the last pixel of the input image, if there is padding.
 * .. code::
 *     H_out = ceil(float(H_in + 2 * paddingAmounts[0] - kernelSize[0])/float(Stride[0])) + 1
 *     if (paddingAmounts[0] > 0 or paddingAmounts[1] > 0)
 *          if ((H_out - 1) * Stride >= H_in + paddingAmounts[0]) {
 *              H_out = H_out - 1
 *          }
 *     }
 * The equivalent expressions hold true for ``W_out`` as well.
 * Only symmetric padding is supported with this option.
 */
struct  _CoreML__Specification__PoolingLayerParams
{
  ProtobufCMessage base;
  /*
   * / Type of pooling operation.
   */
  CoreML__Specification__PoolingLayerParams__PoolingType type;
  /*
   **
   * Must be length 2 in the order ``[H, W]``.
   * If not set, default value ``[3, 3]`` is used.
   */
  size_t n_kernelsize;
  uint64_t *kernelsize;
  /*
   **
   * Must be length 2 in the order ``[H, W]``.
   * If not set, default value ``[1, 1]`` is used.
   */
  size_t n_stride;
  uint64_t *stride;
  /*
   **
   * If true, padded values are excluded from the count (denominator)
   * when computing average pooling.
   */
  protobuf_c_boolean avgpoolexcludepadding;
  /*
   **
   * If true, global pooling is performed.
   * Kernel size is inferred from the input data spatial dimensions.
   */
  protobuf_c_boolean globalpooling;
  CoreML__Specification__PoolingLayerParams__PoolingPaddingTypeCase pooling_padding_type_case;
  union {
    CoreML__Specification__ValidPadding *valid;
    CoreML__Specification__SamePadding *same;
    CoreML__Specification__PoolingLayerParams__ValidCompletePadding *includelastpixel;
  };
};
#define CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__pooling_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_TYPE__MAX, 0,NULL, 0,NULL, 0, 0, CORE_ML__SPECIFICATION__POOLING_LAYER_PARAMS__POOLING_PADDING_TYPE__NOT_SET, {0} }


/*
 * A layer to pool three spatial dimensions
 * Input
 *      A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
 * Output
 *      Rank is same as the input: A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
 * Requires 1 input and produces 1 output.
 * For example, given an input of shape (1,1,2,3,3):
 *        +----+----+----+
 *      / | 10 | 11 | 12 |
 *     /  +----+----+----+
 *    /   | 13 | 14 | 15 |
 *   /    +----+----+----+
 *  /     | 16 | 17 | 18 |
 * /      +----+----+----+
 * +----+----+----+      /
 * |  1 |  2 |  3 |     /
 * +----+----+----+    /
 * |  4 |  5 |  6 |   /
 * +----+----+----+  /
 * |  7 |  8 |  9 | /
 * +----+----+----+
 * And applying MAX pooling using:
 *      Kernel: 2x2x2
 *      Stride: 1x1x1
 *      Valid Padding
 * We expect to get an output with shape: (1,1,1,2,2) and value:
 * +----+----+
 * | 14 | 15 |
 * +----+----+
 * | 17 | 18 |
 * +----+----+
 */
struct  _CoreML__Specification__Pooling3DLayerParams
{
  ProtobufCMessage base;
  /*
   * Whether to use Max or Average
   */
  CoreML__Specification__Pooling3DLayerParams__PoolingType3D type;
  /*
   * Depth of the pooling region.
   */
  int32_t kerneldepth;
  /*
   * Height of the pooling region.
   */
  int32_t kernelheight;
  /*
   * Width of the pooling region.
   */
  int32_t kernelwidth;
  /*
   * Stride along the depth direction
   */
  int32_t stridedepth;
  /*
   * Stride along the height direction
   */
  int32_t strideheight;
  /*
   * Stride along the width direction
   */
  int32_t stridewidth;
  CoreML__Specification__Pooling3DLayerParams__Pooling3DPaddingType paddingtype;
  /*
   * Padding before the input in the depth direction.
   */
  int32_t custompaddingfront;
  /*
   * Padding after the input in the depth direction.
   */
  int32_t custompaddingback;
  /*
   * Padding before the input in the height direction.
   */
  int32_t custompaddingtop;
  /*
   * Padding after the input in the height direction.
   */
  int32_t custompaddingbottom;
  /*
   * Padding before the input in the width direction.
   */
  int32_t custompaddingleft;
  /*
   * Padding after the input in the width direction.
   */
  int32_t custompaddingright;
  /*
   * If true, exclude zeros from padding in Average pooling.  Meaningless in Max Pooling.
   */
  protobuf_c_boolean countexcludepadding;
};
#define CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__pooling3_dlayer_params__descriptor) \
    , CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING_TYPE3_D__MAX, 0, 0, 0, 0, 0, 0, CORE_ML__SPECIFICATION__POOLING3_DLAYER_PARAMS__POOLING3_DPADDING_TYPE__CUSTOM, 0, 0, 0, 0, 0, 0, 0 }


/*
 * A layer to pool three spatial dimensions down to one value.
 * This behaves like a special case of Pooling3DLayerParams in which
 * the Kernel is the size of the input and there is no padding.
 * Input
 *      A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
 * Output
 *      Rank is same as the input: A blob with rank equal to 5, representing [Batch, channels, depth, height, width].
 *      Depth, height, and width of the output will always be 1.
 * Requires 1 input and produces 1 output.
 * For example, given an input of shape (1,1,2,3,3):
 *        +----+----+----+
 *      / | 10 | 11 | 12 |
 *     /  +----+----+----+
 *    /   | 13 | 14 | 15 |
 *   /    +----+----+----+
 *  /     | 16 | 17 | 18 |
 * /      +----+----+----+
 * +----+----+----+      /
 * |  1 |  2 |  3 |     /
 * +----+----+----+    /
 * |  4 |  5 |  6 |   /
 * +----+----+----+  /
 * |  7 |  8 |  9 | /
 * +----+----+----+
 * And applying MAX global 3d pooling, we expect to get an output with shape: (1,1,1,1,1) and value:
 * +----+
 * | 18 |
 * +----+
 */
struct  _CoreML__Specification__GlobalPooling3DLayerParams
{
  ProtobufCMessage base;
  /*
   * Whether to use Max or Average
   */
  CoreML__Specification__GlobalPooling3DLayerParams__GlobalPoolingType3D type;
};
#define CORE_ML__SPECIFICATION__GLOBAL_POOLING3_DLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__global_pooling3_dlayer_params__descriptor) \
    , CORE_ML__SPECIFICATION__GLOBAL_POOLING3_DLAYER_PARAMS__GLOBAL_POOLING_TYPE3_D__MAX }


/*
 **
 * Fill a constant value in the padded region.
 */
struct  _CoreML__Specification__PaddingLayerParams__PaddingConstant
{
  ProtobufCMessage base;
  float value;
};
#define CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_CONSTANT__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__padding_layer_params__padding_constant__descriptor) \
    , 0 }


/*
 **
 * Reflect the values at the border for padding.
 */
struct  _CoreML__Specification__PaddingLayerParams__PaddingReflection
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_REFLECTION__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__padding_layer_params__padding_reflection__descriptor) \
     }


/*
 **
 * Replicate the values at the border for padding.
 */
struct  _CoreML__Specification__PaddingLayerParams__PaddingReplication
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_REPLICATION__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__padding_layer_params__padding_replication__descriptor) \
     }


typedef enum {
  CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE_CONSTANT = 1,
  CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE_REFLECTION = 2,
  CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE_REPLICATION = 3
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE)
} CoreML__Specification__PaddingLayerParams__PaddingTypeCase;

/*
 **
 * A layer that performs padding along spatial dimensions.
 * .. code::
 *      y = PaddingLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 2.
 *     e.g.: blob with shape ``[H_in, W_in]``.
 *     For ranks greater than 2, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch
 *     i.e. Padding is applied on last two dimensions.
 * Output
 *     Same rank as the input.
 *     e.g.: blob with shape ``[H_out, W_out]``.
 * Output dimensions are calculated as follows:
 * .. code::
 *     H_out = H_in + topPaddingAmount + bottomPaddingAmount
 *     W_out = W_in + leftPaddingAmount + rightPaddingAmount
 *     topPaddingAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
 *     bottomPaddingAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
 *     leftPaddingAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
 *     rightPaddingAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
 * There are three types of padding:
 * - ``PaddingConstant``, which fills a constant value at the border.
 * - ``PaddingReflection``, which reflects the values at the border.
 * - ``PaddingReplication``, which replicates the values at the border.
 * Given the following input:
 * .. code::
 *     [1, 3, 4]  :  1   2   3   4
 *                   5   6   7   8
 *                   9   10  11  12
 * Here is the output of applying the padding
 * ``(top=2, left=2, bottom=0, right=0)``
 * with each of the supported types:
 * - ``PaddingConstant`` (``value = 0``):
 *   .. code::
 *       [1, 5, 6]  :  0   0   0  0   0   0
 *                     0   0   0  0   0   0
 *                     0   0   1  2   3   4
 *                     0   0   5  6   7   8
 *                     0   0   9  10  11  12
 * - ``PaddingReflection``:
 *   .. code::
 *       [1, 5, 6]  :  11  10  9  10  11  12
 *                     7   6   5  6   7   8
 *                     3   2   1  2   3   4
 *                     7   6   5  6   7   8
 *                     11  10  9  10  11  12
 * - ``PaddingReplication``:
 *   .. code::
 *       [1, 5, 6]  :  1   1   1  2   3   4
 *                     1   1   1  2   3   4
 *                     1   1   1  2   3   4
 *                     5   5   5  6   7   8
 *                     9   9   9  10  11  12
 */
struct  _CoreML__Specification__PaddingLayerParams
{
  ProtobufCMessage base;
  /*
   * / Amounts to be padded to the input.
   */
  CoreML__Specification__BorderAmounts *paddingamounts;
  CoreML__Specification__PaddingLayerParams__PaddingTypeCase padding_type_case;
  union {
    CoreML__Specification__PaddingLayerParams__PaddingConstant *constant;
    CoreML__Specification__PaddingLayerParams__PaddingReflection *reflection;
    CoreML__Specification__PaddingLayerParams__PaddingReplication *replication;
  };
};
#define CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__padding_layer_params__descriptor) \
    , NULL, CORE_ML__SPECIFICATION__PADDING_LAYER_PARAMS__PADDING_TYPE__NOT_SET, {0} }


/*
 **
 * A layer that concatenates along the axis = -3 or -5.
 * For general concatenation along any axis, see ConcatNDLayer.
 * .. code::
 *      y = ConcatLayer(x1,x2,....)
 * Requires more than 1 input and produces 1 output.
 * Input
 *   All input blobs must have same rank.
 *   If "sequenceConcat" = False, rank must be greater than equal to 3. In this case concatenation is along axis = -3
 *   If "sequenceConcat" = True, rank must be greater than equal to 5. In this case concatenation is along axis = -5
 * Output
 *   Same rank as the input.
 */
struct  _CoreML__Specification__ConcatLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * If true, concatenate along the axis = -5 instead of axis = -3.
   */
  protobuf_c_boolean sequenceconcat;
};
#define CORE_ML__SPECIFICATION__CONCAT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__concat_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that performs local response normalization (LRN).
 * .. code::
 *      y = LRNLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank greater than equal to 3.
 *     Example: Rank 4 blob represents [Batch, channels, height, width]
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 * This layer is described by the following formula:
 * .. math::
 *     x_i \leftarrow  \dfrac{x_i}{\left ( k + \dfrac{\alpha}{\text{localSize}} \sum_j x_j^2 \right )^\beta}
 * where the summation is done over a ``(localSize, 1, 1)`` neighborhood ---
 * that is, over a window "across" channels in 1x1 spatial neighborhoods.
 */
struct  _CoreML__Specification__LRNLayerParams
{
  ProtobufCMessage base;
  float alpha;
  float beta;
  /*
   * / Number of channels in the normalization window.
   */
  uint64_t localsize;
  /*
   * / Defaults to 1 if not set or 0. Must be strictly positive.
   */
  float k;
};
#define CORE_ML__SPECIFICATION__LRNLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__lrnlayer_params__descriptor) \
    , 0, 0, 0, 0 }


/*
 **
 * Softmax Normalization Layer
 * A layer that performs softmax normalization.
 * Normalization is applied along axis = -3 or N-3 (where N is the rank of the input)
 * For softmax layer that can operate on any axis, see SoftmaxNDLayer.
 * .. code::
 *      y = SoftmaxLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     Must be a blob with rank >= 3.
 * Output
 *     A blob with the same shape as the input.
 * This layer is described by the following formula:
 * .. math::
 *     x_i \leftarrow \dfrac{e^{x_i}}{\sum_i{e^{x_i}}}
 */
struct  _CoreML__Specification__SoftmaxLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__SOFTMAX_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__softmax_layer_params__descriptor) \
     }


/*
 **
 * A layer that uniformly splits across axis = -3 to produce a specified number of outputs.
 * For general split operation along any axis, see SplitNDLayer.
 * .. code::
 *      (y1,y2,...yN) = SplitLayer(x), where N = nOutputs
 * Requires 1 input and produces multiple outputs.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H, W]``
 * Output
 *     ``nOutputs`` blobs each with same rank as the input.
 *     e.g.: For input that is of shape ``[C, H, W]``, output shapes will be ``[C/nOutputs, H, W]``
 */
struct  _CoreML__Specification__SplitLayerParams
{
  ProtobufCMessage base;
  /*
   * / The number of outputs.
   */
  uint64_t noutputs;
};
#define CORE_ML__SPECIFICATION__SPLIT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__split_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that performs elementwise addition.
 * This layer has limited broadcasting support. For general broadcasting see AddBroadcastableLayer.
 * .. code::
 *      y = AddLayer(x1,x2,...)
 * Requires 1 or more than 1 input and produces 1 output.
 * Input
 *     In general, there are no rank constraints.
 *     However, only certain set of shapes are broadcastable. For example:
 *     [B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
 * Output
 *     A blob with shape equal to the input blob.
 * If only one input is provided, scalar addition is performed:
 * .. math::
 *     y = x + \alpha
 */
struct  _CoreML__Specification__AddLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Scalar to be added to the input.
   * Only used if there is a single input.
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__ADD_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__add_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that performs elementwise multiplication.
 * This layer has limited broadcasting support. For general broadcasting see MultiplyBroadcastableLayer.
 * .. code::
 *      y = MultiplyLayer(x1,x2,...)
 * Requires 1 or more than 1 input and produces 1 output.
 * Input
 *     In general, there are no rank constraints.
 *     However, only certain set of shapes are broadcastable. For example:
 *     [B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
 * Output
 *     A blob with shape equal to the first input blob.
 * If only one input is provided, scalar multiplication is performed:
 * .. math::
 *     y = \alpha x
 */
struct  _CoreML__Specification__MultiplyLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Scalar to be multiplied with the input.
   * Only used if there is a single input.
   */
  float alpha;
};
#define CORE_ML__SPECIFICATION__MULTIPLY_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__multiply_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that applies a unary function.
 * .. code::
 *      y = UnaryFunctionLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with no rank constraints.
 * Output
 *     A blob with the same shape as the input.
 * The input is first modified by shifting and scaling:
 * .. math::
 *     x \leftarrow \text{scale} \cdot x + \text{shift}
 */
struct  _CoreML__Specification__UnaryFunctionLayerParams
{
  ProtobufCMessage base;
  /*
   * / The type of unary function.
   */
  CoreML__Specification__UnaryFunctionLayerParams__Operation type;
  /*
   **
   * A constant used in ``POWER`` and ``THRESHOLD`` functions.
   */
  float alpha;
  /*
   **
   * A small constant to avoid division by 0 while normalizing variance.
   * Defaults to ``1e-6`` if not set or set to ``0``.
   */
  float epsilon;
  /*
   **
   * Input is shifted by this amount
   * before the unary function is applied.
   * Defaults to ``0.0`` if not set.
   */
  float shift;
  /*
   **
   * Input is scaled by this amount
   * before the unary function is applied.
   * Defaults to ``1.0`` if not set or set to ``0``.
   */
  float scale;
};
#define CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__unary_function_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__UNARY_FUNCTION_LAYER_PARAMS__OPERATION__SQRT, 0, 0, 0, 0 }


/*
 **
 * A layer that scales up spatial dimensions.
 * It supports two modes: nearest neighbour (default) and bilinear.
 * .. code::
 *      y = UpsampleLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H, W]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the input.
 *     e.g.: blob with shape ``[C, scalingFactor[0] * H, scalingFactor[1] * W]``
 */
struct  _CoreML__Specification__UpsampleLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Scaling Factor. Mutually exclusive with fractionalScalingFactor.
   * Must be length 2 in order ``[H, W]``.
   * If not set, default value ``[1, 1]`` is used.
   */
  size_t n_scalingfactor;
  uint64_t *scalingfactor;
  /*
   **
   * Fractional scaling factor. Mutually exclusive with scalingFactor.
   * Must be length 2 in order ``[H, W]``.
   * If not set, default value ``[1.0, 1.0]`` is used.
   */
  size_t n_fractionalscalingfactor;
  float *fractionalscalingfactor;
  CoreML__Specification__UpsampleLayerParams__InterpolationMode mode;
  CoreML__Specification__UpsampleLayerParams__LinearUpsampleMode linearupsamplemode;
};
#define CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__upsample_layer_params__descriptor) \
    , 0,NULL, 0,NULL, CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__INTERPOLATION_MODE__NN, CORE_ML__SPECIFICATION__UPSAMPLE_LAYER_PARAMS__LINEAR_UPSAMPLE_MODE__DEFAULT }


/*
 **
 * A layer that resizes the input to a pre-specified spatial size using bilinear interpolation.
 * .. code::
 *      y = ResizeBilinearLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H_in, W_in]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the input.
 *     e.g.: blob with shape ``[C, H_out, W_out]``.
 */
struct  _CoreML__Specification__ResizeBilinearLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Target Spatial Size.
   * Must be length 2 in order ``[Height, Width]``, i.e. ``[H_out, W_out]``.
   * If not set, default value ``[1, 1]`` is used.
   */
  size_t n_targetsize;
  uint64_t *targetsize;
  /*
   **
   * Mode used to compute the grid on which the spatial output values are evaluated.
   * Same mode is applied to both the height and width axes.
   */
  CoreML__Specification__SamplingMode *mode;
};
#define CORE_ML__SPECIFICATION__RESIZE_BILINEAR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__resize_bilinear_layer_params__descriptor) \
    , 0,NULL, NULL }


/*
 **
 * A layer that extracts cropped spatial patches or RoIs (regions of interest) from the input and resizes them to a pre-specified size using
 * bilinear interpolation.
 * Note that RoI Align layer can be implemented with this layer followed by a pooling layer.
 * .. code::
 *      y = CropResizeLayer(x)
 * Requires 2 inputs and produces 1 output.
 * Input
 *     There are two inputs.
 *     First input represents an image feature map.
 *     Second input represents the bounding box coordinates for N patches or RoIs (region of interest).
 *     First input is rank 5: [1, Batch, C, H_in, W_in].
 *     Second input is rank 5. Its shape can be either [N, 1, 4, 1, 1] or [N, 1, 5, 1, 1].
 *     N: number of patches/RoIs to be extracted
 *     If RoI shape = ``[N, 1, 4, 1, 1]``
 *                    The axis=-3 corresponds to the four coordinates specifying the bounding box.
 *                    All the N RoIs are extracted from all the batches of the input.
 *     If RoI shape = ``[N, 1, 5, 1, 1]``
 *                     The first element of the axis=-3 specifies the input batch id from which to extract the RoI and
 *                               must be in the interval ``[0, Batch - 1]``. That is, n-th RoI is extracted from the RoI[n,0,0,0,0]-th
 *                     input batch id. The last four elements of the axis=-3 specify the bounding box coordinates.
 * Output
 *     A blob with rank 5.
 *           - Shape is [N, Batch, C, H_out, W_out] if input RoI shape is [N, 1, 4, 1, 1]
 *           - Shape is [N, 1, C, H_out, W_out] if input RoI shape is [N, 1, 5, 1, 1]
 */
struct  _CoreML__Specification__CropResizeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Target Spatial Size.
   * Must be length 2 in order ``[Height, Width]``, i.e. ``[H_out, W_out]``.
   * If not set, default value ``[1, 1]`` is used.
   */
  size_t n_targetsize;
  uint64_t *targetsize;
  /*
   **
   * If true the bounding box coordinates must be in the interval [0, 1].
   * They are scaled by (H_in - 1), (W_in - 1), i.e. based on the input spatial dimensions.
   * If false the bounding box coordinates must be in the interval
   * [0, H_in -1] and [0, W_in - 1], respectively for height and width dimensions.
   */
  protobuf_c_boolean normalizedcoordinates;
  /*
   **
   * Mode used to compute the grid on which the spatial output values are evaluated.
   * Same mode is applied to both the height and width axes.
   */
  CoreML__Specification__SamplingMode *mode;
  /*
   **
   * Representation used to express the bounding box coordinates.
   * It determines how the values of the second input are interpreted.
   */
  CoreML__Specification__BoxCoordinatesMode *boxindicesmode;
  /*
   **
   * Additional spatial scale that multiplies the bounding box coordinates.
   * Generally used while implementing the RoI Align layer,
   * which uses unnormalized RoI coordinates along with a spatial scale less than or equal to 1.
   */
  float spatialscale;
};
#define CORE_ML__SPECIFICATION__CROP_RESIZE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__crop_resize_layer_params__descriptor) \
    , 0,NULL, 0, NULL, NULL, 0 }


/*
 **
 * A layer that performs elementwise addition of a bias,
 * which is broadcasted to match the input shape.
 * .. code::
 *      y = BiasLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H, W]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 */
struct  _CoreML__Specification__BiasLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The shape of the bias.
   * Must be one of the following:
   * ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
   */
  size_t n_shape;
  uint64_t *shape;
  /*
   **
   * The bias values.
   * The size must be equal to the product of the ``shape`` dimensions.
   */
  CoreML__Specification__WeightParams *bias;
};
#define CORE_ML__SPECIFICATION__BIAS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__bias_layer_params__descriptor) \
    , 0,NULL, NULL }


/*
 **
 * A layer that performs elmentwise multiplication by a scale factor
 * and optionally adds a bias;
 * both the scale and bias are broadcasted to match the input shape.
 * .. code::
 *      y = ScaleLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H, W]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 */
struct  _CoreML__Specification__ScaleLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The shape of the scale.
   * Must be one of the following:
   * ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
   */
  size_t n_shapescale;
  uint64_t *shapescale;
  /*
   **
   * The scale values.
   * The size must be equal to the product of the ``shape`` dimensions.
   */
  /*
   * / Scale values. Size must be equal to the product of dimensions specified in shapeScale.
   */
  CoreML__Specification__WeightParams *scale;
  /*
   * / If true, a bias is added after scaling.
   */
  protobuf_c_boolean hasbias;
  /*
   **
   * The shape of the bias.
   * Must be one of the following:
   * ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
   */
  size_t n_shapebias;
  uint64_t *shapebias;
  /*
   **
   * The bias values.
   * The size must be equal to the product of the ``shape`` dimensions.
   */
  CoreML__Specification__WeightParams *bias;
};
#define CORE_ML__SPECIFICATION__SCALE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__scale_layer_params__descriptor) \
    , 0,NULL, NULL, 0, 0,NULL, NULL }


/*
 **
 * A layer that loads data as a parameter and provides it as an output.
 * The output is rank 5. For general rank, see LoadConstantNDLayer.
 * .. code::
 *      y = LoadConstantLayer()
 * Requires no input and produces 1 output.
 * Output:
 *     A blob with rank 5 and shape ``[1, 1, C, H, W]``
 */
struct  _CoreML__Specification__LoadConstantLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The shape of the constant to be loaded,
   * which must be``[C, H, W]``, that is length 3.
   */
  size_t n_shape;
  uint64_t *shape;
  /*
   **
   * The data values,
   * of size ``C * H * W``.
   */
  CoreML__Specification__WeightParams *data;
};
#define CORE_ML__SPECIFICATION__LOAD_CONSTANT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__load_constant_layer_params__descriptor) \
    , 0,NULL, NULL }


/*
 **
 * A layer that performs L2 normalization, i.e. divides by the
 * the square root of the sum of squares of all elements of input.
 * .. code::
 *      y = L2NormalizeLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank greater than equal to 3.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 * This layer is described by the following formula:
 * .. math::
 *     x_i \leftarrow \dfrac{x_i}{\sqrt{\sum{x_i^2} + \epsilon}}
 */
struct  _CoreML__Specification__L2NormalizeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * A small constant to avoid division by 0 while normalizing variance.
   * Defaults to ``1e-6`` if not set or set to ``0``.
   */
  float epsilon;
};
#define CORE_ML__SPECIFICATION__L2_NORMALIZE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__l2_normalize_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that flattens the input.
 * .. code::
 *      y = FlattenLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank greater than equal to 3.
 *     e.g.: Rank 4 blob represents [Batch, C, H, W]
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the input, such that last two dimensions are both 1.
 *     e.g.: For rank 4 input, output shape is ``[Batch, C * H * W, 1, 1]``
 * There are two X orders: ``CHANNEL_FIRST`` and ``CHANNEL_LAST``.
 * ``CHANNEL_FIRST`` does not require data to be rearranged,
 * because row major ordering is used by internal storage.
 * ``CHANNEL_LAST`` requires data to be rearranged.
 */
struct  _CoreML__Specification__FlattenLayerParams
{
  ProtobufCMessage base;
  CoreML__Specification__FlattenLayerParams__FlattenOrder mode;
};
#define CORE_ML__SPECIFICATION__FLATTEN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__flatten_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__FLATTEN_LAYER_PARAMS__FLATTEN_ORDER__CHANNEL_FIRST }


/*
 **
 * A layer that recasts the input into a new shape.
 * .. code::
 *      y = ReshapeLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank 5.
 *     e.g.: ``[1, 1, C, H, W]`` or ``[Seq, 1, C, H, W]``.
 * Output
 *     A blob with rank 5.
 *     e.g.: ``[1, 1, C_out, H_out, W_out]`` or ``[Seq_out, 1, C_out, H_out, W_out]``.
 * There are two reshape orders: ``CHANNEL_FIRST`` and ``CHANNEL_LAST``.
 * ``CHANNEL_FIRST`` is equivalent to
 * flattening the input to ``[Seq, 1, C * H * W, 1, 1]`` in channel first order
 * and then reshaping it to the target shape;
 * no data rearrangement is required.
 * ``CHANNEL_LAST`` is equivalent to
 * flattening the input to ``[Seq, 1, H * W * C, 1, 1]`` in channel last order,
 * reshaping it to ``[Seq_out, 1, H_out, W_out, C_out]`` (it is now in "H_out-major"" order),
 * and then permuting it to ``[C_out, H_out, W_out]``;
 * both the flattening and permuting requires the data to be rearranged.
 */
struct  _CoreML__Specification__ReshapeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The shape of the output.
   * Must be of length 3 or 4.
   * If set to 3, ``targetShape`` is interpreted as
   * ``[1, 1, C_out, H_out, W_out]``, and sequence length of the input is preserved.
   * If set to 4, ``targetShape`` is interpreted as
   * ``[Seq_out, 1, C_out, H_out, W_out]``,
   * where ``Seq_out`` is the new sequence length.
   */
  size_t n_targetshape;
  int64_t *targetshape;
  CoreML__Specification__ReshapeLayerParams__ReshapeOrder mode;
};
#define CORE_ML__SPECIFICATION__RESHAPE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reshape_layer_params__descriptor) \
    , 0,NULL, CORE_ML__SPECIFICATION__RESHAPE_LAYER_PARAMS__RESHAPE_ORDER__CHANNEL_FIRST }


/*
 **
 * A layer that rearranges the dimensions and data of an input.
 * For generic transpose/permute operation see TransposeLayer.
 * .. code::
 *      y = PermuteLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     Must be a rank 5 blob.
 *     e.g.: shape ``[Seq, B, C, H, W]``.
 * Output
 *     Rank 5 blob. Transposed version of the input, such that dimensions at axis=1 or axis=-4 is unchanged.
 * Examples:
 *  Assume input shape is [Seq, B, C, H, W]
 * - If ``axis`` is set to ``[0, 3, 1, 2]``,
 *   then the output has shape ``[Seq, B, W, C, H]``
 * - If ``axis`` is set to ``[3, 1, 2, 0]``,
 *   then the output has shape ``[W, B, C, H, Seq]``
 * - If ``axis`` is set to ``[0, 3, 2, 1]``,
 *   then the output has shape ``[Seq, B, W, H, C]``
 * - If ``axis`` is not set, or is set to ``[0, 1, 2, 3]``,
 *   the output is the same as the input.
 */
struct  _CoreML__Specification__PermuteLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The order in which to permute the dimensions.
   * Must have length 4 and a permutation of ``[0, 1, 2, 3]``.
   */
  size_t n_axis;
  uint64_t *axis;
};
#define CORE_ML__SPECIFICATION__PERMUTE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__permute_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that reorganizes data in the input in specific ways.
 * .. code::
 *      y = ReorganizeDataLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 3.
 *     e.g.: blob with shape ``[C, H, W]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the input.
 *     e.g.: blob with shape ``[C_out, H_out, W_out]``.
 * mode == SPACE_TO_DEPTH
 *  ``[C_out, H_out, W_out]`` : ``[C * blockSize * blockSize, H/blockSize, W/blockSize]``.
 *  blockSize must divide H and W.
 *  Data is moved from the spatial dimensions to the channel dimension. Input is spatially divided into
 *  non-overlapping blocks of size blockSize X blockSize and data from each block is moved into the
 *  channel dimension.
 * mode == DEPTH_TO_SPACE
 *  ``[C_out, H_out, W_out]`` : ``[C/(blockSize * blockSize), H * blockSize, W * blockSize]``.
 *  Square of blockSize must divide C.
 *  Reverse of SPACE_TO_DEPTH. Data is moved from the channel dimension to the spatial dimensions.
 * mode == PIXEL_SHUFFLE
 *  ``[C_out, H_out, W_out]`` : ``[C/(blockSize * blockSize), H * blockSize, W *  blockSize]``.
 *  Square of blockSize must divide C.
 *  Similar to DEPTH_TO_SPACE, but using the pixel-shuffle semantics for channel order in the output space.
 *  In both modes, elements along the channel dimension are collapsed into
 *  blocks in the spatial dimensions. The difference is in the arrangement of
 *  the input-channels' data in the output space. See below example for more
 *  detail.
 *  (Only available in Core ML Specification >= 5 (iOS >= 14, macOS >= 11.0)
 * Examples:
 * Assume input is the following [C = 8, H = 1, W = 2] tensor:
 * .. code::
 *    [[[1 2]] [[3 4]] [[5 6]] [[7 8]] [[9 10]] [[11 12]] [[13 14]] [[15 16]]]
 * If block_size == 2 and mode == DEPTH_TO_SPACE, output will be the following
 * [C = 2, H = 2, W = 4] tensor:
 * .. code::
 *    [[[ 1  5  2  6]
 *      [ 9 13 10 14]]
 *     [[ 3  7  4  8]
 *      [11 15 12 16]]]
 * For mode == SPACE_TO_DEPTH, the behavior is the same as mode ==
 * DEPTH_TO_SPACE, but with the input and output swapped.
 * If block_size == 2 and mode == PIXEL_SHUFFLE, output will be the following
 * [C = 2, H = 2, W = 4] tensor:
 * .. code::
 *    [[[ 1  3  2  4]
 *      [ 5  7  6  8]]
 *     [[ 9 11 10 12]
 *      [13 15 14 16]]]
 */
struct  _CoreML__Specification__ReorganizeDataLayerParams
{
  ProtobufCMessage base;
  CoreML__Specification__ReorganizeDataLayerParams__ReorganizationType mode;
  /*
   * / must be greater than 1
   */
  uint64_t blocksize;
};
#define CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reorganize_data_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__REORGANIZE_DATA_LAYER_PARAMS__REORGANIZATION_TYPE__SPACE_TO_DEPTH, 0 }


/*
 **
 * A layer that slices the input data along axis = -1 or -2 or -3.
 * For general slice along any axis, please see SliceStaticLayer/SliceDynamicLayer.
 * .. code::
 *      y = SliceLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob that can, in general, have any rank. However, depending on the value of "axis" ,
 *     there may be additional rank constraints.
 * Output
 *     A blob with the same rank as the input.
 * Sliced section is taken from the interval ``[startIndex, endIndex)``, i.e.
 * startIndex is inclusive while endIndex is exclusive.
 * stride must be positive and represents the step size for slicing.
 * Negative indexing is supported for startIndex and endIndex.
 * -1 denotes N-1, -2 denotes N-2 and so on, where N is the length of the dimension to be sliced.
 */
struct  _CoreML__Specification__SliceLayerParams
{
  ProtobufCMessage base;
  /*
   * / start of the sliced section. Inclusive.
   */
  int64_t startindex;
  /*
   * / end of sliced section. Exclusive.
   */
  int64_t endindex;
  /*
   * / The step size. Must be positive.
   */
  uint64_t stride;
  /*
   * The following mapping is used for interpreting this parameter:
   * CHANNEL_AXIS => axis = -3, input must have rank at least 3.
   * HEIGHT_AXIS => axis = -2, input must have rank at least 2.
   * WIDTH_AXIS => axis = -1
   */
  CoreML__Specification__SliceLayerParams__SliceAxis axis;
};
#define CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__slice_layer_params__descriptor) \
    , 0, 0, 0, CORE_ML__SPECIFICATION__SLICE_LAYER_PARAMS__SLICE_AXIS__CHANNEL_AXIS }


/*
 **
 * A layer that reduces the input using a specified operation.
 * .. code::
 *      y = ReduceLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob that can, in general, have any rank. However, depending on the value of "axis" ,
 *      there may be additional rank constraints.
 * Output
 *     A blob with the same rank as the input, which has 1s on the dimensions specified in the parameter "axis"
 *     Values supported for axis are [-1], [-2], [-3], [-2,-1], [-3,-2,-1]
 *     and the equivalent positive values (depending on the rank of the input)
 *     For mode == 'ArgMax', axis must be [-1] or [-2] or [-3].
 */
struct  _CoreML__Specification__ReduceLayerParams
{
  ProtobufCMessage base;
  /*
   * / Specifies function used to reduce.
   */
  CoreML__Specification__ReduceLayerParams__ReduceOperation mode;
  /*
   **
   * Used if mode is ``LOGSUM``.
   * Defaults to ``1e-6`` if not set or is set to ``0``.
   */
  float epsilon;
  /*
   * The following mapping is used for interpreting this parameter:
   * CHW = axis [-3, -2, -1], input must have rank at least 3.
   * HW = axis [-2, -1], input must have rank at least 2.
   * C = axis [-3]
   * H = axis [-2]
   * W = axis [-1]
   */
  CoreML__Specification__ReduceLayerParams__ReduceAxis axis;
};
#define CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_OPERATION__SUM, 0, CORE_ML__SPECIFICATION__REDUCE_LAYER_PARAMS__REDUCE_AXIS__CHW }


/*
 **
 * A layer that crops the spatial dimensions of an input.
 * If two inputs are provided, the shape of the second input is used as the reference shape.
 * .. code::
 *      y = CropLayer(x1) or y = CropLayer(x1,x2)
 * Requires 1 or 2 inputs and produces 1 output.
 * Input
 *    1 or 2 tensors, each with rank at least 3, both inputs must have equal rank.
 *    Example:
 *     - 1 input case: A blob with shape ``[C, H_in, W_in]``.
 *     - 2 input case: 1st blob with shape ``[C, H_in, W_in]``, 2nd blob with shape ``[C, H_out, W_out]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the inputs.
 *     e.g.: A blob with shape ``[C, H_out, W_out]``.
 * If one input is used, output is computed as follows:
 * .. code::
 *      y = x1[:, topCropAmount:H_in - bottomCropAmount, leftCropAmount:W_in - rightCropAmount]
 *      topCropAmount == Height startEdgeSize == borderAmounts[0].startEdgeSize
 *      bottomCropAmount == Height endEdgeSize == borderAmounts[0].endEdgeSize
 *      leftCropAmount == Width startEdgeSize == borderAmounts[1].startEdgeSize
 *      rightCropAmount == Width endEdgeSize == borderAmounts[1].endEdgeSize
 *      H_out = H_in - topCropAmount - bottomCropAmount
 *      W_out = W_in - leftCropAmount - rightCropAmount
 * If two inputs are used, output is computed as follows:
 * .. code::
 *      y = x1[:, offset[0]:offset[0] + H_out, offset[1]:offset[1] + W_out]
 */
struct  _CoreML__Specification__CropLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The amounts to be cropped from the input.
   * Used only if a single input is provided.
   */
  CoreML__Specification__BorderAmounts *cropamounts;
  /*
   **
   * The offset amounts.
   * Used only if two inputs are provided.
   * Must be of length 2, in order ``[H, W]``.
   */
  size_t n_offset;
  uint64_t *offset;
};
#define CORE_ML__SPECIFICATION__CROP_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__crop_layer_params__descriptor) \
    , NULL, 0,NULL }


/*
 **
 * A layer that computes the elementwise average of the inputs.
 * This layer has limited broadcasting support. For general broadcasting see AddBroadcastableLayer.
 * .. code::
 *      y = AverageLayer(x1,x2,...)
 * Requires multiple inputs and produces 1 output.
 * Input
 *     In general, there are no rank constraints.
 *     However, only certain set of shapes are broadcastable. For example:
 *     [B, 1, 1, 1], [B, C, 1, 1], [B, 1, H, W], [B, C, H, W]
 * Output
 *     A blob with the same shape as each input.
 */
struct  _CoreML__Specification__AverageLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__AVERAGE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__average_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes the elementwise maximum over the inputs.
 * .. code::
 *      y = MaxLayer(x1,x2,...)
 * Requires multiple inputs and produces 1 output.
 * Input
 *     In general, there are no rank constraints.
 *     However, only certain set of shapes are broadcastable. For example:
 *     [B, C, 1, 1], [B, C, H, W]
 * Output
 *     A blob with the same shape as each input.
 */
struct  _CoreML__Specification__MaxLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MAX_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__max_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes the elementwise minimum over the inputs.
 * .. code::
 *      y = MinLayer(x1,x2,...)
 * Requires multiple inputs and produces 1 output.
 * Input
 *     In general, there are no rank constraints.
 *     However, only certain set of shapes are broadcastable. For example:
 *     [B, C, 1, 1], [B, C, H, W]
 * Output
 *     A blob with the same shape as each input.
 */
struct  _CoreML__Specification__MinLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MIN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__min_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes the dot product of two vectors.
 * .. code::
 *      y = DotProductLayer(x1,x2)
 * Requires 2 inputs and produces 1 output.
 * Input
 *     Two blobs with rank at least 3, such that the last two dimensions must be 1.
 *     e.g.: blobs with shape ``[B, C, 1, 1]``.
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     Same rank as the input.
 *     e.g. for rank 4 inputs, output shape: [B, 1, 1, 1]
 */
struct  _CoreML__Specification__DotProductLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * If true, inputs are normalized first,
   * thereby computing the cosine similarity.
   */
  protobuf_c_boolean cosinesimilarity;
};
#define CORE_ML__SPECIFICATION__DOT_PRODUCT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__dot_product_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that performs mean variance normalization, along axis = -3.
 * .. code::
 *      y = MeanVarianceNormalizeLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank greater than equal to 3.
 *     Example: Rank 4 blob represents [Batch, channels, height, width]
 *     For ranks greater than 3, the leading dimensions, starting from 0 to -4 (inclusive), are all treated as batch.
 * Output
 *     A blob with the same shape as the input.
 * If ``acrossChannels == true``
 * normalization is performed on flattened input, i.e. the input is reshaped to (Batch,C), where "Batch" contains
 * all dimensions from 0 to -4 (inclusive), and C contains dimensions -1, -2, -3.
 * If ``acrossChannels == false``
 * normalization is performed within a channel,
 * across spatial dimensions (i.e. last two dimensions).
 */
struct  _CoreML__Specification__MeanVarianceNormalizeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * If true, mean and variance are computed across channels.
   */
  protobuf_c_boolean acrosschannels;
  /*
   **
   * If false, only mean is subtracted.
   */
  protobuf_c_boolean normalizevariance;
  /*
   **
   * A small constant to avoid division by 0 while normalizing variance.
   * Defaults to ``1e-6`` if not set or set to ``0``.
   */
  float epsilon;
};
#define CORE_ML__SPECIFICATION__MEAN_VARIANCE_NORMALIZE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__mean_variance_normalize_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that repeats a sequence or the dimension sitting at axis = -5
 * .. code::
 *      y = SequenceRepeatLayer(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     A blob with rank at least 5.
 *     e.g: shape ``[Seq, B, C, H, W]``
 * Output
 *     A blob with the same rank as the input.
 *     e.g.: for input shape ``[Seq, B, C, H, W]``, output shape is ``[nRepetitions * Seq, B, C, H, W]``.
 */
struct  _CoreML__Specification__SequenceRepeatLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Number of repetitions.
   * Defaults to ``1`` if not set or set to ``0``.
   */
  uint64_t nrepetitions;
};
#define CORE_ML__SPECIFICATION__SEQUENCE_REPEAT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sequence_repeat_layer_params__descriptor) \
    , 0 }


/*
 **
 * A simple recurrent layer.
 * .. code::
 *      y_t = SimpleRecurrentLayer(x_t, y_{t-1})
 * Input
 *    A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
 *    This represents a sequence of vectors of size ``inputVectorSize``.
 * Output
 *    Same rank as the input.
 *    Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
 * - Output Shape: ``[1, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == false``
 * - Output Shape: ``[Seq, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == true``
 * This layer is described by the following equation:
 * .. math::
 *     \boldsymbol{y_t} = f(\mathrm{clip}(W \boldsymbol{x_t} + \
 *                                        R \boldsymbol{y_{t-1}} + b))
 * - ``W`` is a 2-dimensional weight matrix
 *   (``[outputVectorSize, inputVectorSize]``, row-major)
 * - ``R`` is a 2-dimensional recursion matrix
 *   (``[outputVectorSize, outputVectorSize]``, row-major)
 * - ``b`` is a 1-dimensional bias vector (``[outputVectorSize]``)
 * - ``f()`` is an activation
 * - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
 */
struct  _CoreML__Specification__SimpleRecurrentLayerParams
{
  ProtobufCMessage base;
  /*
   * / The size of the input vectors.
   */
  uint64_t inputvectorsize;
  /*
   * / The size of the output vectors.
   */
  uint64_t outputvectorsize;
  /*
   **
   * Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
   */
  /*
   * / The activation function.
   */
  CoreML__Specification__ActivationParams *activation;
  /*
   **
   *If false output is just the result after final state update.
   *If true, output is a sequence, containing outputs at all time steps.
   */
  protobuf_c_boolean sequenceoutput;
  /*
   * / If false, no bias is added.
   */
  protobuf_c_boolean hasbiasvector;
  /*
   * / Weight matrix W.
   */
  CoreML__Specification__WeightParams *weightmatrix;
  /*
   * / Recursion Weight matrix R.
   */
  CoreML__Specification__WeightParams *recursionmatrix;
  /*
   * / Bias vector b.
   */
  CoreML__Specification__WeightParams *biasvector;
  /*
   * If true, then the node processes the input sequence from right to left
   */
  protobuf_c_boolean reverseinput;
};
#define CORE_ML__SPECIFICATION__SIMPLE_RECURRENT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__simple_recurrent_layer_params__descriptor) \
    , 0, 0, NULL, 0, 0, NULL, NULL, NULL, 0 }


/*
 **
 * Gated-Recurrent Unit (GRU) Layer
 * .. code::
 *      y_t = GRULayer(x_t, y_{t-1})
 * Input
 *    A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
 *    This represents a sequence of vectors of size ``inputVectorSize``.
 * Output
 *    Same rank as the input.
 *    Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
 * - Output Shape: ``[1, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == false``
 * - Output Shape: ``[Seq, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == true``
 * This layer is described by the following equations:
 * Update Gate
 *     .. math::
 *         \boldsymbol{z_t} = \
 *             f(\mathrm{clip}(W_z \boldsymbol{x_t} + \
 *                             R_z \boldsymbol{y_{t-1}} + b_z)
 * Reset Gate
 *     .. math::
 *         \boldsymbol{r_t} = \
 *             f(\mathrm{clip}(W_r \boldsymbol{x_t} + \
 *                             R_r \boldsymbol{y_{t-1}} + b_r))
 * Cell Memory State
 *     .. math::
 *         \boldsymbol{c_t} = \
 *             \boldsymbol{y_{t-1}} \odot \boldsymbol{r_t}
 * Output Gate
 *     .. math::
 *         \boldsymbol{o_t} = \
 *             g(\mathrm{clip}(W_o \boldsymbol{x_t} + \
 *                             R_o \boldsymbol{c_t} + b_o))
 * Output
 *     .. math::
 *         \boldsymbol{y_t} = \
 *             (1 - \boldsymbol{z_t}) \odot \boldsymbol{o_t} + \
 *              \boldsymbol{z_t} \odot \boldsymbol{y_{t-1}}
 * - ``W_z``, ``W_r``, ``W_o`` are 2-dimensional input weight matrices
 *   (``[outputVectorSize, inputVectorSize]``, row-major)
 * - ``R_z``, ``R_r``, ``R_o`` are 2-dimensional recursion matrices
 *   (``[outputVectorSize, outputVectorSize]``, row-major)
 * - ``b_z``, ``b_r``, ``b_o`` are 1-dimensional bias vectors
 *   (``[outputVectorSize]``)
 * - ``f()``, ``g()`` are activations
 * - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
 * - ``⊙`` denotes the elementwise product of matrices
 */
struct  _CoreML__Specification__GRULayerParams
{
  ProtobufCMessage base;
  /*
   * / Size of the input vectors.
   */
  uint64_t inputvectorsize;
  /*
   * / Size of the output vectors.
   */
  uint64_t outputvectorsize;
  /*
   **
   * 2 element array representing activations [f(), g()] in that order.
   * Typical values used = [sigmoid, tanh].
   * Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
   */
  size_t n_activations;
  CoreML__Specification__ActivationParams **activations;
  /*
   **
   * If false output is just the result after final state update.
   * If true, output is a sequence, containing outputs at all time steps.
   */
  protobuf_c_boolean sequenceoutput;
  /*
   **
   * If false, no biases (``b_z``, ``b_r``, ``b_o``) are added.
   */
  protobuf_c_boolean hasbiasvectors;
  /*
   * / Weight Matrix W_z.
   */
  CoreML__Specification__WeightParams *updategateweightmatrix;
  /*
   * / Weight Matrix W_r.
   */
  CoreML__Specification__WeightParams *resetgateweightmatrix;
  /*
   * / Weight Matrix W_o.
   */
  CoreML__Specification__WeightParams *outputgateweightmatrix;
  /*
   * / Recursion Weight Matrix R_z.
   */
  CoreML__Specification__WeightParams *updategaterecursionmatrix;
  /*
   * / Recursion Weight Matrix R_r.
   */
  CoreML__Specification__WeightParams *resetgaterecursionmatrix;
  /*
   * / Recursion Weight Matrix R_o.
   */
  CoreML__Specification__WeightParams *outputgaterecursionmatrix;
  /*
   * / Bias vector b_z.
   */
  CoreML__Specification__WeightParams *updategatebiasvector;
  /*
   * / Bias vector b_r.
   */
  CoreML__Specification__WeightParams *resetgatebiasvector;
  /*
   * / Bias vector b_o.
   */
  CoreML__Specification__WeightParams *outputgatebiasvector;
  /*
   * / If true, then the node processes the input sequence from right to left
   */
  protobuf_c_boolean reverseinput;
};
#define CORE_ML__SPECIFICATION__GRULAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__grulayer_params__descriptor) \
    , 0, 0, 0,NULL, 0, 0, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 0 }


/*
 **
 * Long short-term memory (LSTM) parameters.
 * This is described by the following equations:
 * Input Gate
 *     .. math::
 *         \boldsymbol{i_t} = \
 *             f(\mathrm{clip}(W_i \boldsymbol{x_t} + \
 *                             R_i \boldsymbol{y_{t-1}} + \
 *                             p_i \odot c_{t-1} + b_i))
 * Forget Gate
 *     .. math::
 *         \boldsymbol{f_t} = \
 *             f(\mathrm{clip}(W_f \boldsymbol{x_t} + \
 *                             R_f \boldsymbol{y_{t-1}} + \
 *                             p_f \odot c_{t-1} + b_f))
 * Block Input
 *     .. math::
 *         \boldsymbol{z_t} = \
 *             g(\mathrm{clip}(W_z \boldsymbol{x_t} + \
 *                             R_z \boldsymbol{y_{t-1}} + b_z))
 * Cell Memory State
 *     .. math::
 *         \boldsymbol{c_t} = \
 *             \boldsymbol{c_{t-1}} \odot \boldsymbol{f_t} + \
 *             \boldsymbol{i_t} \odot \boldsymbol{z_t}
 * Output Gate
 *     .. math::
 *         \boldsymbol{o_t} = \
 *             f(\mathrm{clip}(W_o \boldsymbol{x_t} + \
 *                             R_o \boldsymbol{y_{t-1}} + \
 *                             p_o \odot c_t + b_o))
 * Output
 *     .. math::
 *         \boldsymbol{y_t} = \
 *             h(\boldsymbol{c_t}) \odot \boldsymbol{o_t}
 * - ``W_i``, ``W_f``, ``W_z``, ``W_o`` are 2-dimensional input weight matrices
 *   (``[outputVectorSize, inputVectorSize]``, row-major)
 * - ``R_i``, ``R_f``, ``R_z``, ``R_o`` are 2-dimensional recursion matrices
 *   (``[outputVectorSize, outputVectorSize]``, row-major)
 * - ``b_i``, ``b_f``, ``b_z``, ``b_o`` are 1-dimensional bias vectors
 *   (``[outputVectorSize]``)
 * - ``p_``, ``p_f``, ``p_o`` are 1-dimensional peephole vectors
 *   (``[outputVectorSize]``)
 * - ``f()``, ``g()``, ``h()`` are activations
 * - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
 * - ``⊙`` denotes the elementwise product of matrices
 */
struct  _CoreML__Specification__LSTMParams
{
  ProtobufCMessage base;
  /*
   **
   * If true, output is a sequence, containing outputs at all time steps.
   * If false, output is just the result after final state update.
   */
  protobuf_c_boolean sequenceoutput;
  /*
   **
   * If false, no biases (``b_i``, ``b_f``, ``b_z``, ``b_o``) are added.
   */
  protobuf_c_boolean hasbiasvectors;
  /*
   **
   * If true, a vector of ``1`` values is added to ``b_f``.
   */
  protobuf_c_boolean forgetbias;
  /*
   **
   * If true, peephole vectors are included.
   */
  protobuf_c_boolean haspeepholevectors;
  /*
   **
   * If the coupled Input and Forget flag is on, the behaviour of
   * ``c_t`` is changed to the following (i.e. forget gate is not used):
   * .. math::
   *     \boldsymbol{c_t} = \
   *         \boldsymbol{c_{t-1}} \odot (1 - \boldsymbol{i_t}) + \
   *         \boldsymbol{i_t} \odot \boldsymbol{z_t}
   */
  protobuf_c_boolean coupledinputandforgetgate;
  /*
   **
   * Places a limit on the maximum and minimum values of ``c_t``.
   * c_t = min(c_t, cellClipThreshold)
   * c_t = max(c_t, -cellClipThreshold)
   * If 0, it is set to its default value = 50.0.
   */
  float cellclipthreshold;
};
#define CORE_ML__SPECIFICATION__LSTMPARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__lstmparams__descriptor) \
    , 0, 0, 0, 0, 0, 0 }


/*
 **
 * Weights for long short-term memory (LSTM) layers
 */
struct  _CoreML__Specification__LSTMWeightParams
{
  ProtobufCMessage base;
  /*
   * / Weight Matrix W_i.
   */
  CoreML__Specification__WeightParams *inputgateweightmatrix;
  /*
   * / Weight Matrix W_f.
   */
  CoreML__Specification__WeightParams *forgetgateweightmatrix;
  /*
   * / Weight Matrix W_z.
   */
  CoreML__Specification__WeightParams *blockinputweightmatrix;
  /*
   * / Weight Matrix W_o.
   */
  CoreML__Specification__WeightParams *outputgateweightmatrix;
  /*
   * / Recursion Weight Matrix R_i.
   */
  CoreML__Specification__WeightParams *inputgaterecursionmatrix;
  /*
   * / Recursion Weight Matrix R_f.
   */
  CoreML__Specification__WeightParams *forgetgaterecursionmatrix;
  /*
   * / Recursion Weight Matrix R_z.
   */
  CoreML__Specification__WeightParams *blockinputrecursionmatrix;
  /*
   * / Recursion Weight Matrix R_o.
   */
  CoreML__Specification__WeightParams *outputgaterecursionmatrix;
  /*
   *biases:
   */
  /*
   * / Bias vector b_i.
   */
  CoreML__Specification__WeightParams *inputgatebiasvector;
  /*
   * / Bias vector b_f.
   */
  CoreML__Specification__WeightParams *forgetgatebiasvector;
  /*
   * / Bias vector b_z.
   */
  CoreML__Specification__WeightParams *blockinputbiasvector;
  /*
   * / Bias vector b_o.
   */
  CoreML__Specification__WeightParams *outputgatebiasvector;
  /*
   *peepholes:
   */
  /*
   * / Peephole vector p_i.
   */
  CoreML__Specification__WeightParams *inputgatepeepholevector;
  /*
   * / Peephole vector p_f.
   */
  CoreML__Specification__WeightParams *forgetgatepeepholevector;
  /*
   * / Peephole vector p_o.
   */
  CoreML__Specification__WeightParams *outputgatepeepholevector;
};
#define CORE_ML__SPECIFICATION__LSTMWEIGHT_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__lstmweight_params__descriptor) \
    , NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL }


/*
 **
 * A unidirectional long short-term memory (LSTM) layer.
 * .. code::
 *      (y_t, c_t) = UniDirectionalLSTMLayer(x_t, y_{t-1}, c_{t-1})
 * Input
 *    A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
 *    This represents a sequence of vectors of size ``inputVectorSize``.
 * Output
 *    Same rank as the input.
 *    Represents a vector of size ``outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
 * - Output Shape: ``[1, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == false``
 * - Output Shape: ``[Seq, Batch, outputVectorSize, 1, 1]`` , if ``sequenceOutput == true``
 */
struct  _CoreML__Specification__UniDirectionalLSTMLayerParams
{
  ProtobufCMessage base;
  /*
   * / Size of the input vectors.
   */
  uint64_t inputvectorsize;
  /*
   * / Size of the output vectors.
   */
  uint64_t outputvectorsize;
  /*
   **
   * 3 element array representing activations [f(),g(),h()] in that order.
   * Typical values used = [sigmoid, tanh, tanh].
   * Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
   */
  size_t n_activations;
  CoreML__Specification__ActivationParams **activations;
  CoreML__Specification__LSTMParams *params;
  /*
   * / Weights, biases and peepholes.
   */
  CoreML__Specification__LSTMWeightParams *weightparams;
  /*
   * / If true, then the node processes the input sequence from right to left
   */
  protobuf_c_boolean reverseinput;
};
#define CORE_ML__SPECIFICATION__UNI_DIRECTIONAL_LSTMLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__uni_directional_lstmlayer_params__descriptor) \
    , 0, 0, 0,NULL, NULL, NULL, 0 }


/*
 **
 * Bidirectional long short-term memory (LSTM) layer
 * .. code::
 *      (y_t, c_t, y_t_reverse, c_t_reverse) = BiDirectionalLSTMLayer(x_t, y_{t-1}, c_{t-1}, y_{t-1}_reverse, c_{t-1}_reverse)
 * Input
 *    A blob of rank 5, with shape `[Seq, Batch, inputVectorSize, 1, 1]``.
 *    This represents a sequence of vectors of size ``inputVectorSize``.
 * Output
 *    Same rank as the input.
 *    Represents a vector of size ``2 * outputVectorSize``. It is either the final output or a sequence of outputs at all time steps.
 * - Output Shape: ``[1, Batch, 2 * outputVectorSize, 1, 1]`` , if ``sequenceOutput == false``
 * - Output Shape: ``[Seq, Batch, 2 * outputVectorSize, 1, 1]`` , if ``sequenceOutput == true``
 * The first LSTM operates on the input sequence in the forward direction.
 * The second LSTM operates on the input sequence in the reverse direction.
 * Example: given the input sequence ``[x_1, x_2, x_3]``,
 * where ``x_i`` are vectors at time index ``i``:
 * The forward LSTM output is ``[yf_1, yf_2, yf_3]``,
 * where ``yf_i`` are vectors of size ``outputVectorSize``:
 * - ``yf_1`` is the output at the end of sequence {``x_1``}
 * - ``yf_2`` is the output at the end of sequence {``x_1``, ``x_2``}
 * - ``yf_3`` is the output at the end of sequence {``x_1``, ``x_2``, ``x_3``}
 * The backward LSTM output: ``[yb_1, yb_2, yb_3]``,
 * where ``yb_i`` are vectors of size ``outputVectorSize``:
 * - ``yb_1`` is the output at the end of sequence {``x_3``}
 * - ``yb_2`` is the output at the end of sequence {``x_3``, ``x_2``}
 * - ``yb_3`` is the output at the end of sequence {``x_3``, ``x_2``, ``x_1``}
 * Output of the bi-dir layer:
 * - if ``sequenceOutput = True`` : { ``[yf_1, yb_3]``,  ``[yf_2, yb_2]``,  ``[yf_3, yb_1]`` }
 * - if ``sequenceOutput = False`` : { ``[yf_3, yb_3]`` }
 */
struct  _CoreML__Specification__BiDirectionalLSTMLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Size of the input vectors.
   */
  uint64_t inputvectorsize;
  /*
   **
   * Size of the outputs vectors.
   * It is same for both forward and backward LSTMs.
   */
  uint64_t outputvectorsize;
  /*
   **
   * 3 element array representing activations [f(),g(),h()] in that order.
   * Typical values used = [sigmoid, tanh, tanh].
   * Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha = 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
   */
  size_t n_activationsforwardlstm;
  CoreML__Specification__ActivationParams **activationsforwardlstm;
  /*
   **
   * Currently, backward LSTM activations
   * must be same as the ones for the forward LSTM.
   */
  size_t n_activationsbackwardlstm;
  CoreML__Specification__ActivationParams **activationsbackwardlstm;
  /*
   **
   * Common parameters shared by the forward and backward LSTMs.
   */
  CoreML__Specification__LSTMParams *params;
  /*
   **
   * Weights and biases.
   * Must be a length 2 message,
   * for the forward and backward LSTM respectively.
   */
  size_t n_weightparams;
  CoreML__Specification__LSTMWeightParams **weightparams;
};
#define CORE_ML__SPECIFICATION__BI_DIRECTIONAL_LSTMLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__bi_directional_lstmlayer_params__descriptor) \
    , 0, 0, 0,NULL, 0,NULL, NULL, 0,NULL }


typedef enum {
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE_DOUBLE_VALUE = 10,
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE_STRING_VALUE = 20,
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE_INT_VALUE = 30,
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE_LONG_VALUE = 40,
  CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE_BOOL_VALUE = 50
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE)
} CoreML__Specification__CustomLayerParams__CustomLayerParamValue__ValueCase;

struct  _CoreML__Specification__CustomLayerParams__CustomLayerParamValue
{
  ProtobufCMessage base;
  CoreML__Specification__CustomLayerParams__CustomLayerParamValue__ValueCase value_case;
  union {
    double doublevalue;
    char *stringvalue;
    int32_t intvalue;
    int64_t longvalue;
    protobuf_c_boolean boolvalue;
  };
};
#define CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__custom_layer_params__custom_layer_param_value__descriptor) \
    , CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__CUSTOM_LAYER_PARAM_VALUE__VALUE__NOT_SET, {0} }


struct  _CoreML__Specification__CustomLayerParams__ParametersEntry
{
  ProtobufCMessage base;
  char *key;
  CoreML__Specification__CustomLayerParams__CustomLayerParamValue *value;
};
#define CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__PARAMETERS_ENTRY__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__custom_layer_params__parameters_entry__descriptor) \
    , (char *)protobuf_c_empty_string, NULL }


struct  _CoreML__Specification__CustomLayerParams
{
  ProtobufCMessage base;
  /*
   * The name of the class (conforming to MLCustomLayer) corresponding to this layer
   */
  char *classname;
  /*
   * Any weights -- these are serialized in binary format and memmapped at runtime
   */
  size_t n_weights;
  CoreML__Specification__WeightParams **weights;
  /*
   * these may be handled as strings, so this should not be large
   */
  size_t n_parameters;
  CoreML__Specification__CustomLayerParams__ParametersEntry **parameters;
  /*
   * An (optional) description of the layer provided by the model creator. This information is displayed when viewing the model, but does not affect the model's execution on device.
   */
  char *description;
};
#define CORE_ML__SPECIFICATION__CUSTOM_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__custom_layer_params__descriptor) \
    , (char *)protobuf_c_empty_string, 0,NULL, 0,NULL, (char *)protobuf_c_empty_string }


struct  _CoreML__Specification__TransposeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Length of "axes" should match the rank of input & output tensor
   * "axes" should be a permutation of "[0,1,2,...,N-1]" where N is the rank.
   */
  /*
   */
  size_t n_axes;
  uint64_t *axes;
};
#define CORE_ML__SPECIFICATION__TRANSPOSE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__transpose_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that computes the matrix multiplication of two tensors with numpy-like broadcasting
 * where the matrices reside in the last two indices of the tensor.
 * .. code::
 *      y = BatchedMatMul(a,b)
 * Requires 1 or 2 inputs and produces 1 output.
 * The first tensor, "a", must be provided as an input. The second tensor can either be an input or provided as a weight matrix parameter.
 * Input
 *     - a: First N-Dimensional tensor
 *     - b: Second N-Dimensional tensor (either a rank-N input or a matrix, i.e. N=2, provided as a layer parameter)
 * Output
 *     A tensor containing the matrix product of two tensors.
 *     When there are two inputs: rank is max(2, rank(a), rank(b))
 *     When there is one input: rank is same as that of the input.
 * This operation behaves as following:
 *  When there are two inputs:
 *      - If N >= 2 for both tensors, it is treated as a batch of matrices residing in the last two indices.
 *        All the indices, except for the last two, are broadcasted using conventional rules.
 *      - If the first tensor is 1-D, it is converted to a 2-D tensor by prepending a 1 to its shape. Eg. (D) -> (1,D)
 *      - If the second tensor is 1-D, it is converted to a 2-D tensor by appending a 1 to its shape. Eg. (D) -> (D,1)
 *  When there is one input:
 *      - The weight matrix corresponds to a matrix, of shape (X1, X2). Values of X1, X2 must be provided as layer parameters.
 *      - The input, "a", is reshaped into a matrix by combining all the leading dimensions, except the last, into a batch dimension. eg:
 *             - if "a" is rank 1 (X1,) -->  (1, X1). Output shape will be (X2,)
 *             - if "a" is rank 2 (B1, X1) --> no need to reshape. Output shape will be (B1, X2)
 *             - if "a" is rank 3 (B1, B2, X1) --> (B1 * B2, X1). Output shape will be (B1, B2, X2)
 *             - etc
 */
struct  _CoreML__Specification__BatchedMatMulLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * If transposeA is true, it transposes the left matrix on the fly before matrix multiplication.
   * (is ignored when there is one input)
   */
  protobuf_c_boolean transposea;
  /*
   **
   * If transposeB is true, it transposes the right matrix on the fly before matrix multiplication.
   * (is ignored when there is one input)
   */
  protobuf_c_boolean transposeb;
  /*
   * / X1: same as the last dimension of the input tensor
   */
  uint64_t weightmatrixfirstdimension;
  /*
   * / X2: same as the last dimension of the output tensor
   */
  uint64_t weightmatrixseconddimension;
  /*
   * / Whether a bias is added or not. Supported only when there is one input.
   */
  protobuf_c_boolean hasbias;
  /*
   * Weight matrix representing shape [X1, X2].
   * Values are however stored in column major order,
   * in the "repeated float" or "bytes" fields of the message "WeightParams"
   */
  CoreML__Specification__WeightParams *weights;
  /*
   * / Bias vector [X2]. Supported only when there is one input.
   */
  CoreML__Specification__WeightParams *bias;
  /*
   **
   * If set, this layer, at runtime, quantizes the floating point input blob to int8 before applying the
   * matrix multiplication using the INT8 weight parameters provided in weights->int8RawValue. The
   * result is then dequantized.
   * Requires:
   * * number of inputs to be 1
   * * hasBias == false
   * * QuantizationType == LinearQuantizationParams, such that
   *   * size of the "scale" field is 1 and "bias" field is empty in "LinearQuantizationParams"
   * * numberOfBits == 8
   * * weights->rawValue_size to be empty
   */
  protobuf_c_boolean int8dynamicquantize;
};
#define CORE_ML__SPECIFICATION__BATCHED_MAT_MUL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__batched_mat_mul_layer_params__descriptor) \
    , 0, 0, 0, 0, 0, NULL, NULL, 0 }


/*
 **
 * A layer that concatenates a list of tensors along a specified axis.
 * .. code::
 *      y = ConcatNDLayer(x1,x2,....)
 * Requires at least 2 input and produces 1 output.
 * Input
 *     The rank of the input tensors must match and all dimensions also must match, except for the dimension 'axis'.
 * Output
 *     Same rank as the input. The dimension along "axis", is the sum of the dimensions of the inputs.
 * example:
 * in1 : shape (3, 2), value = [[1, 2], [3, 4], [5, 6]]
 * in2 : shape (3, 2), value = [[7, 8], [9, 10], [11, 12]]
 * axis = 0
 * if interleave = False (default)
 * output : shape (6, 2)
 * output[0:3, :] = in1
 * output[3:6, :] = in2
 * value = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]]
 * if interleave = True
 * output : shape (6, 2)
 * output[0::2, :] = in1
 * output[1::2, :] = in2
 * value = [[1, 2], [7, 8], [3, 4], [9, 10], [5, 6], [11, 12]]
 */
struct  _CoreML__Specification__ConcatNDLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Dimension along which to concatenate. Supports negative values of the parameter 'axis'.
   */
  int64_t axis;
  /*
   **
   * (Only available in Core ML Specification >= 5 (iOS >= 14, macOS >= 11.0)
   * Interleave option. If True, concatenation is done via interleaving the inputs.
   * This requires all inputs to have the exact same shape.
   */
  protobuf_c_boolean interleave;
};
#define CORE_ML__SPECIFICATION__CONCAT_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__concat_ndlayer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that performs softmax normalization along a specified axis.
 * .. code::
 *      y = SoftmaxNDLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__SoftmaxNDLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Dimension on which the softmax would be performed. Supports negative values of the parameter 'axis'.
   */
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__SOFTMAX_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__softmax_ndlayer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that reverses specific dimensions of the input tensor.
 * It is similar in functionality to the numpy.flip method.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__ReverseLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Reverses each dimension of the input tensor for which corresponding reverseDim is set to True.
   * Requires len(reverseDim) == rank(inputTensor)
   */
  size_t n_reversedim;
  protobuf_c_boolean *reversedim;
};
#define CORE_ML__SPECIFICATION__REVERSE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reverse_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that reverses variable length slices.
 * Requires 2 inputs and produces 1 output.
 * 2 inputs, in order are denoted by "data", "seq_lengths".
 * "seq_lenghts" must be a rank 1 tensor, i.e. seq_lengths.shape = (B,)
 * which contains the lengths of the amount of sequence to be reversed, for each element of the batch.
 * Dimension "batchAxis" in "data" must be equal to B, i.e,
 * data.shape[batchAxis] = B.
 * According to the batch axis, input "data" is first divided into a batch of B inputs,
 * each of which is flipped along the dimension "sequenceAxis", by the amount specified in
 * "seq_lengths", the second input.
 * e.g.:
 * data [shape = (2,4)]:
 * [0 1 2 3]
 * [4 5 6 7]
 * seq_lengths [shape = (2,)]:
 * [3, 0]
 * batchAxis = 0
 * sequenceAxis = 1
 * output [shape = (2,4)]:
 * [2 1 0 3]
 * [4 5 6 7]
 * data [shape = (2,3,2)]:
 * [0 1]
 * [2 3]
 * [4 5] (slice = 0)
 * [6 7]
 * [8 9]
 * [10 11] (slice = 1)
 * seq_lengths [shape = (2,)]:
 * [2, 3]
 * batchAxis = 0
 * sequenceAxis = 1
 * output [shape = (2,3,2)]:
 * [2 3]
 * [0 1]
 * [4 5] (slice = 0)
 * [10 11]
 * [8 9]
 * [6 7] (slice = 1)
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__ReverseSeqLayerParams
{
  ProtobufCMessage base;
  /*
   * batch axis has to be strictly less than seq_axis
   */
  int64_t batchaxis;
  int64_t sequenceaxis;
};
#define CORE_ML__SPECIFICATION__REVERSE_SEQ_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reverse_seq_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that loads data as a parameter and provides it as an output.
 * .. code::
 *      y = LoadConstantNDLayer()
 * Requires no input and produces 1 output.
 * Output: A tensor with shape as provided in the parameter "shape"
 */
struct  _CoreML__Specification__LoadConstantNDLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The shape of the constant to be loaded.
   */
  size_t n_shape;
  uint64_t *shape;
  CoreML__Specification__WeightParams *data;
};
#define CORE_ML__SPECIFICATION__LOAD_CONSTANT_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__load_constant_ndlayer_params__descriptor) \
    , 0,NULL, NULL }


/*
 **
 * A layer that generates an output tensor with a constant value.
 * Input is only used to determine the shape of the output.
 * This layer is used to allocate a tensor with a dynamic shape (that of the input) and constant value.
 * Requires 1 input and produces 1 output.
 * .. code::
 *      y = FillLikeLayer(x)
 * Input
 *     A N-Dimensional tensor, whose values are ignored. Only the shape is used to
 *     infer the shape of the output.
 * Output
 *     A N-Dimensional tensor with the same shape as the input tensor.
 */
struct  _CoreML__Specification__FillLikeLayerParams
{
  ProtobufCMessage base;
  float value;
};
#define CORE_ML__SPECIFICATION__FILL_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__fill_like_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that generates an output tensor with a constant value.
 * This layer is used to allocate a tensor with a static shape and constant value.
 * Requires no input and produces 1 output.
 * .. code::
 *      y = FillStaticLayer(x)
 * Output
 *     A N-Dimensional tensor of shape "targetShape".
 */
struct  _CoreML__Specification__FillStaticLayerParams
{
  ProtobufCMessage base;
  float value;
  size_t n_targetshape;
  uint64_t *targetshape;
};
#define CORE_ML__SPECIFICATION__FILL_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__fill_static_layer_params__descriptor) \
    , 0, 0,NULL }


/*
 **
 * A layer that generates an output tensor with a constant value.
 * This layer is used to allocate a tensor with a dynamic shape (as specified by the input) and constant value.
 * Requires 1 input and produces 1 output.
 * .. code::
 *      y = FillDynamicLayer(x)
 * Input
 *     A rank 1 tensor specifying the shape of the output
 * Output
 *     An N-Dimensional tensor with the shape specified by the values in the input tensor.
 */
struct  _CoreML__Specification__FillDynamicLayerParams
{
  ProtobufCMessage base;
  float value;
};
#define CORE_ML__SPECIFICATION__FILL_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__fill_dynamic_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that returns the elements either from tensor x or tensor y,
 * depending on the value in the condition tensor.
 * It is similar in functionality to the numpy.where method with 3 inputs.
 * Requires 3 inputs and produces 1 output.
 * Inputs, in order, are the condition tensor, x and y.
 * for each vector index (i,...,j):
 *    output[i,...,j] = x[i,...,j] if condition[i,...,j] = True
 *                      y[i,...,j] if condition[i,...,j] = False
 * All the 3 inputs are first broadcasted to a common shape.
 * (the shapes must be broadcastable)
 * output.rank = max(input[0].rank, input[1].rank, input[2].rank)
 */
struct  _CoreML__Specification__WhereBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__WHERE_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__where_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric sine function.
 * .. code::
 *      y = SinLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__SinLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__SIN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sin_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric cosine function.
 * .. code::
 *      y = CosLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__CosLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__COS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__cos_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric tangent function.
 * .. code::
 *      y = TanLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__TanLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__TAN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__tan_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric arcsine function.
 * .. code::
 *      y = AsinLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AsinLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ASIN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__asin_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric arccosine function.
 * .. code::
 *      y = AcosLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AcosLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACOS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__acos_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric arctangent function.
 * .. code::
 *      y = AtanLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AtanLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ATAN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__atan_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic sine function.
 * .. code::
 *      y = SinhLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__SinhLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__SINH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sinh_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic cosine function.
 * .. code::
 *      y = CoshLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__CoshLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__COSH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__cosh_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic tangent function.
 * .. code::
 *      y = TanhLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__TanhLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__TANH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__tanh_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic arcsine function.
 * .. code::
 *      y = AsinhLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AsinhLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ASINH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__asinh_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic arccosine function.
 * .. code::
 *      y = AcoshLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AcoshLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ACOSH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__acosh_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes elementwise trigonometric hyperbolic arctangent function.
 * .. code::
 *      y = AtanhLayer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__AtanhLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ATANH_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__atanh_layer_params__descriptor) \
     }


/*
 **
 * A layer that raises each element in first tensor to the power of
 * corresponding element in the second tensor.
 * Supports conventional numpy-like broadcasting.
 * .. code::
 *      y = PowBroadcastableLayer(x)
 * Requires 2 inputs and produces 1 output.
 * Input
 *     - First N-Dimensional tensor
 *     - Second N-Dimensional tensor
 * Output
 *     An N-Dimensional tensor with the broadcast shape.
 */
struct  _CoreML__Specification__PowBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__POW_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__pow_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes the exponential of all elements in the input tensor, with the base 2.
 * .. code::
 *      y = Exp2Layer(x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__Exp2LayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__EXP2_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__exp2_layer_params__descriptor) \
     }


/*
 **
 * A layer that returns a tensor containing the indices of all non-zero
 * elements of input tensor.
 * It is similar in functionality to the numpy.where method with 1 input.
 * Requires 1 input and produces 1 output.
 * Output is of rank 2, of shape (N,R),
 * where N is the number of non-zero elements in the input and R is the rank of the input.
 * Output contains indices represented in the multi-index form
 * e.g.:
 * input {shape = (4,)}:
 * [0 1 0 2]
 * output {shape = (2,1)}:
 * [1]
 * [3]
 * input {shape = (3, 3)}:
 * [1 2 1]
 * [0 2 2]
 * [2 1 0]
 * output {shape = (7,1)}:
 * [0. 0.]
 * [0. 1.]
 * [0. 2.]
 * [1. 1.]
 * [1. 2.]
 * [2. 0.]
 * [2. 1.]
 */
struct  _CoreML__Specification__WhereNonZeroLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__WHERE_NON_ZERO_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__where_non_zero_layer_params__descriptor) \
     }


/*
 **
 * A layer that copies a tensor setting everything outside a central band in
 * each inner-most matrix to zero.
 * Requires 1 input and produces 1 output.
 * Parameters for matrix_band_part layer
 * band(m, n) = (num_lower < 0 || (m-n) <= num_lower) && (num_upper < 0 || (n-m) <= num_upper).
 * output[i, j, k, ..., m, n] = band(m, n) * input[i, j, k, ..., m, n]
 * Output shape is same as the input shape.
 * Rank of the input must be at least 2.
 * For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
 */
struct  _CoreML__Specification__MatrixBandPartLayerParams
{
  ProtobufCMessage base;
  int64_t numlower;
  int64_t numupper;
};
#define CORE_ML__SPECIFICATION__MATRIX_BAND_PART_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__matrix_band_part_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that copies a tensor setting everything outside upper triangular to zero.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input shape.
 * Rank of the input must be at least 2.
 * For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
 */
struct  _CoreML__Specification__UpperTriangularLayerParams
{
  ProtobufCMessage base;
  /*
   * Diagonal below which to zero elements. k = 0 (the default) is the main diagonal, k < 0 is below it and k > 0 is above
   */
  int64_t k;
};
#define CORE_ML__SPECIFICATION__UPPER_TRIANGULAR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__upper_triangular_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that copies a tensor setting everything outside lower triangular to zero.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input shape.
 * Rank of the input must be at least 2.
 * For rank higher than 2, the last 2 dimensions are treated as the matrix, while the rest are treated as batch.
 */
struct  _CoreML__Specification__LowerTriangularLayerParams
{
  ProtobufCMessage base;
  /*
   * Diagonal above which to zero elements. k = 0 (the default) is the main diagonal, k < 0 is below it and k > 0 is above
   */
  int64_t k;
};
#define CORE_ML__SPECIFICATION__LOWER_TRIANGULAR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__lower_triangular_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that broadcasts a tensor to a new shape.
 * Requires 2 inputs and produces 1 output.
 * First input is broadcast to produce the output, while the second input is only
 * used to determine the shape of the output. Values of second input are not used.
 * Output is a tensor with the same shape as the second input.
 */
struct  _CoreML__Specification__BroadcastToLikeLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__BROADCAST_TO_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__broadcast_to_like_layer_params__descriptor) \
     }


/*
 **
 * A layer that broadcasts a tensor to a new shape.
 * Requires 1 input and produces 1 output.
 * Output tensor is the broadcasted version of the input and has shape as specified in the
 * parameter "targetShape".
 */
struct  _CoreML__Specification__BroadcastToStaticLayerParams
{
  ProtobufCMessage base;
  size_t n_targetshape;
  uint64_t *targetshape;
};
#define CORE_ML__SPECIFICATION__BROADCAST_TO_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__broadcast_to_static_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that broadcasts a tensor to a new shape.
 * Requires 2 inputs and produces 1 output.
 * First input is the one that is broadcasted to produce the output.
 * Second input is a rank 1 tensor specifying the shape of the output.
 * Output tensor has shape as specified by the values in the 2nd input tensor.
 */
struct  _CoreML__Specification__BroadcastToDynamicLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__BROADCAST_TO_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__broadcast_to_dynamic_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise addition operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__AddBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ADD_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__add_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise maximum operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__MaxBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MAX_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__max_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise minimum operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__MinBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MIN_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__min_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise modular operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__ModBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MOD_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__mod_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise floor division operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__FloorDivBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__FLOOR_DIV_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__floor_div_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise subtract operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__SubtractBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__SUBTRACT_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__subtract_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise multiply operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__MultiplyBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__MULTIPLY_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__multiply_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise division operation with broadcast support.
 * Requires 2 inputs and produces 1 output.
 */
struct  _CoreML__Specification__DivideBroadcastableLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__DIVIDE_BROADCASTABLE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__divide_broadcastable_layer_params__descriptor) \
     }


/*
 **
 * Gather layer that gathers elements from the first input, along a specified axis,
 * at indices specified in the second input.
 * It is similar in functionality to the numpy.take method.
 * Requires 2 inputs and produces 1 output.
 * Given two inputs, 'data' and 'indices', gather the slices of 'data'
 * and store into output.
 * e.g.
 * for i in [0, length(indices) - 1]
 *    output[i] = data[indices[i]]  (1-D case, axis=0)
 * if axis = 0:
 * for each vector index (i,...,j)
 *    output[i,...,j,:,..,:] = data[indices[i,...,j],:,..,:]
 * output.rank = (data.rank - 1) + indices.rank
 * Negative indices and negative axis are supported.
 * e.g:
 * data shape = (2, 3)
 * indices shape = (6, 8)
 * axis = 0
 * output shape = (6, 8) + (3,) = (6, 8, 3)
 * data shape = (2, 3, 5)
 * indices shape = (6, 8)
 * axis = 1
 * output shape = (2,) + (6, 8) + (5,) =  (2, 6, 8, 5)
 */
struct  _CoreML__Specification__GatherLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__GATHER_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__gather_layer_params__descriptor) \
    , 0 }


struct  _CoreML__Specification__ScatterLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  /*
   * / mode of accumulation.
   */
  CoreML__Specification__ScatterMode mode;
};
#define CORE_ML__SPECIFICATION__SCATTER_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__scatter_layer_params__descriptor) \
    , 0, CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_UPDATE }


/*
 **
 * A layer that gathers elements from the first input, 'params', at the multi-indices specified
 * by the second input, 'indices'.
 * Requires 2 inputs and produces 1 output.
 * 'params' = input[0], 'indices' = input[1]
 * 'indices' is a rank K+1 tensor of shape [I_0, I_1, .., I_(K-1), I_K] which is viewed as a collection of
 * indices of (I_0 * I_1 * ... * I_(K-1)) points in the I_K dimensional space. For instance, the multi-index of the first point
 * is indices[0,0,...,0,:].
 * Here is how the output is constructed:
 * for i = 0,1,...,(I_0-1)
 *   ...
 *     for j = 0,1,....,(I_(K-1)-1)
 *          output[i,....,j,:,:,..,:] = params[indices[i,...,j,:], :,:,..,:]
 * Hence, output shape is [I_0, I_1,...,I(K-1)] + params.shape[I_K:]
 * output.rank = indices.rank - 1 + params.rank - indices.shape[-1]
 * e.g:
 * input[0] shape = (4, 2, 3, 4)
 * input[1] shape = (6, 2)
 * output shape = (6,) + (3, 4) = (6, 3, 4)
 * input[0] shape = (3, 3, 3, 4, 7)
 * input[1] shape = (3, 5)
 * output shape = (3,) + () = (3,)
 * input[0] shape = (5, 3, 2, 5)
 * input[1] shape = (2, 7, 3, 2)
 * output shape = (2, 7, 3) + (2, 5) = (2, 7, 3, 2, 5)
 */
struct  _CoreML__Specification__GatherNDLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__GATHER_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__gather_ndlayer_params__descriptor) \
     }


/*
 * A layer that scatters data into a new tensor according to multi-indices from the input.
 * This is the inverse operation of GatherND.
 * Requires 3 inputs and produces 1 output.
 * 3 inputs, in order are denoted as "container", "indices", "updates".
 * 'indices' is a rank K+1 tensor of shape [I_0, I_1, .., I_(K-1), I_K] which is viewed as a collection of
 * indices of (I_0 * I_1 * ... * I_(K-1)) points in the I_K dimensional space. For instance, the multi-index of the first point
 * is indices[0,0,...,0,:].
 * container.rank >= I_K
 * updates.rank = K + (container.rank - I_K)
 * shape of 'updates' = [I_0, I_1,...,I(K-1)] + container.shape[I_K:]
 * output = container
 * For each vector index (i,...,j) s.t. 0<=i<I_0,..., 0<=j<I_K
 *   output[indices[i,...,j,:], :,:,..,:] = updates[i,....,j,:,:,..,:] // if mode == "SCATTER_UPDATE"
 * The output has the same shape as the first input.
 * e.g:
 * container shape = (3, 2)
 * indices shape = (4, 2)
 * updates shape = (4,)
 * output shape = (3, 2)
 * container shape = (7, 6)
 * indices shape = (4, 7, 2, 5, 1)
 * updates shape = (4, 7, 2, 5, 6)
 * output shape = (7, 6)
 */
struct  _CoreML__Specification__ScatterNDLayerParams
{
  ProtobufCMessage base;
  /*
   * / mode of accumulation.
   */
  CoreML__Specification__ScatterMode mode;
};
#define CORE_ML__SPECIFICATION__SCATTER_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__scatter_ndlayer_params__descriptor) \
    , CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_UPDATE }


/*
 **
 * Gather layer that gathers elements from the first input, along a specified axis,
 * at indices specified in the second input.
 * It is similar in functionality to the numpy.take_along_axis method.
 * Requires 2 inputs and produces 1 output.
 * Given two inputs, 'data' and 'indices', gather the slices of 'data'
 * and store into output.
 * Both inputs and output have the same rank.
 * Output shape is same as the shape of 'indices'
 * Shapes of 'indices' and 'data' match, except at the 'axis' dimension.
 * This operation performs the following operation for axis=0:
 * for each vector index (i,j,....,k)
 *    output[i,j,....,k] = data[index[i,j,....,k],j,....,k]
 * Negative indices and negative axis are supported.
 * e.g:
 * data shape = (4, 4, 7)
 * indices shape = (4, 5, 7)
 * axis = 1
 * output shape = (4, 5, 7)
 */
struct  _CoreML__Specification__GatherAlongAxisLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__GATHER_ALONG_AXIS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__gather_along_axis_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that scatters data into a new tensor according to indices from
 * the input along the given axis into the output tensor.
 * This is the inverse operation of GatherAlongAxis.
 * It is similar in functionality to the numpy.put_along_axis method.
 * Requires 3 inputs and produces 1 output.
 * 3 inputs, in order are denoted as "container", "indices", "updates".
 * All inputs and output have the same rank.
 * Output shape is same as the shape of 'container'
 * Shapes of 'indices' and 'updates' match, which is same as the shape of 'container' except at the 'axis' dimension.
 * Negative indices and negative axis are supported.
 * This operation performs the following operation for axis=0:
 * output = container
 * for each vector index (i,j,....,k)
 *    output[index[i,j,....,k],j,....,k] = updates[i,j,....,k]
 * e.g.:
 * container shape = (2, 5, 6)
 * indices shape = (2, 2, 6)
 * updates shape = (2, 2, 6)
 * axis = -2
 * output shape = (2, 5, 6)
 */
struct  _CoreML__Specification__ScatterAlongAxisLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  /*
   * / mode of accumulation.
   */
  CoreML__Specification__ScatterMode mode;
};
#define CORE_ML__SPECIFICATION__SCATTER_ALONG_AXIS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__scatter_along_axis_layer_params__descriptor) \
    , 0, CORE_ML__SPECIFICATION__SCATTER_MODE__SCATTER_UPDATE }


/*
 **
 * A layer that stacks the input tensors along the given axis.
 * It is similar in functionality to the numpy.stack method.
 * Requires at least 2 inputs and produces 1 output.
 * All inputs must have the same shape.
 * Rank of the output is 1 greater than the rank of the inputs.
 * Negative indexing is supported for the "axis" parameter.
 * e.g.:
 * input shape = (2, 4, 2)
 * number of inputs = 5
 * axis = 3
 * output shape = (2, 4, 2, 5)
 * input shape = (2, 4, 2)
 * number of inputs = 5
 * axis = -2
 * output shape = (2, 4, 5, 2)
 */
struct  _CoreML__Specification__StackLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__STACK_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__stack_layer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that reshapes a tensor that does not alter the rank of the input.
 * Order of the data is left unchanged.
 * Requires 1 input and produces 1 output.
 * e.g:
 * input shape = (20,10)
 * targetShape = (5,-1)
 * output shape = (5,40)
 * input shape = (20,10,5)
 * targetShape = (0,2,25)
 * output shape = (20,2,25)
 * input shape = (10,3,5)
 * targetShape = (25,0,-1)
 * output shape = (25,3,2)
 */
struct  _CoreML__Specification__RankPreservingReshapeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Length of this field must be same as the input/output rank.
   * It can have 0's, in which case the corresponding input dimension is kept intact.
   * At most one element can be -1, in which case the output dimension is calculated from rest of the shape.
   */
  size_t n_targetshape;
  int64_t *targetshape;
};
#define CORE_ML__SPECIFICATION__RANK_PRESERVING_RESHAPE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__rank_preserving_reshape_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * Constant padding layer.
 * Pad the input array with a constant value, either along a single given axis or along a set of axes.
 * Requires 1 or 2 inputs and produces 1 output.
 * The amount of padding can be either set as a parameter ("padAmounts") or provided as a second input.
 * Output rank is same as the rank of the first input.
 * when "padToGivenOutputSizeMode" is False:
 * output_shape[i] = input_shape[i] + padAmounts[2*i] + padAmounts[2*i+1], i=0,...,rank-1
 * Examples:
 * input shape = (20,10)
 * padAmounts = [0,1,4,0]
 * output shape = (21,14)
 * input shape = (20,10,5)
 * padAmounts = [0,0,3,4,0,9]
 * output shape = (20,17,14)
 * when "padToGivenOutputSizeMode" is True
 * output_shape[i] = max(input_shape[i], max(padAmounts[2*i] + padAmounts[2*i+1])), i=0,...,rank-1
 * input shape = (20,10)
 * padAmounts = [0,21,14,0]
 * output shape = (21,14)
 * input shape = (20,10,5)
 * padAmounts = [0,0,17,0,0,14]
 * output shape = (20,17,14)
 */
struct  _CoreML__Specification__ConstantPaddingLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The value to be used for padding.
   */
  float value;
  /*
   **
   * Length of this repeated field must be twice the rank of the first input.
   * 2*i-th and (2*i+1)-th values represent the amount of padding to be applied to the i-th input
   * dimension, "before" and "after" the input values, respectively.
   */
  size_t n_padamounts;
  uint64_t *padamounts;
  /*
   **
   * When this is True, positive values in "padAmounts" are equivalent to the output shape.
   * In that case only one of padAmounts[2*i] and padAmounts[2*i+1] can be non zero, for i=0,..,rank-1.
   */
  protobuf_c_boolean padtogivenoutputsizemode;
};
#define CORE_ML__SPECIFICATION__CONSTANT_PADDING_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__constant_padding_layer_params__descriptor) \
    , 0, 0,NULL, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the normal distribution.
 * Requires 1 input and produces 1 output.
 * Parameters
 *     seed: seed used for the normal distribution.
 *     mean: mean of the normal distribution.
 *     stdDev: standard deviation of the normal distribution.
 * Input
 *     An N-Dimensional tensor, whose values are ignored. Only the shape is used to
 *     infer the shape of the output.
 * Output
 *     An N-Dimensional tensor with the same shape as the input tensor.
 */
struct  _CoreML__Specification__RandomNormalLikeLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float mean;
  float stddev;
};
#define CORE_ML__SPECIFICATION__RANDOM_NORMAL_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_normal_like_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the normal distribution.
 * Requires no input and produces 1 output.
 * Parameters
 *     seed: seed used for the normal distribution.
 *     mean: mean of the normal distribution.
 *     stdDev: standard deviation of the normal distribution.
 *     outputShape: shape of the output tensor.
 * Output
 *     An N-Dimensional tensor of shape "outputShape".
 */
struct  _CoreML__Specification__RandomNormalStaticLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float mean;
  float stddev;
  size_t n_outputshape;
  uint64_t *outputshape;
};
#define CORE_ML__SPECIFICATION__RANDOM_NORMAL_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_normal_static_layer_params__descriptor) \
    , 0, 0, 0, 0,NULL }


/*
 **
 * A layer that returns a tensor filled with values from the normal distribution.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *     seed: seed used for the normal distribution.
 *     mean: mean of the normal distribution.
 *     stdDev: standard deviation of the normal distribution.
 * Input
 *     A rank 1 tensor specifying the shape of the output
 * Output
 *     An N-Dimensional tensor with the shape specified by the values in the input tensor.
 */
struct  _CoreML__Specification__RandomNormalDynamicLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float mean;
  float stddev;
};
#define CORE_ML__SPECIFICATION__RANDOM_NORMAL_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_normal_dynamic_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the uniform distribution.
 * Requires 1 input and produces 1 output.
 * Parameters
 *     seed: seed used for the uniform distribution.
 *     minVal: lower bound on the range of random values for the uniform distribution.
 *     maxVal: upper bound on the range of random values for the uniform distribution.
 * Input
 *     An N-Dimensional tensor, whose values are ignored. Only the shape is used to
 *     infer the shape of the output.
 * Output
 *     An N-Dimensional tensor with the same shape as the input tensor.
 */
struct  _CoreML__Specification__RandomUniformLikeLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float minval;
  float maxval;
};
#define CORE_ML__SPECIFICATION__RANDOM_UNIFORM_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_uniform_like_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the uniform distribution.
 * Requires no input and produces 1 output.
 * Parameters
 *     seed: seed used for the uniform distribution.
 *     minVal: lower bound on the range of random values for the uniform distribution.
 *     maxVal: upper bound on the range of random values for the uniform distribution.
 *     outputShape: shape of the output tensor.
 * Output
 *     An N-Dimensional tensor of shape "outputShape".
 */
struct  _CoreML__Specification__RandomUniformStaticLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float minval;
  float maxval;
  size_t n_outputshape;
  uint64_t *outputshape;
};
#define CORE_ML__SPECIFICATION__RANDOM_UNIFORM_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_uniform_static_layer_params__descriptor) \
    , 0, 0, 0, 0,NULL }


/*
 **
 * A layer that returns a tensor filled with values from the uniform distribution.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *     seed: seed used for the uniform distribution.
 *     minVal: lower bound on the range of random values for the uniform distribution.
 *     maxVal: upper bound on the range of random values for the uniform distribution.
 * Input
 *     A rank 1 tensor specifying the shape of the output
 * Output
 *     An N-Dimensional tensor with the shape specified by the values in the input tensor.
 */
struct  _CoreML__Specification__RandomUniformDynamicLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float minval;
  float maxval;
};
#define CORE_ML__SPECIFICATION__RANDOM_UNIFORM_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_uniform_dynamic_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the Bernoulli distribution.
 * Requires 1 input and produces 1 output.
 * Parameters
 *     seed: seed used for the Bernoulli distribution.
 *     prob: probability of a 1 event.
 * Input
 *     An N-Dimensional tensor, whose values are ignored. Only the shape is used to
 *     infer the shape of the output.
 * Output
 *     An N-Dimensional tensor with the same shape as the input tensor.
 */
struct  _CoreML__Specification__RandomBernoulliLikeLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float prob;
};
#define CORE_ML__SPECIFICATION__RANDOM_BERNOULLI_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_bernoulli_like_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that returns a tensor filled with values from the Bernoulli distribution.
 * Requires no input and produces 1 output.
 * Parameters
 *     seed: seed used for the Bernoulli distribution.
 *     prob: probability of a 1 event.
 *     outputShape: shape of the output tensor.
 * Output
 *     An N-Dimensional tensor of shape "outputShape".
 */
struct  _CoreML__Specification__RandomBernoulliStaticLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float prob;
  size_t n_outputshape;
  uint64_t *outputshape;
};
#define CORE_ML__SPECIFICATION__RANDOM_BERNOULLI_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_bernoulli_static_layer_params__descriptor) \
    , 0, 0, 0,NULL }


/*
 **
 * A layer that returns a tensor filled with values from the Bernoulli distribution.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *     seed: seed used for the Bernoulli distribution.
 *     prob: probability of a 1 event.
 * Input
 *     A rank 1 tensor specifying the shape of the output
 * Output
 *     An N-Dimensional tensor with the shape specified by the values in the input tensor.
 */
struct  _CoreML__Specification__RandomBernoulliDynamicLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  float prob;
};
#define CORE_ML__SPECIFICATION__RANDOM_BERNOULLI_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__random_bernoulli_dynamic_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that returns a tensor of the specified shape filled with values from the categorical distribution.
 * Requires 1 input and produces 1 output.
 * Parameter:
 *     seed: seed used for the categorical distribution.
 *     numSamples: number of samples to draw.
 *     isLogits: true if the inputs are logits, false if the inputs are probabilities.
 *     eps: default value is 1e-10.
 *     temperature: default value is 1.0.
 * Input tensor shape = [D_1, D_2, ... , D_(R-1), D_R] (Rank = R)
 * Then the shape of the output is [D_1, D_2, ... , D_(R-1), numSamples] (Rank = R)
 */
struct  _CoreML__Specification__CategoricalDistributionLayerParams
{
  ProtobufCMessage base;
  int64_t seed;
  int64_t numsamples;
  protobuf_c_boolean islogits;
  float eps;
  float temperature;
};
#define CORE_ML__SPECIFICATION__CATEGORICAL_DISTRIBUTION_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__categorical_distribution_layer_params__descriptor) \
    , 0, 0, 0, 0, 0 }


/*
 **
 * A layer that performs reduction with L1 normalization operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceL1LayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_L1_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_l1_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with L2 normalization operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceL2LayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_L2_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_l2_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with max operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceMaxLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_MAX_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_max_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with min operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceMinLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_MIN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_min_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with sum operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceSumLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_SUM_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_sum_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with prod operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceProdLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_PROD_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_prod_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with mean operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceMeanLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_MEAN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_mean_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with logSum operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceLogSumLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_LOG_SUM_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_log_sum_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with logSumExp operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceSumSquareLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_SUM_SQUARE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_sum_square_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that performs reduction with logSumExp operation.
 * Negative indexing is supported.
 * Requires 1 input and produces 1 output.
 * Parameters:
 *    axes: dimensions along which to perform reduction
 *    keepDims: if True, keep the reduced dimensions (value will be 1), otherwise, reduced dimensions are squeezed
 *    reduceAll: ignore the "axes" parameter, perform reduction along all axes
 */
struct  _CoreML__Specification__ReduceLogSumExpLayerParams
{
  ProtobufCMessage base;
  size_t n_axes;
  int64_t *axes;
  protobuf_c_boolean keepdims;
  protobuf_c_boolean reduceall;
};
#define CORE_ML__SPECIFICATION__REDUCE_LOG_SUM_EXP_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reduce_log_sum_exp_layer_params__descriptor) \
    , 0,NULL, 0, 0 }


/*
 **
 * A layer that increases the rank of the input tensor by adding unit dimensions.
 * Requires 1 input and produces 1 output.
 * e.g.:
 * input shape = (10,5)
 * axes = (0,1)
 * output shape = (1,1,10,5)
 * input shape = (10,5)
 * axes = (0,2)
 * output shape = (1,10,1,5)
 * input shape = (10,5)
 * axes = (-2,-1)
 * output shape = (10,5,1,1)
 */
struct  _CoreML__Specification__ExpandDimsLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Axis values provided here get dimension 1 in the output tensor.
   * Negative indexing is supported.
   */
  size_t n_axes;
  int64_t *axes;
};
#define CORE_ML__SPECIFICATION__EXPAND_DIMS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__expand_dims_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that flattens the input tensor into a 2-dimensional matrix.
 * Requires 1 input and produces 1 output.
 * Output tensor is always rank 2.
 * First dimension of output is the product of all the dimensions in input[:axis] ("axis" is exclusive)
 * Second dimension of output is the product of all the dimensions in input[axis:] ("axis" is inclusive)
 * e.g.:
 * input shape:  (3,)
 * axis:  -1
 * output shape:  (1, 3)
 * input shape:  (3,)
 * axis:  1
 * output shape:  (3, 1)
 * input shape:  (4, 3)
 * axis:  -1
 * output shape:  (4, 3)
 * input shape:  (5, 2)
 * axis:  0
 * output shape:  (1, 10)
 * input shape:  (5, 5, 3)
 * axis:  -2
 * output shape:  (5, 15)
 * input shape:  (2, 3, 2)
 * axis:  -1
 * output shape:  (6, 2)
 */
struct  _CoreML__Specification__FlattenTo2DLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__FLATTEN_TO2_DLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__flatten_to2_dlayer_params__descriptor) \
    , 0 }


/*
 **
 * A layer that reshapes a tensor.
 * Requires 1 input and produces 1 output.
 * Output tensor is the reshaped version of the input and has shape as specified in the
 * parameter "targetShape".
 */
struct  _CoreML__Specification__ReshapeStaticLayerParams
{
  ProtobufCMessage base;
  size_t n_targetshape;
  int64_t *targetshape;
};
#define CORE_ML__SPECIFICATION__RESHAPE_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reshape_static_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that reshapes a tensor.
 * Requires 2 inputs and produces 1 output.
 * First input is reshaped to produce the output, while the second input is only
 * used to determine the shape of the output. Values of the second input are not used.
 * Output is a tensor with the same shape as the second input.
 */
struct  _CoreML__Specification__ReshapeLikeLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__RESHAPE_LIKE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reshape_like_layer_params__descriptor) \
     }


/*
 **
 * A layer that reshapes a tensor.
 * Requires 2 inputs and produces 1 output.
 * First input is the one that is reshaped to produce the output.
 * Second input is a rank 1 tensor specifying the shape of the output.
 * Output tensor has shape as specified by the values in the 2nd input tensor.
 */
struct  _CoreML__Specification__ReshapeDynamicLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__RESHAPE_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__reshape_dynamic_layer_params__descriptor) \
     }


/*
 **
 * A layer that decreases the rank of the input tensor by removing unit dimensions.
 * Requires 1 input and produces 1 output.
 * Output rank is one less than input rank, if input rank is more than 1.
 * If input rank is 1, output rank is also 1.
 * e.g.:
 * input shape = (1,1,10,5)
 * axes = (0,1)
 * output shape = (10,5)
 * input shape = (1,10,5,1)
 * axes = (0,3)
 * output shape = (10,5)
 * input shape = (10,5,1,1)
 * axes = (-2,-1)
 * output shape = (10,5)
 * input shape = (1,)
 * axes = (0)
 * output shape = (1,)
 */
struct  _CoreML__Specification__SqueezeLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * Axis values provided here get removed from the input tensor.
   * Negative indexing is supported.
   */
  size_t n_axes;
  int64_t *axes;
  /*
   * if true squeeze all dimensions that are 1.
   */
  protobuf_c_boolean squeezeall;
};
#define CORE_ML__SPECIFICATION__SQUEEZE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__squeeze_layer_params__descriptor) \
    , 0,NULL, 0 }


/*
 **
 * A layer that returns top K (or bottom K) values and the corresponding indices
 * of the input along a given axis.
 * Requires 1 or 2 inputs and produces 2 outputs.
 * The second input is the value of the K, and is optional.
 * If there is only one input, value of K that is specified in the layer parameter is used.
 * Both outputs have the same rank as the first input.
 * Second input must correspond to a scalar tensor.
 * e.g.:
 * first input's shape = (45, 34, 10, 5)
 * axis = 1
 * output shape, for both outputs = (45, K, 10, 5)
 */
struct  _CoreML__Specification__TopKLayerParams
{
  ProtobufCMessage base;
  /*
   * /  negative indexing is supported
   */
  int64_t axis;
  /*
   * / is ignored if a second input is present.
   */
  uint64_t k;
  /*
   * / if true, bottom K (values, indices) are returned instead
   */
  protobuf_c_boolean usebottomk;
};
#define CORE_ML__SPECIFICATION__TOP_KLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__top_klayer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns the indices of the maximum value along a specified axis in a tensor.
 * Requires 1 input and produces 1 output. Negative indexing is supported.
 * Output has the same rank as the input if "removeDim" is False (default).
 * Output has rank one less than the input if "removeDim" is True and input rank is more than 1.
 * e.g.:
 * input shape = (45, 34, 10, 5)
 * axis = -2
 * output shape = (45, 1, 10, 5), if removeDim = False (default)
 * output shape = (45, 10, 5), if removeDim = True
 * input shape = (5,)
 * axis = 0
 * output shape = (1,), if removeDim = False or True
 */
struct  _CoreML__Specification__ArgMaxLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  protobuf_c_boolean removedim;
};
#define CORE_ML__SPECIFICATION__ARG_MAX_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__arg_max_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that returns the indices of the minimum value along a specified axis in a tensor.
 * Requires 1 input and produces 1 output. Negative indexing is supported.
 * Output has the same rank as the input if "removeDim" is False (default).
 * Output has rank one less than the input if "removeDim" is True and input rank is more than 1.
 * e.g.:
 * input shape = (45, 34, 10, 5)
 * axis = -2
 * output shape = (45, 1, 10, 5), if removeDim = False (default)
 * output shape = (45, 10, 5), if removeDim = True
 * input shape = (5,)
 * axis = 0
 * output shape = (1,), if removeDim = False or True
 */
struct  _CoreML__Specification__ArgMinLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  protobuf_c_boolean removedim;
};
#define CORE_ML__SPECIFICATION__ARG_MIN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__arg_min_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer layer that splits the input tensor into multiple output tensors,
 * along the specified axis.
 * The layer either uniformly splits the input tensor into ``num_splits`` tensors, or
 * splits according to the given split sizes in ``split_sizes``.
 * Supports unequal splits and negative indexing.
 * Requires 1 input and produces at least 2 outputs.
 * Rank of all the outputs is same as that of the input.
 * If parameter "splitSizes" is provided, value of the parameter "numSplits" is ignored, since in that case
 * "numSplits" is automatically inferred to be the length of "splitSizes".
 * e.g.:
 * input shape:  (5, 3, 4)
 * axis = -3, split_sizes = [3, 2]
 * output shape:  (3, 3, 4)
 * output shape:  (2, 3, 4)
 */
struct  _CoreML__Specification__SplitNDLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  uint64_t numsplits;
  size_t n_splitsizes;
  uint64_t *splitsizes;
};
#define CORE_ML__SPECIFICATION__SPLIT_NDLAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__split_ndlayer_params__descriptor) \
    , 0, 0, 0,NULL }


/*
 **
 * A layer that performs element-wise ceil operation on the input tensor that
 * rounds the value to the smallest integer not less than x.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__CeilLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__CEIL_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__ceil_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise round operation on the input tensor
 * that rounds the value to the nearest integer.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__RoundLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ROUND_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__round_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise floor operation on the input tensor
 * that rounds the value to the largest integer not greater than x.
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__FloorLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__FLOOR_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__floor_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise sign operation (+1 for positive values,
 * -1 for negative values, 0 for zeros).
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__SignLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__SIGN_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sign_layer_params__descriptor) \
     }


/*
 **
 * A layer that performs element-wise clip operation. Clip the values in the
 * input tensor to the threshold values [min_value, max_value].
 * Requires 1 input and produces 1 output.
 * Parameter minVal: the minimum threshold.
 * Parameter maxVal: the maximum threshold.
 * output =  min(max(input, minVal), maxVal)
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__ClipLayerParams
{
  ProtobufCMessage base;
  float minval;
  float maxval;
};
#define CORE_ML__SPECIFICATION__CLIP_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__clip_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that extracts a slice of size ``(end - begin) / stride``
 * from the given input tensor.
 * Support negative indexing and negative strides.
 * Requires 1 input and produces 1 output.
 * Output rank is same as the input rank.
 * Value of beginIds, beginMasks, endIds, endMasks, strides are required parameters.
 * Lengths of all the parameters must equal the rank of the input.
 * i-th element of "beginIds" is ignored and assumed to be 0 if the i-th element of
 * "beginMasks" is True
 * i-th element of "endIds" is ignored and assumed to be -1 if the i-th element of
 * "endMasks" is True
 * e.g.:
 * if i-th element of "squeezeMasks" is set to True, only beginIds[i] would be sliced
 * out, and all other masks and inputs are ignored.
 * e.g. (without squeezeMasks):
 * input shape:  (5, 5, 5)
 * beginIds:  [1, 2, 3]
 * beginMasks:  [True, False, True]
 * endIds:  [3, -3, 2]
 * endMasks:  [False, True, True]
 * strides:  [2, 2, 2]
 * SqueezeMasks:  [False, False, False]
 * output shape:  (2, 2, 3)
 * This is equivalent to input[:3:2, 2::2, ::2]
 * e.g. (with squeezeMasks):
 * input shape:  (5, 5, 5)
 * beginIds:  [1, 2, 3]
 * beginMasks:  [True, False, True]
 * endIds:  [3, -3, 2]
 * endMasks:  [False, True, True]
 * strides:  [2, 2, 2]
 * SqueezeMasks:  [False, True, False]
 * output shape:  (2, 3)
 * This is equivalent to input[:3:2, 2, ::2]
 */
struct  _CoreML__Specification__SliceStaticLayerParams
{
  ProtobufCMessage base;
  size_t n_beginids;
  int64_t *beginids;
  size_t n_beginmasks;
  protobuf_c_boolean *beginmasks;
  size_t n_endids;
  int64_t *endids;
  size_t n_endmasks;
  protobuf_c_boolean *endmasks;
  size_t n_strides;
  int64_t *strides;
  size_t n_squeezemasks;
  protobuf_c_boolean *squeezemasks;
};
#define CORE_ML__SPECIFICATION__SLICE_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__slice_static_layer_params__descriptor) \
    , 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL }


/*
 **
 * A layer that extracts a slice of size ``(end - begin) / stride``
 * from the given input tensor.
 * Support negative indexing and negative strides.
 * See "SliceStaticLayerParams" for the description and an example of the functionality of the layer.
 * Requires 2 to 7 inputs and produces 1 output.
 * Rank of the output is same as the rank of the first input unless squeezeMask is set.
 * Value of beginIds, beginMasks, endIds, endMasks, strides can be passed in either
 * as dynamic inputs or as static parameters.
 * Lengths of all the parameters or inputs from 2-6 must equal the rank of the first input.
 * The 2nd input represents the "beginIds".
 * The 3rd input, if present, corresponds to "endIds". In this case the value of the "endIds" parameter is ignored.
 * The 4th input, if present, corresponds to "strides". In this case the value of the "strides" parameter is ignored.
 * The 5th input, if present, corresponds to "beginMasks". In this case the value of the "beginMasks" parameter is ignored.
 * The 6th input, if present, corresponds to "endMasks". In this case the value of the "endMasks" parameter is ignored.
 * The 7th input, if present, corresponds to "squeezeMasks". In this case the value of the "squeezeMasks" parameter is ignored.
 */
struct  _CoreML__Specification__SliceDynamicLayerParams
{
  ProtobufCMessage base;
  size_t n_beginmasks;
  protobuf_c_boolean *beginmasks;
  size_t n_endids;
  int64_t *endids;
  size_t n_endmasks;
  protobuf_c_boolean *endmasks;
  size_t n_strides;
  int64_t *strides;
  size_t n_squeezemasks;
  protobuf_c_boolean *squeezemasks;
};
#define CORE_ML__SPECIFICATION__SLICE_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__slice_dynamic_layer_params__descriptor) \
    , 0,NULL, 0,NULL, 0,NULL, 0,NULL, 0,NULL }


/*
 **
 * A layer that constructs a tensor by repeating the input tensor multiple
 * number of times.
 * Requires 1 or 2 inputs and produces 1 output.
 * Output rank is same as the input rank.
 * If two inputs are provided, second input is used as "reps"
 * and "reps" parameter is ignored.
 * If only one input is provided,
 * length of the "reps" parameter must be at least 1 and
 * not greater than the rank of the input.
 * If it is less than the input rank, it is made equal to the input rank by prepending 1's to it.
 * e.g.:
 * input shape = (2, 4, 2)
 * reps = (1, 2, 6)
 * output shape = (2, 8, 12)
 * input shape = (2, 4, 2)
 * reps = (6)
 * reps after prepending ones = (1, 1, 6)
 * output shape = (2, 4, 12)
 * input shape = (2, 4, 2)
 * second input = [1, 2, 6] -> shape: (3,)
 * reps = N/A [Ignored]
 * output shape = (2, 8, 12)
 */
struct  _CoreML__Specification__TileLayerParams
{
  ProtobufCMessage base;
  size_t n_reps;
  uint64_t *reps;
};
#define CORE_ML__SPECIFICATION__TILE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__tile_layer_params__descriptor) \
    , 0,NULL }


/*
 **
 * A layer that returns the shape of an input tensor.
 * Requires 1 input and produces 1 output.
 * Input: a tensor.
 * Output: a vector of length R, where R is the rank of the input tensor
 * Output is always a rank 1 tensor.
 */
struct  _CoreML__Specification__GetShapeLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__GET_SHAPE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__get_shape_layer_params__descriptor) \
     }


/*
 **
 * A layer that computes the Gauss error function,
 * which is defined as:
 * .. math::
 *     f(x) = \dfrac{1}{\sqrt{\pi}}\int_{-x}^{x}{e^{-t^2}dt}
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__ErfLayerParams
{
  ProtobufCMessage base;
};
#define CORE_ML__SPECIFICATION__ERF_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__erf_layer_params__descriptor) \
     }


/*
 **
 * A layer that evaluates the Gaussian Error Linear Unit (GELU) activation.
 * Following equations are used to compute the activation based on the value of the "mode" parameter:
 * mode == 'EXACT':
 * .. math::
 *     f(x) = 0.5x\left ( 1+\rm{erf}\left ( \frac{x}{\sqrt{2}} \right ) \right )
 * mode == 'TANH_APPROXIMATION':
 * .. math::
 *     f(x) = 0.5x\left ( 1+\rm{tanh}\left ( \sqrt{2/\pi}\left ( x + 0.044715x^3 \right ) \right ) \right )
 * mode == 'SIGMOID_APPROXIMATION':
 * .. math::
 *     f(x) = x*\rm{sigmoid}(1.702x)
 * Requires 1 input and produces 1 output.
 * Output shape is same as the input.
 */
struct  _CoreML__Specification__GeluLayerParams
{
  ProtobufCMessage base;
  /*
   * / mode of GELU operation.
   */
  CoreML__Specification__GeluLayerParams__GeluMode mode;
};
#define CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__gelu_layer_params__descriptor) \
    , CORE_ML__SPECIFICATION__GELU_LAYER_PARAMS__GELU_MODE__EXACT }


/*
 **
 * RangeStatic layer that returns a tensor that contains evenly spaced values.
 * It is similar in functionality to the numpy.arange method.
 * Requires no input and produces 1 output.
 * Output is a rank 1 tensor.
 */
struct  _CoreML__Specification__RangeStaticLayerParams
{
  ProtobufCMessage base;
  float endvalue;
  float startvalue;
  float stepsizevalue;
};
#define CORE_ML__SPECIFICATION__RANGE_STATIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__range_static_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that returns a tensor that contains evenly spaced values.
 * Its functionality is similar to the numpy.arange method.
 * Requires at least 1 input, up to a maximum of 3 inputs.
 * Produces 1 output, which is a rank 1 tensor.
 * Each input must be a scalar, or rank 1 and shape (1,).
 * The first input represents the "endValue".
 * The second input, if present, corresponds to "startValue". In this case the value of the "startValue" parameter is ignored.
 * The third input, if present, corresponds to "stepSizeValue". In this case the value of the "stepSizeValue" parameter is ignored.
 */
struct  _CoreML__Specification__RangeDynamicLayerParams
{
  ProtobufCMessage base;
  float startvalue;
  float stepsizevalue;
};
#define CORE_ML__SPECIFICATION__RANGE_DYNAMIC_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__range_dynamic_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that returns a tensor containing all windows of size ``windowSize``
 * separated by ``step`` along the dimension ``axis``.
 * .. code::
 *      y = SlidingWindows(x)
 * Requires 1 input and produces 1 output.
 * Input
 *     An N-Dimensional tensor.
 * Output
 *     An (N+1)-Dimensional tensor.
 * This operation behaves as following:
 *      - if axis = 0 & input is rank 1 (L,). Output shape will be (M, W).
 *      - if axis = 1 & input is rank 3 (B1, L, C1). Output shape will be (B1, M, W, C1)
 *      - if axis = 2 & input is rank 5 (B1, B2, L, C1, C2) --> (B1 * B2, L, C1 * C2) --> (B1 * B2, M, W, C1 * C2). Output shape will be (B1, B2, M, W, C1, C2)
 *      - etc.
 * where
 *      - L, C, B refer to input length, feature dimension length & batch size respectively
 *      - W is the window size.
 *      - M is the number of windows/slices calculated as M = (L - W) / step + 1
 */
struct  _CoreML__Specification__SlidingWindowsLayerParams
{
  ProtobufCMessage base;
  int64_t axis;
  uint64_t windowsize;
  uint64_t step;
};
#define CORE_ML__SPECIFICATION__SLIDING_WINDOWS_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sliding_windows_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A layer that applies layer normalization over the input tensor.
 * Requires 1 input and produces 1 output.
 * output = gamma * (input - computed_mean) / (sqrt(computed_variance + eps)) + beta
 * Parameters
 *     normalizedShape: subset of the input shape, along with layer norm is performed, rest of the input shape is treated as the batch dimension. The mean and variance are computed for the input, over the last few dimensions as specified by the normalizedShape parameter.
 *     gamma: must have shape = "normalizedShape"
 *     beta: must have shape = "normalizedShape"
 *     eps: small constant to avoid division by 0
 * Output shape is same as the input.
 * e.g.:
 * input shape = (10,5)
 * normalized shape = (5,) or (10,5)
 * input shape = (10,5,6,7)
 * normalized shape = (7,) or (6,7) or (5,6,7) or (10,5,6,7)
 */
struct  _CoreML__Specification__LayerNormalizationLayerParams
{
  ProtobufCMessage base;
  size_t n_normalizedshape;
  int64_t *normalizedshape;
  float eps;
  CoreML__Specification__WeightParams *gamma;
  CoreML__Specification__WeightParams *beta;
};
#define CORE_ML__SPECIFICATION__LAYER_NORMALIZATION_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__layer_normalization_layer_params__descriptor) \
    , 0,NULL, 0, NULL, NULL }


/*
 **
 * Non maximum suppression (NMS) layer.
 * Applies the non maximum suppression algorithm to input bounding box coordinates.
 * The effect of this layer is similar to the functionality of the "NonMaximumSuppression"
 * model type (for details please see NonMaximumSuppression.proto) with a couple of differences.
 * One, this is a layer in a neural network model, whereas that is a different model type. Second,
 * this layer supports a batch of bounding boxes.
 * The NMS layer requires at least 2 inputs, and up to a maximum of 5 inputs. It produces 4 outputs.
 * Following is the description of inputs and outputs:
 * input 1, shape (B,N,4): coordinates of N boxes, for a batch size B.
 * input 2, shape (B,N,C): class scores for each box. C can be 1 when there is only 1 score per box, i.e., no class specific score.
 * input 3, optional, shape (1,): IoU threshold. When present, it overwrites the value provided in layer parameter "iouThreshold".
 * input 4, optional, shape (1,): Score threshold. When present, it overwrites the value provided in layer parameter "scoreThreshold".
 * input 5, optional, shape (1,): Maximum number of boxes. When present, it overwrites the value provided in layer parameter "maxBoxes".
 * output 1, shape (B,maxBoxes,4): box coordinates, corresponding to the surviving boxes.
 * output 2, shape (B,maxBoxes,C): box scores, corresponding to the surviving boxes.
 * output 3, shape (B,maxBoxes): indices of the surviving boxes. Hence it will have values in the range [0,N-1], except for padding.
 * output 4, shape (B,): number of boxes selected after the NMS algorithm, for each batch.
 * When surviving boxes are less than "maxBoxes", the first 3 outputs are padded.
 * For the first two outputs, the padding is done using values 0, whereas for the third output the
 * padding value used is -1, since the output values represent indices.
 * If no box survives, that is, all the scores are below the "scoreThreshold",
 * then for that batch, number of boxes (value of the fourth output) will be 1. The first 3 outputs will
 * correspond to the box with the highest score. This is to avoid generating an "empty" output.
 * The four values that describe the box dimensions are (in order):
 *  - x (center location of the box along the horizontal axis)
 *  - y (center location of the box along the vertical axis)
 *  - width (size of box along the horizontal axis)
 *  - height (size of box on along the vertical axis)
 * In each batch,
 * the N scores for N boxes, used for suppression, are generated by taking the max of the matrix (N,C)
 * along the columns.
 * If "perClassSuppression" flag is false, suppression happens across all classes.
 * If "perClassSuppression" flag is true, each box is assigned to the class with the highest
 * score and then the suppression happens separately for boxes within the same class.
 * Note that the 4th output can be used to dynamically slice the first 3 outputs, in case
 * the padded outputs are not required.
 */
struct  _CoreML__Specification__NonMaximumSuppressionLayerParams
{
  ProtobufCMessage base;
  /*
   **
   * The intersection over union (IoU) threshold over which boxes are suppressed.
   */
  float iouthreshold;
  /*
   **
   * Before IoU suppression is performed, boxes with class scores below this threshold are rejected.
   */
  float scorethreshold;
  /*
   **
   * The maximum number of boxes to be given out as output.
   * If the number of surviving boxes are less, output is padded up to this number.
   */
  uint64_t maxboxes;
  /*
   **
   * If true, suppression is performed independently within boxes of each class.
   */
  protobuf_c_boolean perclasssuppression;
};
#define CORE_ML__SPECIFICATION__NON_MAXIMUM_SUPPRESSION_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__non_maximum_suppression_layer_params__descriptor) \
    , 0, 0, 0, 0 }


/*
 **
 * A layer that performs element-wise clamped ReLU operation.
 * Requires 1 input and produces 1 output.
 * This function has the following formula:
 * .. math::
 *     f(x) = \begin{cases}
 *               \text{min}(\text{beta},x) \;\; \text{if} \;\; x \geq 0\\
 *               \text{min}(\text{beta} ,\text{alpha}\cdot x) \;\; \text{if} \;\; x<0
 *            \end{cases}
 * Output shape is same as the input.
 * Available (iOS >= 14, macOS >= 11.0, watchOS >= 7)
 */
struct  _CoreML__Specification__ClampedReLULayerParams
{
  ProtobufCMessage base;
  float alpha;
  float beta;
};
#define CORE_ML__SPECIFICATION__CLAMPED_RE_LULAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__clamped_re_lulayer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that returns the indices that would sort the input tensor, along a specified axis.
 * Requires 1 input and produces 1 output.
 * Output has the same rank and shape as the input.
 * Value of "axis" must be positive and less than the rank of the input.
 * e.g.:
 * input shape = (5,)
 * axis = 0
 * input values = [3.1, 5.4, 32.9, 3.2, 77.0]
 * output shape = (5,)
 * output values = [0, 3, 1, 2, 4], descending = False
 * output values = [4, 2, 1, 3, 0], descending = True
 * input shape = (2,3)
 * axis = 1
 * input values = [[3, 5, 32], [3, 77, 6]]
 * output shape = (2,3)
 * output values = [[0, 1, 2], [0, 2, 1]], descending = False
 * output values = [[2, 1, 0], [1, 2, 0]], descending = True
 */
struct  _CoreML__Specification__ArgSortLayerParams
{
  ProtobufCMessage base;
  /*
   * / must be between [0, input_rank - 1]
   */
  int64_t axis;
  protobuf_c_boolean descending;
};
#define CORE_ML__SPECIFICATION__ARG_SORT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__arg_sort_layer_params__descriptor) \
    , 0, 0 }


/*
 **
 * A layer that does slice operation by providing size to be extracted 
 * from the given input tensor.
 * Requires 2 inputs and produces 1 output.
 * Rank of the output is same as the rank of the first input.
 * The 1st input represents the tensor to be sliced.
 * The 2nd input represents the beginning index to be sliced from.
 * Example:
 * Input 1: x (x.shape = (2, 3, 4))
 * Input 2: begin
 * size: 2
 * axis: 1
 * Output: x[:, begin:begin+2, :]
 */
struct  _CoreML__Specification__SliceBySizeLayerParams
{
  ProtobufCMessage base;
  int64_t size;
  int64_t axis;
};
#define CORE_ML__SPECIFICATION__SLICE_BY_SIZE_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__slice_by_size_layer_params__descriptor) \
    , 0, 0 }


typedef enum {
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__CLASS_LABELS__NOT_SET = 0,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__CLASS_LABELS_STRING_CLASS_LABELS = 100,
  CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__CLASS_LABELS_INT64_CLASS_LABELS = 101
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__CLASS_LABELS)
} CoreML__Specification__NeuralNetworkClassifier__ClassLabelsCase;

/*
 **
 * A neural network specialized as a classifier.
 */
struct  _CoreML__Specification__NeuralNetworkClassifier
{
  ProtobufCMessage base;
  size_t n_layers;
  CoreML__Specification__NeuralNetworkLayer **layers;
  size_t n_preprocessing;
  CoreML__Specification__NeuralNetworkPreprocessing **preprocessing;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
   */
  CoreML__Specification__NeuralNetworkMultiArrayShapeMapping arrayinputshapemapping;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for image inputs
   */
  CoreML__Specification__NeuralNetworkImageShapeMapping imageinputshapemapping;
  CoreML__Specification__NetworkUpdateParameters *updateparams;
  /*
   * The name of the output blob containing the probability of each class.
   * In other words, the score vector. Must be a 1-D tensor with the same
   * number and order of elements as ClassLabels.
   */
  char *labelprobabilitylayername;
  CoreML__Specification__NeuralNetworkClassifier__ClassLabelsCase class_labels_case;
  union {
    CoreML__Specification__StringVector *stringclasslabels;
    CoreML__Specification__Int64Vector *int64classlabels;
  };
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_classifier__descriptor) \
    , 0,NULL, 0,NULL, CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING__RANK5_ARRAY_MAPPING, CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING__RANK5_IMAGE_MAPPING, NULL, (char *)protobuf_c_empty_string, CORE_ML__SPECIFICATION__NEURAL_NETWORK_CLASSIFIER__CLASS_LABELS__NOT_SET, {0} }


struct  _CoreML__Specification__OneHotLayerParams
{
  ProtobufCMessage base;
  /*
   * / size of the one hot vector
   */
  uint64_t onehotvectorsize;
  /*
   * /  negative indexing is supported. It refers to the axis in the output tensor.
   */
  int64_t axis;
  float onvalue;
  float offvalue;
};
#define CORE_ML__SPECIFICATION__ONE_HOT_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__one_hot_layer_params__descriptor) \
    , 0, 0, 0, 0 }


struct  _CoreML__Specification__CumSumLayerParams
{
  ProtobufCMessage base;
  /*
   * /  negative indexing is supported
   */
  int64_t axis;
  /*
   * / if true, the first element of the output is 0, and the last element contains the sum of the input up to the penultimate value
   * / if false, the first element of the output is same as the input and the last element is the sum of all the input values
   * / (this behavior is reversed when "reverse" flag is True)
   */
  protobuf_c_boolean excludefinalsum;
  /*
   * / if true, cumsum is performed in the opposite direction
   */
  protobuf_c_boolean reverse;
};
#define CORE_ML__SPECIFICATION__CUM_SUM_LAYER_PARAMS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__cum_sum_layer_params__descriptor) \
    , 0, 0, 0 }


/*
 **
 * A neural network specialized as a regressor.
 */
struct  _CoreML__Specification__NeuralNetworkRegressor
{
  ProtobufCMessage base;
  size_t n_layers;
  CoreML__Specification__NeuralNetworkLayer **layers;
  size_t n_preprocessing;
  CoreML__Specification__NeuralNetworkPreprocessing **preprocessing;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for multiarray inputs
   */
  CoreML__Specification__NeuralNetworkMultiArrayShapeMapping arrayinputshapemapping;
  /*
   * use this enum value to determine the input tensor shapes to the neural network, for image inputs
   */
  CoreML__Specification__NeuralNetworkImageShapeMapping imageinputshapemapping;
  CoreML__Specification__NetworkUpdateParameters *updateparams;
};
#define CORE_ML__SPECIFICATION__NEURAL_NETWORK_REGRESSOR__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__neural_network_regressor__descriptor) \
    , 0,NULL, 0,NULL, CORE_ML__SPECIFICATION__NEURAL_NETWORK_MULTI_ARRAY_SHAPE_MAPPING__RANK5_ARRAY_MAPPING, CORE_ML__SPECIFICATION__NEURAL_NETWORK_IMAGE_SHAPE_MAPPING__RANK5_IMAGE_MAPPING, NULL }


/*
 **
 * Details on how the network will be updated
 */
struct  _CoreML__Specification__NetworkUpdateParameters
{
  ProtobufCMessage base;
  size_t n_losslayers;
  CoreML__Specification__LossLayer **losslayers;
  CoreML__Specification__Optimizer *optimizer;
  CoreML__Specification__Int64Parameter *epochs;
  /*
   **
   * Describes whether to shuffle the batch of data between epochs.
   */
  CoreML__Specification__BoolParameter *shuffle;
  /*
   **
   * The seed to be used in an associated random number generator.
   */
  CoreML__Specification__Int64Parameter *seed;
};
#define CORE_ML__SPECIFICATION__NETWORK_UPDATE_PARAMETERS__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__network_update_parameters__descriptor) \
    , 0,NULL, NULL, NULL, NULL, NULL }


typedef enum {
  CORE_ML__SPECIFICATION__LOSS_LAYER__LOSS_LAYER_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__LOSS_LAYER__LOSS_LAYER_TYPE_CATEGORICAL_CROSS_ENTROPY_LOSS_LAYER = 10,
  CORE_ML__SPECIFICATION__LOSS_LAYER__LOSS_LAYER_TYPE_MEAN_SQUARED_ERROR_LOSS_LAYER = 11
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__LOSS_LAYER__LOSS_LAYER_TYPE)
} CoreML__Specification__LossLayer__LossLayerTypeCase;

/*
 **
 * Loss layer - categorical cross entropy and mean squared error are the only supported loss functions currently
 */
struct  _CoreML__Specification__LossLayer
{
  ProtobufCMessage base;
  char *name;
  CoreML__Specification__LossLayer__LossLayerTypeCase loss_layer_type_case;
  union {
    CoreML__Specification__CategoricalCrossEntropyLossLayer *categoricalcrossentropylosslayer;
    CoreML__Specification__MeanSquaredErrorLossLayer *meansquarederrorlosslayer;
  };
};
#define CORE_ML__SPECIFICATION__LOSS_LAYER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__loss_layer__descriptor) \
    , (char *)protobuf_c_empty_string, CORE_ML__SPECIFICATION__LOSS_LAYER__LOSS_LAYER_TYPE__NOT_SET, {0} }


/*
 **
 * Categorical cross entropy loss layer
 * Categorical cross entropy is used for single label categorization (only one category is applicable for each data point).
 * The input is a vector of length N representing the distribution over N categories.  It must be the output of a softmax.
 * The target is a single value representing the true category or class label. If the target is the predictedFeatureName of a neural network classifier it will be inverse mapped to the corresponding categorical index for you.
 * math:
 * Loss_{CCE}(input, target) = -\sum_{i=1}^{N} (target == i) log( input[i] ) = - log (input[target])
 */
struct  _CoreML__Specification__CategoricalCrossEntropyLossLayer
{
  ProtobufCMessage base;
  char *input;
  char *target;
};
#define CORE_ML__SPECIFICATION__CATEGORICAL_CROSS_ENTROPY_LOSS_LAYER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__categorical_cross_entropy_loss_layer__descriptor) \
    , (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string }


/*
 **
 * Mean squared error loss layer,
 * specifying input and target
 */
struct  _CoreML__Specification__MeanSquaredErrorLossLayer
{
  ProtobufCMessage base;
  char *input;
  char *target;
};
#define CORE_ML__SPECIFICATION__MEAN_SQUARED_ERROR_LOSS_LAYER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__mean_squared_error_loss_layer__descriptor) \
    , (char *)protobuf_c_empty_string, (char *)protobuf_c_empty_string }


typedef enum {
  CORE_ML__SPECIFICATION__OPTIMIZER__OPTIMIZER_TYPE__NOT_SET = 0,
  CORE_ML__SPECIFICATION__OPTIMIZER__OPTIMIZER_TYPE_SGD_OPTIMIZER = 10,
  CORE_ML__SPECIFICATION__OPTIMIZER__OPTIMIZER_TYPE_ADAM_OPTIMIZER = 11
    PROTOBUF_C__FORCE_ENUM_TO_BE_INT_SIZE(CORE_ML__SPECIFICATION__OPTIMIZER__OPTIMIZER_TYPE)
} CoreML__Specification__Optimizer__OptimizerTypeCase;

/*
 **
 * Optimizer - stochastic gradient descent and adam are the only supported optimizers currently
 */
struct  _CoreML__Specification__Optimizer
{
  ProtobufCMessage base;
  CoreML__Specification__Optimizer__OptimizerTypeCase optimizer_type_case;
  union {
    CoreML__Specification__SGDOptimizer *sgdoptimizer;
    CoreML__Specification__AdamOptimizer *adamoptimizer;
  };
};
#define CORE_ML__SPECIFICATION__OPTIMIZER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__optimizer__descriptor) \
    , CORE_ML__SPECIFICATION__OPTIMIZER__OPTIMIZER_TYPE__NOT_SET, {0} }


/*
 **
 * Stochastic gradient descent optimizer,
 * specifying configurable learning rate, mini batch size, and momentum
 */
struct  _CoreML__Specification__SGDOptimizer
{
  ProtobufCMessage base;
  CoreML__Specification__DoubleParameter *learningrate;
  CoreML__Specification__Int64Parameter *minibatchsize;
  CoreML__Specification__DoubleParameter *momentum;
};
#define CORE_ML__SPECIFICATION__SGDOPTIMIZER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__sgdoptimizer__descriptor) \
    , NULL, NULL, NULL }


/*
 **
 * Adam optimizer,
 * specifying configurable learning rate, mini batch size, betas, and eps
 */
struct  _CoreML__Specification__AdamOptimizer
{
  ProtobufCMessage base;
  CoreML__Specification__DoubleParameter *learningrate;
  CoreML__Specification__Int64Parameter *minibatchsize;
  CoreML__Specification__DoubleParameter *beta1;
  CoreML__Specification__DoubleParameter *beta2;
  CoreML__Specification__DoubleParameter *eps;
};
#define CORE_ML__SPECIFICATION__ADAM_OPTIMIZER__INIT \
 { PROTOBUF_C_MESSAGE_INIT (&core_ml__specification__adam_optimizer__descriptor) \
    , NULL, NULL, NULL, NULL, NULL }


/* CoreML__Specification__NeuralNetwork methods */
void   core_ml__specification__neural_network__init
                     (CoreML__Specification__NeuralNetwork         *message);
size_t core_ml__specification__neural_network__get_packed_size
                     (const CoreML__Specification__NeuralNetwork   *message);
size_t core_ml__specification__neural_network__pack
                     (const CoreML__Specification__NeuralNetwork   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network__pack_to_buffer
                     (const CoreML__Specification__NeuralNetwork   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetwork *
       core_ml__specification__neural_network__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network__free_unpacked
                     (CoreML__Specification__NeuralNetwork *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkImageScaler methods */
void   core_ml__specification__neural_network_image_scaler__init
                     (CoreML__Specification__NeuralNetworkImageScaler         *message);
size_t core_ml__specification__neural_network_image_scaler__get_packed_size
                     (const CoreML__Specification__NeuralNetworkImageScaler   *message);
size_t core_ml__specification__neural_network_image_scaler__pack
                     (const CoreML__Specification__NeuralNetworkImageScaler   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_image_scaler__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkImageScaler   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkImageScaler *
       core_ml__specification__neural_network_image_scaler__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_image_scaler__free_unpacked
                     (CoreML__Specification__NeuralNetworkImageScaler *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkMeanImage methods */
void   core_ml__specification__neural_network_mean_image__init
                     (CoreML__Specification__NeuralNetworkMeanImage         *message);
size_t core_ml__specification__neural_network_mean_image__get_packed_size
                     (const CoreML__Specification__NeuralNetworkMeanImage   *message);
size_t core_ml__specification__neural_network_mean_image__pack
                     (const CoreML__Specification__NeuralNetworkMeanImage   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_mean_image__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkMeanImage   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkMeanImage *
       core_ml__specification__neural_network_mean_image__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_mean_image__free_unpacked
                     (CoreML__Specification__NeuralNetworkMeanImage *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkPreprocessing methods */
void   core_ml__specification__neural_network_preprocessing__init
                     (CoreML__Specification__NeuralNetworkPreprocessing         *message);
size_t core_ml__specification__neural_network_preprocessing__get_packed_size
                     (const CoreML__Specification__NeuralNetworkPreprocessing   *message);
size_t core_ml__specification__neural_network_preprocessing__pack
                     (const CoreML__Specification__NeuralNetworkPreprocessing   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_preprocessing__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkPreprocessing   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkPreprocessing *
       core_ml__specification__neural_network_preprocessing__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_preprocessing__free_unpacked
                     (CoreML__Specification__NeuralNetworkPreprocessing *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationReLU methods */
void   core_ml__specification__activation_re_lu__init
                     (CoreML__Specification__ActivationReLU         *message);
size_t core_ml__specification__activation_re_lu__get_packed_size
                     (const CoreML__Specification__ActivationReLU   *message);
size_t core_ml__specification__activation_re_lu__pack
                     (const CoreML__Specification__ActivationReLU   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_re_lu__pack_to_buffer
                     (const CoreML__Specification__ActivationReLU   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationReLU *
       core_ml__specification__activation_re_lu__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_re_lu__free_unpacked
                     (CoreML__Specification__ActivationReLU *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationLeakyReLU methods */
void   core_ml__specification__activation_leaky_re_lu__init
                     (CoreML__Specification__ActivationLeakyReLU         *message);
size_t core_ml__specification__activation_leaky_re_lu__get_packed_size
                     (const CoreML__Specification__ActivationLeakyReLU   *message);
size_t core_ml__specification__activation_leaky_re_lu__pack
                     (const CoreML__Specification__ActivationLeakyReLU   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_leaky_re_lu__pack_to_buffer
                     (const CoreML__Specification__ActivationLeakyReLU   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationLeakyReLU *
       core_ml__specification__activation_leaky_re_lu__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_leaky_re_lu__free_unpacked
                     (CoreML__Specification__ActivationLeakyReLU *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationTanh methods */
void   core_ml__specification__activation_tanh__init
                     (CoreML__Specification__ActivationTanh         *message);
size_t core_ml__specification__activation_tanh__get_packed_size
                     (const CoreML__Specification__ActivationTanh   *message);
size_t core_ml__specification__activation_tanh__pack
                     (const CoreML__Specification__ActivationTanh   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_tanh__pack_to_buffer
                     (const CoreML__Specification__ActivationTanh   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationTanh *
       core_ml__specification__activation_tanh__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_tanh__free_unpacked
                     (CoreML__Specification__ActivationTanh *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationScaledTanh methods */
void   core_ml__specification__activation_scaled_tanh__init
                     (CoreML__Specification__ActivationScaledTanh         *message);
size_t core_ml__specification__activation_scaled_tanh__get_packed_size
                     (const CoreML__Specification__ActivationScaledTanh   *message);
size_t core_ml__specification__activation_scaled_tanh__pack
                     (const CoreML__Specification__ActivationScaledTanh   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_scaled_tanh__pack_to_buffer
                     (const CoreML__Specification__ActivationScaledTanh   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationScaledTanh *
       core_ml__specification__activation_scaled_tanh__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_scaled_tanh__free_unpacked
                     (CoreML__Specification__ActivationScaledTanh *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationSigmoid methods */
void   core_ml__specification__activation_sigmoid__init
                     (CoreML__Specification__ActivationSigmoid         *message);
size_t core_ml__specification__activation_sigmoid__get_packed_size
                     (const CoreML__Specification__ActivationSigmoid   *message);
size_t core_ml__specification__activation_sigmoid__pack
                     (const CoreML__Specification__ActivationSigmoid   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_sigmoid__pack_to_buffer
                     (const CoreML__Specification__ActivationSigmoid   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationSigmoid *
       core_ml__specification__activation_sigmoid__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_sigmoid__free_unpacked
                     (CoreML__Specification__ActivationSigmoid *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationLinear methods */
void   core_ml__specification__activation_linear__init
                     (CoreML__Specification__ActivationLinear         *message);
size_t core_ml__specification__activation_linear__get_packed_size
                     (const CoreML__Specification__ActivationLinear   *message);
size_t core_ml__specification__activation_linear__pack
                     (const CoreML__Specification__ActivationLinear   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_linear__pack_to_buffer
                     (const CoreML__Specification__ActivationLinear   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationLinear *
       core_ml__specification__activation_linear__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_linear__free_unpacked
                     (CoreML__Specification__ActivationLinear *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationSigmoidHard methods */
void   core_ml__specification__activation_sigmoid_hard__init
                     (CoreML__Specification__ActivationSigmoidHard         *message);
size_t core_ml__specification__activation_sigmoid_hard__get_packed_size
                     (const CoreML__Specification__ActivationSigmoidHard   *message);
size_t core_ml__specification__activation_sigmoid_hard__pack
                     (const CoreML__Specification__ActivationSigmoidHard   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_sigmoid_hard__pack_to_buffer
                     (const CoreML__Specification__ActivationSigmoidHard   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationSigmoidHard *
       core_ml__specification__activation_sigmoid_hard__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_sigmoid_hard__free_unpacked
                     (CoreML__Specification__ActivationSigmoidHard *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationPReLU methods */
void   core_ml__specification__activation_pre_lu__init
                     (CoreML__Specification__ActivationPReLU         *message);
size_t core_ml__specification__activation_pre_lu__get_packed_size
                     (const CoreML__Specification__ActivationPReLU   *message);
size_t core_ml__specification__activation_pre_lu__pack
                     (const CoreML__Specification__ActivationPReLU   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_pre_lu__pack_to_buffer
                     (const CoreML__Specification__ActivationPReLU   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationPReLU *
       core_ml__specification__activation_pre_lu__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_pre_lu__free_unpacked
                     (CoreML__Specification__ActivationPReLU *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationELU methods */
void   core_ml__specification__activation_elu__init
                     (CoreML__Specification__ActivationELU         *message);
size_t core_ml__specification__activation_elu__get_packed_size
                     (const CoreML__Specification__ActivationELU   *message);
size_t core_ml__specification__activation_elu__pack
                     (const CoreML__Specification__ActivationELU   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_elu__pack_to_buffer
                     (const CoreML__Specification__ActivationELU   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationELU *
       core_ml__specification__activation_elu__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_elu__free_unpacked
                     (CoreML__Specification__ActivationELU *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationThresholdedReLU methods */
void   core_ml__specification__activation_thresholded_re_lu__init
                     (CoreML__Specification__ActivationThresholdedReLU         *message);
size_t core_ml__specification__activation_thresholded_re_lu__get_packed_size
                     (const CoreML__Specification__ActivationThresholdedReLU   *message);
size_t core_ml__specification__activation_thresholded_re_lu__pack
                     (const CoreML__Specification__ActivationThresholdedReLU   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_thresholded_re_lu__pack_to_buffer
                     (const CoreML__Specification__ActivationThresholdedReLU   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationThresholdedReLU *
       core_ml__specification__activation_thresholded_re_lu__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_thresholded_re_lu__free_unpacked
                     (CoreML__Specification__ActivationThresholdedReLU *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationSoftsign methods */
void   core_ml__specification__activation_softsign__init
                     (CoreML__Specification__ActivationSoftsign         *message);
size_t core_ml__specification__activation_softsign__get_packed_size
                     (const CoreML__Specification__ActivationSoftsign   *message);
size_t core_ml__specification__activation_softsign__pack
                     (const CoreML__Specification__ActivationSoftsign   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_softsign__pack_to_buffer
                     (const CoreML__Specification__ActivationSoftsign   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationSoftsign *
       core_ml__specification__activation_softsign__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_softsign__free_unpacked
                     (CoreML__Specification__ActivationSoftsign *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationSoftplus methods */
void   core_ml__specification__activation_softplus__init
                     (CoreML__Specification__ActivationSoftplus         *message);
size_t core_ml__specification__activation_softplus__get_packed_size
                     (const CoreML__Specification__ActivationSoftplus   *message);
size_t core_ml__specification__activation_softplus__pack
                     (const CoreML__Specification__ActivationSoftplus   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_softplus__pack_to_buffer
                     (const CoreML__Specification__ActivationSoftplus   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationSoftplus *
       core_ml__specification__activation_softplus__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_softplus__free_unpacked
                     (CoreML__Specification__ActivationSoftplus *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationParametricSoftplus methods */
void   core_ml__specification__activation_parametric_softplus__init
                     (CoreML__Specification__ActivationParametricSoftplus         *message);
size_t core_ml__specification__activation_parametric_softplus__get_packed_size
                     (const CoreML__Specification__ActivationParametricSoftplus   *message);
size_t core_ml__specification__activation_parametric_softplus__pack
                     (const CoreML__Specification__ActivationParametricSoftplus   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_parametric_softplus__pack_to_buffer
                     (const CoreML__Specification__ActivationParametricSoftplus   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationParametricSoftplus *
       core_ml__specification__activation_parametric_softplus__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_parametric_softplus__free_unpacked
                     (CoreML__Specification__ActivationParametricSoftplus *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ActivationParams methods */
void   core_ml__specification__activation_params__init
                     (CoreML__Specification__ActivationParams         *message);
size_t core_ml__specification__activation_params__get_packed_size
                     (const CoreML__Specification__ActivationParams   *message);
size_t core_ml__specification__activation_params__pack
                     (const CoreML__Specification__ActivationParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__activation_params__pack_to_buffer
                     (const CoreML__Specification__ActivationParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ActivationParams *
       core_ml__specification__activation_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__activation_params__free_unpacked
                     (CoreML__Specification__ActivationParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__Tensor methods */
void   core_ml__specification__tensor__init
                     (CoreML__Specification__Tensor         *message);
size_t core_ml__specification__tensor__get_packed_size
                     (const CoreML__Specification__Tensor   *message);
size_t core_ml__specification__tensor__pack
                     (const CoreML__Specification__Tensor   *message,
                      uint8_t             *out);
size_t core_ml__specification__tensor__pack_to_buffer
                     (const CoreML__Specification__Tensor   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__Tensor *
       core_ml__specification__tensor__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__tensor__free_unpacked
                     (CoreML__Specification__Tensor *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkLayer methods */
void   core_ml__specification__neural_network_layer__init
                     (CoreML__Specification__NeuralNetworkLayer         *message);
size_t core_ml__specification__neural_network_layer__get_packed_size
                     (const CoreML__Specification__NeuralNetworkLayer   *message);
size_t core_ml__specification__neural_network_layer__pack
                     (const CoreML__Specification__NeuralNetworkLayer   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_layer__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkLayer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkLayer *
       core_ml__specification__neural_network_layer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_layer__free_unpacked
                     (CoreML__Specification__NeuralNetworkLayer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BranchLayerParams methods */
void   core_ml__specification__branch_layer_params__init
                     (CoreML__Specification__BranchLayerParams         *message);
size_t core_ml__specification__branch_layer_params__get_packed_size
                     (const CoreML__Specification__BranchLayerParams   *message);
size_t core_ml__specification__branch_layer_params__pack
                     (const CoreML__Specification__BranchLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__branch_layer_params__pack_to_buffer
                     (const CoreML__Specification__BranchLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BranchLayerParams *
       core_ml__specification__branch_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__branch_layer_params__free_unpacked
                     (CoreML__Specification__BranchLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LoopLayerParams methods */
void   core_ml__specification__loop_layer_params__init
                     (CoreML__Specification__LoopLayerParams         *message);
size_t core_ml__specification__loop_layer_params__get_packed_size
                     (const CoreML__Specification__LoopLayerParams   *message);
size_t core_ml__specification__loop_layer_params__pack
                     (const CoreML__Specification__LoopLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__loop_layer_params__pack_to_buffer
                     (const CoreML__Specification__LoopLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LoopLayerParams *
       core_ml__specification__loop_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__loop_layer_params__free_unpacked
                     (CoreML__Specification__LoopLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LoopBreakLayerParams methods */
void   core_ml__specification__loop_break_layer_params__init
                     (CoreML__Specification__LoopBreakLayerParams         *message);
size_t core_ml__specification__loop_break_layer_params__get_packed_size
                     (const CoreML__Specification__LoopBreakLayerParams   *message);
size_t core_ml__specification__loop_break_layer_params__pack
                     (const CoreML__Specification__LoopBreakLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__loop_break_layer_params__pack_to_buffer
                     (const CoreML__Specification__LoopBreakLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LoopBreakLayerParams *
       core_ml__specification__loop_break_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__loop_break_layer_params__free_unpacked
                     (CoreML__Specification__LoopBreakLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LoopContinueLayerParams methods */
void   core_ml__specification__loop_continue_layer_params__init
                     (CoreML__Specification__LoopContinueLayerParams         *message);
size_t core_ml__specification__loop_continue_layer_params__get_packed_size
                     (const CoreML__Specification__LoopContinueLayerParams   *message);
size_t core_ml__specification__loop_continue_layer_params__pack
                     (const CoreML__Specification__LoopContinueLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__loop_continue_layer_params__pack_to_buffer
                     (const CoreML__Specification__LoopContinueLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LoopContinueLayerParams *
       core_ml__specification__loop_continue_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__loop_continue_layer_params__free_unpacked
                     (CoreML__Specification__LoopContinueLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CopyLayerParams methods */
void   core_ml__specification__copy_layer_params__init
                     (CoreML__Specification__CopyLayerParams         *message);
size_t core_ml__specification__copy_layer_params__get_packed_size
                     (const CoreML__Specification__CopyLayerParams   *message);
size_t core_ml__specification__copy_layer_params__pack
                     (const CoreML__Specification__CopyLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__copy_layer_params__pack_to_buffer
                     (const CoreML__Specification__CopyLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CopyLayerParams *
       core_ml__specification__copy_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__copy_layer_params__free_unpacked
                     (CoreML__Specification__CopyLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GreaterThanLayerParams methods */
void   core_ml__specification__greater_than_layer_params__init
                     (CoreML__Specification__GreaterThanLayerParams         *message);
size_t core_ml__specification__greater_than_layer_params__get_packed_size
                     (const CoreML__Specification__GreaterThanLayerParams   *message);
size_t core_ml__specification__greater_than_layer_params__pack
                     (const CoreML__Specification__GreaterThanLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__greater_than_layer_params__pack_to_buffer
                     (const CoreML__Specification__GreaterThanLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GreaterThanLayerParams *
       core_ml__specification__greater_than_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__greater_than_layer_params__free_unpacked
                     (CoreML__Specification__GreaterThanLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GreaterEqualLayerParams methods */
void   core_ml__specification__greater_equal_layer_params__init
                     (CoreML__Specification__GreaterEqualLayerParams         *message);
size_t core_ml__specification__greater_equal_layer_params__get_packed_size
                     (const CoreML__Specification__GreaterEqualLayerParams   *message);
size_t core_ml__specification__greater_equal_layer_params__pack
                     (const CoreML__Specification__GreaterEqualLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__greater_equal_layer_params__pack_to_buffer
                     (const CoreML__Specification__GreaterEqualLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GreaterEqualLayerParams *
       core_ml__specification__greater_equal_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__greater_equal_layer_params__free_unpacked
                     (CoreML__Specification__GreaterEqualLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LessThanLayerParams methods */
void   core_ml__specification__less_than_layer_params__init
                     (CoreML__Specification__LessThanLayerParams         *message);
size_t core_ml__specification__less_than_layer_params__get_packed_size
                     (const CoreML__Specification__LessThanLayerParams   *message);
size_t core_ml__specification__less_than_layer_params__pack
                     (const CoreML__Specification__LessThanLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__less_than_layer_params__pack_to_buffer
                     (const CoreML__Specification__LessThanLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LessThanLayerParams *
       core_ml__specification__less_than_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__less_than_layer_params__free_unpacked
                     (CoreML__Specification__LessThanLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LessEqualLayerParams methods */
void   core_ml__specification__less_equal_layer_params__init
                     (CoreML__Specification__LessEqualLayerParams         *message);
size_t core_ml__specification__less_equal_layer_params__get_packed_size
                     (const CoreML__Specification__LessEqualLayerParams   *message);
size_t core_ml__specification__less_equal_layer_params__pack
                     (const CoreML__Specification__LessEqualLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__less_equal_layer_params__pack_to_buffer
                     (const CoreML__Specification__LessEqualLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LessEqualLayerParams *
       core_ml__specification__less_equal_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__less_equal_layer_params__free_unpacked
                     (CoreML__Specification__LessEqualLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__EqualLayerParams methods */
void   core_ml__specification__equal_layer_params__init
                     (CoreML__Specification__EqualLayerParams         *message);
size_t core_ml__specification__equal_layer_params__get_packed_size
                     (const CoreML__Specification__EqualLayerParams   *message);
size_t core_ml__specification__equal_layer_params__pack
                     (const CoreML__Specification__EqualLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__equal_layer_params__pack_to_buffer
                     (const CoreML__Specification__EqualLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__EqualLayerParams *
       core_ml__specification__equal_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__equal_layer_params__free_unpacked
                     (CoreML__Specification__EqualLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NotEqualLayerParams methods */
void   core_ml__specification__not_equal_layer_params__init
                     (CoreML__Specification__NotEqualLayerParams         *message);
size_t core_ml__specification__not_equal_layer_params__get_packed_size
                     (const CoreML__Specification__NotEqualLayerParams   *message);
size_t core_ml__specification__not_equal_layer_params__pack
                     (const CoreML__Specification__NotEqualLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__not_equal_layer_params__pack_to_buffer
                     (const CoreML__Specification__NotEqualLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NotEqualLayerParams *
       core_ml__specification__not_equal_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__not_equal_layer_params__free_unpacked
                     (CoreML__Specification__NotEqualLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LogicalAndLayerParams methods */
void   core_ml__specification__logical_and_layer_params__init
                     (CoreML__Specification__LogicalAndLayerParams         *message);
size_t core_ml__specification__logical_and_layer_params__get_packed_size
                     (const CoreML__Specification__LogicalAndLayerParams   *message);
size_t core_ml__specification__logical_and_layer_params__pack
                     (const CoreML__Specification__LogicalAndLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__logical_and_layer_params__pack_to_buffer
                     (const CoreML__Specification__LogicalAndLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LogicalAndLayerParams *
       core_ml__specification__logical_and_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__logical_and_layer_params__free_unpacked
                     (CoreML__Specification__LogicalAndLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LogicalOrLayerParams methods */
void   core_ml__specification__logical_or_layer_params__init
                     (CoreML__Specification__LogicalOrLayerParams         *message);
size_t core_ml__specification__logical_or_layer_params__get_packed_size
                     (const CoreML__Specification__LogicalOrLayerParams   *message);
size_t core_ml__specification__logical_or_layer_params__pack
                     (const CoreML__Specification__LogicalOrLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__logical_or_layer_params__pack_to_buffer
                     (const CoreML__Specification__LogicalOrLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LogicalOrLayerParams *
       core_ml__specification__logical_or_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__logical_or_layer_params__free_unpacked
                     (CoreML__Specification__LogicalOrLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LogicalXorLayerParams methods */
void   core_ml__specification__logical_xor_layer_params__init
                     (CoreML__Specification__LogicalXorLayerParams         *message);
size_t core_ml__specification__logical_xor_layer_params__get_packed_size
                     (const CoreML__Specification__LogicalXorLayerParams   *message);
size_t core_ml__specification__logical_xor_layer_params__pack
                     (const CoreML__Specification__LogicalXorLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__logical_xor_layer_params__pack_to_buffer
                     (const CoreML__Specification__LogicalXorLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LogicalXorLayerParams *
       core_ml__specification__logical_xor_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__logical_xor_layer_params__free_unpacked
                     (CoreML__Specification__LogicalXorLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LogicalNotLayerParams methods */
void   core_ml__specification__logical_not_layer_params__init
                     (CoreML__Specification__LogicalNotLayerParams         *message);
size_t core_ml__specification__logical_not_layer_params__get_packed_size
                     (const CoreML__Specification__LogicalNotLayerParams   *message);
size_t core_ml__specification__logical_not_layer_params__pack
                     (const CoreML__Specification__LogicalNotLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__logical_not_layer_params__pack_to_buffer
                     (const CoreML__Specification__LogicalNotLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LogicalNotLayerParams *
       core_ml__specification__logical_not_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__logical_not_layer_params__free_unpacked
                     (CoreML__Specification__LogicalNotLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BorderAmounts__EdgeSizes methods */
void   core_ml__specification__border_amounts__edge_sizes__init
                     (CoreML__Specification__BorderAmounts__EdgeSizes         *message);
/* CoreML__Specification__BorderAmounts methods */
void   core_ml__specification__border_amounts__init
                     (CoreML__Specification__BorderAmounts         *message);
size_t core_ml__specification__border_amounts__get_packed_size
                     (const CoreML__Specification__BorderAmounts   *message);
size_t core_ml__specification__border_amounts__pack
                     (const CoreML__Specification__BorderAmounts   *message,
                      uint8_t             *out);
size_t core_ml__specification__border_amounts__pack_to_buffer
                     (const CoreML__Specification__BorderAmounts   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BorderAmounts *
       core_ml__specification__border_amounts__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__border_amounts__free_unpacked
                     (CoreML__Specification__BorderAmounts *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ValidPadding methods */
void   core_ml__specification__valid_padding__init
                     (CoreML__Specification__ValidPadding         *message);
size_t core_ml__specification__valid_padding__get_packed_size
                     (const CoreML__Specification__ValidPadding   *message);
size_t core_ml__specification__valid_padding__pack
                     (const CoreML__Specification__ValidPadding   *message,
                      uint8_t             *out);
size_t core_ml__specification__valid_padding__pack_to_buffer
                     (const CoreML__Specification__ValidPadding   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ValidPadding *
       core_ml__specification__valid_padding__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__valid_padding__free_unpacked
                     (CoreML__Specification__ValidPadding *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SamePadding methods */
void   core_ml__specification__same_padding__init
                     (CoreML__Specification__SamePadding         *message);
size_t core_ml__specification__same_padding__get_packed_size
                     (const CoreML__Specification__SamePadding   *message);
size_t core_ml__specification__same_padding__pack
                     (const CoreML__Specification__SamePadding   *message,
                      uint8_t             *out);
size_t core_ml__specification__same_padding__pack_to_buffer
                     (const CoreML__Specification__SamePadding   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SamePadding *
       core_ml__specification__same_padding__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__same_padding__free_unpacked
                     (CoreML__Specification__SamePadding *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SamplingMode methods */
void   core_ml__specification__sampling_mode__init
                     (CoreML__Specification__SamplingMode         *message);
size_t core_ml__specification__sampling_mode__get_packed_size
                     (const CoreML__Specification__SamplingMode   *message);
size_t core_ml__specification__sampling_mode__pack
                     (const CoreML__Specification__SamplingMode   *message,
                      uint8_t             *out);
size_t core_ml__specification__sampling_mode__pack_to_buffer
                     (const CoreML__Specification__SamplingMode   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SamplingMode *
       core_ml__specification__sampling_mode__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sampling_mode__free_unpacked
                     (CoreML__Specification__SamplingMode *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BoxCoordinatesMode methods */
void   core_ml__specification__box_coordinates_mode__init
                     (CoreML__Specification__BoxCoordinatesMode         *message);
size_t core_ml__specification__box_coordinates_mode__get_packed_size
                     (const CoreML__Specification__BoxCoordinatesMode   *message);
size_t core_ml__specification__box_coordinates_mode__pack
                     (const CoreML__Specification__BoxCoordinatesMode   *message,
                      uint8_t             *out);
size_t core_ml__specification__box_coordinates_mode__pack_to_buffer
                     (const CoreML__Specification__BoxCoordinatesMode   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BoxCoordinatesMode *
       core_ml__specification__box_coordinates_mode__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__box_coordinates_mode__free_unpacked
                     (CoreML__Specification__BoxCoordinatesMode *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__WeightParams methods */
void   core_ml__specification__weight_params__init
                     (CoreML__Specification__WeightParams         *message);
size_t core_ml__specification__weight_params__get_packed_size
                     (const CoreML__Specification__WeightParams   *message);
size_t core_ml__specification__weight_params__pack
                     (const CoreML__Specification__WeightParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__weight_params__pack_to_buffer
                     (const CoreML__Specification__WeightParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__WeightParams *
       core_ml__specification__weight_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__weight_params__free_unpacked
                     (CoreML__Specification__WeightParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__QuantizationParams methods */
void   core_ml__specification__quantization_params__init
                     (CoreML__Specification__QuantizationParams         *message);
size_t core_ml__specification__quantization_params__get_packed_size
                     (const CoreML__Specification__QuantizationParams   *message);
size_t core_ml__specification__quantization_params__pack
                     (const CoreML__Specification__QuantizationParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__quantization_params__pack_to_buffer
                     (const CoreML__Specification__QuantizationParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__QuantizationParams *
       core_ml__specification__quantization_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__quantization_params__free_unpacked
                     (CoreML__Specification__QuantizationParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LinearQuantizationParams methods */
void   core_ml__specification__linear_quantization_params__init
                     (CoreML__Specification__LinearQuantizationParams         *message);
size_t core_ml__specification__linear_quantization_params__get_packed_size
                     (const CoreML__Specification__LinearQuantizationParams   *message);
size_t core_ml__specification__linear_quantization_params__pack
                     (const CoreML__Specification__LinearQuantizationParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__linear_quantization_params__pack_to_buffer
                     (const CoreML__Specification__LinearQuantizationParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LinearQuantizationParams *
       core_ml__specification__linear_quantization_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__linear_quantization_params__free_unpacked
                     (CoreML__Specification__LinearQuantizationParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LookUpTableQuantizationParams methods */
void   core_ml__specification__look_up_table_quantization_params__init
                     (CoreML__Specification__LookUpTableQuantizationParams         *message);
size_t core_ml__specification__look_up_table_quantization_params__get_packed_size
                     (const CoreML__Specification__LookUpTableQuantizationParams   *message);
size_t core_ml__specification__look_up_table_quantization_params__pack
                     (const CoreML__Specification__LookUpTableQuantizationParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__look_up_table_quantization_params__pack_to_buffer
                     (const CoreML__Specification__LookUpTableQuantizationParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LookUpTableQuantizationParams *
       core_ml__specification__look_up_table_quantization_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__look_up_table_quantization_params__free_unpacked
                     (CoreML__Specification__LookUpTableQuantizationParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ConvolutionLayerParams methods */
void   core_ml__specification__convolution_layer_params__init
                     (CoreML__Specification__ConvolutionLayerParams         *message);
size_t core_ml__specification__convolution_layer_params__get_packed_size
                     (const CoreML__Specification__ConvolutionLayerParams   *message);
size_t core_ml__specification__convolution_layer_params__pack
                     (const CoreML__Specification__ConvolutionLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__convolution_layer_params__pack_to_buffer
                     (const CoreML__Specification__ConvolutionLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ConvolutionLayerParams *
       core_ml__specification__convolution_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__convolution_layer_params__free_unpacked
                     (CoreML__Specification__ConvolutionLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__Convolution3DLayerParams methods */
void   core_ml__specification__convolution3_dlayer_params__init
                     (CoreML__Specification__Convolution3DLayerParams         *message);
size_t core_ml__specification__convolution3_dlayer_params__get_packed_size
                     (const CoreML__Specification__Convolution3DLayerParams   *message);
size_t core_ml__specification__convolution3_dlayer_params__pack
                     (const CoreML__Specification__Convolution3DLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__convolution3_dlayer_params__pack_to_buffer
                     (const CoreML__Specification__Convolution3DLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__Convolution3DLayerParams *
       core_ml__specification__convolution3_dlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__convolution3_dlayer_params__free_unpacked
                     (CoreML__Specification__Convolution3DLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__InnerProductLayerParams methods */
void   core_ml__specification__inner_product_layer_params__init
                     (CoreML__Specification__InnerProductLayerParams         *message);
size_t core_ml__specification__inner_product_layer_params__get_packed_size
                     (const CoreML__Specification__InnerProductLayerParams   *message);
size_t core_ml__specification__inner_product_layer_params__pack
                     (const CoreML__Specification__InnerProductLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__inner_product_layer_params__pack_to_buffer
                     (const CoreML__Specification__InnerProductLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__InnerProductLayerParams *
       core_ml__specification__inner_product_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__inner_product_layer_params__free_unpacked
                     (CoreML__Specification__InnerProductLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__EmbeddingLayerParams methods */
void   core_ml__specification__embedding_layer_params__init
                     (CoreML__Specification__EmbeddingLayerParams         *message);
size_t core_ml__specification__embedding_layer_params__get_packed_size
                     (const CoreML__Specification__EmbeddingLayerParams   *message);
size_t core_ml__specification__embedding_layer_params__pack
                     (const CoreML__Specification__EmbeddingLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__embedding_layer_params__pack_to_buffer
                     (const CoreML__Specification__EmbeddingLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__EmbeddingLayerParams *
       core_ml__specification__embedding_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__embedding_layer_params__free_unpacked
                     (CoreML__Specification__EmbeddingLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__EmbeddingNDLayerParams methods */
void   core_ml__specification__embedding_ndlayer_params__init
                     (CoreML__Specification__EmbeddingNDLayerParams         *message);
size_t core_ml__specification__embedding_ndlayer_params__get_packed_size
                     (const CoreML__Specification__EmbeddingNDLayerParams   *message);
size_t core_ml__specification__embedding_ndlayer_params__pack
                     (const CoreML__Specification__EmbeddingNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__embedding_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__EmbeddingNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__EmbeddingNDLayerParams *
       core_ml__specification__embedding_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__embedding_ndlayer_params__free_unpacked
                     (CoreML__Specification__EmbeddingNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BatchnormLayerParams methods */
void   core_ml__specification__batchnorm_layer_params__init
                     (CoreML__Specification__BatchnormLayerParams         *message);
size_t core_ml__specification__batchnorm_layer_params__get_packed_size
                     (const CoreML__Specification__BatchnormLayerParams   *message);
size_t core_ml__specification__batchnorm_layer_params__pack
                     (const CoreML__Specification__BatchnormLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__batchnorm_layer_params__pack_to_buffer
                     (const CoreML__Specification__BatchnormLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BatchnormLayerParams *
       core_ml__specification__batchnorm_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__batchnorm_layer_params__free_unpacked
                     (CoreML__Specification__BatchnormLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__PoolingLayerParams__ValidCompletePadding methods */
void   core_ml__specification__pooling_layer_params__valid_complete_padding__init
                     (CoreML__Specification__PoolingLayerParams__ValidCompletePadding         *message);
/* CoreML__Specification__PoolingLayerParams methods */
void   core_ml__specification__pooling_layer_params__init
                     (CoreML__Specification__PoolingLayerParams         *message);
size_t core_ml__specification__pooling_layer_params__get_packed_size
                     (const CoreML__Specification__PoolingLayerParams   *message);
size_t core_ml__specification__pooling_layer_params__pack
                     (const CoreML__Specification__PoolingLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__pooling_layer_params__pack_to_buffer
                     (const CoreML__Specification__PoolingLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__PoolingLayerParams *
       core_ml__specification__pooling_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__pooling_layer_params__free_unpacked
                     (CoreML__Specification__PoolingLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__Pooling3DLayerParams methods */
void   core_ml__specification__pooling3_dlayer_params__init
                     (CoreML__Specification__Pooling3DLayerParams         *message);
size_t core_ml__specification__pooling3_dlayer_params__get_packed_size
                     (const CoreML__Specification__Pooling3DLayerParams   *message);
size_t core_ml__specification__pooling3_dlayer_params__pack
                     (const CoreML__Specification__Pooling3DLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__pooling3_dlayer_params__pack_to_buffer
                     (const CoreML__Specification__Pooling3DLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__Pooling3DLayerParams *
       core_ml__specification__pooling3_dlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__pooling3_dlayer_params__free_unpacked
                     (CoreML__Specification__Pooling3DLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GlobalPooling3DLayerParams methods */
void   core_ml__specification__global_pooling3_dlayer_params__init
                     (CoreML__Specification__GlobalPooling3DLayerParams         *message);
size_t core_ml__specification__global_pooling3_dlayer_params__get_packed_size
                     (const CoreML__Specification__GlobalPooling3DLayerParams   *message);
size_t core_ml__specification__global_pooling3_dlayer_params__pack
                     (const CoreML__Specification__GlobalPooling3DLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__global_pooling3_dlayer_params__pack_to_buffer
                     (const CoreML__Specification__GlobalPooling3DLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GlobalPooling3DLayerParams *
       core_ml__specification__global_pooling3_dlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__global_pooling3_dlayer_params__free_unpacked
                     (CoreML__Specification__GlobalPooling3DLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__PaddingLayerParams__PaddingConstant methods */
void   core_ml__specification__padding_layer_params__padding_constant__init
                     (CoreML__Specification__PaddingLayerParams__PaddingConstant         *message);
/* CoreML__Specification__PaddingLayerParams__PaddingReflection methods */
void   core_ml__specification__padding_layer_params__padding_reflection__init
                     (CoreML__Specification__PaddingLayerParams__PaddingReflection         *message);
/* CoreML__Specification__PaddingLayerParams__PaddingReplication methods */
void   core_ml__specification__padding_layer_params__padding_replication__init
                     (CoreML__Specification__PaddingLayerParams__PaddingReplication         *message);
/* CoreML__Specification__PaddingLayerParams methods */
void   core_ml__specification__padding_layer_params__init
                     (CoreML__Specification__PaddingLayerParams         *message);
size_t core_ml__specification__padding_layer_params__get_packed_size
                     (const CoreML__Specification__PaddingLayerParams   *message);
size_t core_ml__specification__padding_layer_params__pack
                     (const CoreML__Specification__PaddingLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__padding_layer_params__pack_to_buffer
                     (const CoreML__Specification__PaddingLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__PaddingLayerParams *
       core_ml__specification__padding_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__padding_layer_params__free_unpacked
                     (CoreML__Specification__PaddingLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ConcatLayerParams methods */
void   core_ml__specification__concat_layer_params__init
                     (CoreML__Specification__ConcatLayerParams         *message);
size_t core_ml__specification__concat_layer_params__get_packed_size
                     (const CoreML__Specification__ConcatLayerParams   *message);
size_t core_ml__specification__concat_layer_params__pack
                     (const CoreML__Specification__ConcatLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__concat_layer_params__pack_to_buffer
                     (const CoreML__Specification__ConcatLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ConcatLayerParams *
       core_ml__specification__concat_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__concat_layer_params__free_unpacked
                     (CoreML__Specification__ConcatLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LRNLayerParams methods */
void   core_ml__specification__lrnlayer_params__init
                     (CoreML__Specification__LRNLayerParams         *message);
size_t core_ml__specification__lrnlayer_params__get_packed_size
                     (const CoreML__Specification__LRNLayerParams   *message);
size_t core_ml__specification__lrnlayer_params__pack
                     (const CoreML__Specification__LRNLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__lrnlayer_params__pack_to_buffer
                     (const CoreML__Specification__LRNLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LRNLayerParams *
       core_ml__specification__lrnlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__lrnlayer_params__free_unpacked
                     (CoreML__Specification__LRNLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SoftmaxLayerParams methods */
void   core_ml__specification__softmax_layer_params__init
                     (CoreML__Specification__SoftmaxLayerParams         *message);
size_t core_ml__specification__softmax_layer_params__get_packed_size
                     (const CoreML__Specification__SoftmaxLayerParams   *message);
size_t core_ml__specification__softmax_layer_params__pack
                     (const CoreML__Specification__SoftmaxLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__softmax_layer_params__pack_to_buffer
                     (const CoreML__Specification__SoftmaxLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SoftmaxLayerParams *
       core_ml__specification__softmax_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__softmax_layer_params__free_unpacked
                     (CoreML__Specification__SoftmaxLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SplitLayerParams methods */
void   core_ml__specification__split_layer_params__init
                     (CoreML__Specification__SplitLayerParams         *message);
size_t core_ml__specification__split_layer_params__get_packed_size
                     (const CoreML__Specification__SplitLayerParams   *message);
size_t core_ml__specification__split_layer_params__pack
                     (const CoreML__Specification__SplitLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__split_layer_params__pack_to_buffer
                     (const CoreML__Specification__SplitLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SplitLayerParams *
       core_ml__specification__split_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__split_layer_params__free_unpacked
                     (CoreML__Specification__SplitLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AddLayerParams methods */
void   core_ml__specification__add_layer_params__init
                     (CoreML__Specification__AddLayerParams         *message);
size_t core_ml__specification__add_layer_params__get_packed_size
                     (const CoreML__Specification__AddLayerParams   *message);
size_t core_ml__specification__add_layer_params__pack
                     (const CoreML__Specification__AddLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__add_layer_params__pack_to_buffer
                     (const CoreML__Specification__AddLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AddLayerParams *
       core_ml__specification__add_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__add_layer_params__free_unpacked
                     (CoreML__Specification__AddLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MultiplyLayerParams methods */
void   core_ml__specification__multiply_layer_params__init
                     (CoreML__Specification__MultiplyLayerParams         *message);
size_t core_ml__specification__multiply_layer_params__get_packed_size
                     (const CoreML__Specification__MultiplyLayerParams   *message);
size_t core_ml__specification__multiply_layer_params__pack
                     (const CoreML__Specification__MultiplyLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__multiply_layer_params__pack_to_buffer
                     (const CoreML__Specification__MultiplyLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MultiplyLayerParams *
       core_ml__specification__multiply_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__multiply_layer_params__free_unpacked
                     (CoreML__Specification__MultiplyLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__UnaryFunctionLayerParams methods */
void   core_ml__specification__unary_function_layer_params__init
                     (CoreML__Specification__UnaryFunctionLayerParams         *message);
size_t core_ml__specification__unary_function_layer_params__get_packed_size
                     (const CoreML__Specification__UnaryFunctionLayerParams   *message);
size_t core_ml__specification__unary_function_layer_params__pack
                     (const CoreML__Specification__UnaryFunctionLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__unary_function_layer_params__pack_to_buffer
                     (const CoreML__Specification__UnaryFunctionLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__UnaryFunctionLayerParams *
       core_ml__specification__unary_function_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__unary_function_layer_params__free_unpacked
                     (CoreML__Specification__UnaryFunctionLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__UpsampleLayerParams methods */
void   core_ml__specification__upsample_layer_params__init
                     (CoreML__Specification__UpsampleLayerParams         *message);
size_t core_ml__specification__upsample_layer_params__get_packed_size
                     (const CoreML__Specification__UpsampleLayerParams   *message);
size_t core_ml__specification__upsample_layer_params__pack
                     (const CoreML__Specification__UpsampleLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__upsample_layer_params__pack_to_buffer
                     (const CoreML__Specification__UpsampleLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__UpsampleLayerParams *
       core_ml__specification__upsample_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__upsample_layer_params__free_unpacked
                     (CoreML__Specification__UpsampleLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ResizeBilinearLayerParams methods */
void   core_ml__specification__resize_bilinear_layer_params__init
                     (CoreML__Specification__ResizeBilinearLayerParams         *message);
size_t core_ml__specification__resize_bilinear_layer_params__get_packed_size
                     (const CoreML__Specification__ResizeBilinearLayerParams   *message);
size_t core_ml__specification__resize_bilinear_layer_params__pack
                     (const CoreML__Specification__ResizeBilinearLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__resize_bilinear_layer_params__pack_to_buffer
                     (const CoreML__Specification__ResizeBilinearLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ResizeBilinearLayerParams *
       core_ml__specification__resize_bilinear_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__resize_bilinear_layer_params__free_unpacked
                     (CoreML__Specification__ResizeBilinearLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CropResizeLayerParams methods */
void   core_ml__specification__crop_resize_layer_params__init
                     (CoreML__Specification__CropResizeLayerParams         *message);
size_t core_ml__specification__crop_resize_layer_params__get_packed_size
                     (const CoreML__Specification__CropResizeLayerParams   *message);
size_t core_ml__specification__crop_resize_layer_params__pack
                     (const CoreML__Specification__CropResizeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__crop_resize_layer_params__pack_to_buffer
                     (const CoreML__Specification__CropResizeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CropResizeLayerParams *
       core_ml__specification__crop_resize_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__crop_resize_layer_params__free_unpacked
                     (CoreML__Specification__CropResizeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BiasLayerParams methods */
void   core_ml__specification__bias_layer_params__init
                     (CoreML__Specification__BiasLayerParams         *message);
size_t core_ml__specification__bias_layer_params__get_packed_size
                     (const CoreML__Specification__BiasLayerParams   *message);
size_t core_ml__specification__bias_layer_params__pack
                     (const CoreML__Specification__BiasLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__bias_layer_params__pack_to_buffer
                     (const CoreML__Specification__BiasLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BiasLayerParams *
       core_ml__specification__bias_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__bias_layer_params__free_unpacked
                     (CoreML__Specification__BiasLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ScaleLayerParams methods */
void   core_ml__specification__scale_layer_params__init
                     (CoreML__Specification__ScaleLayerParams         *message);
size_t core_ml__specification__scale_layer_params__get_packed_size
                     (const CoreML__Specification__ScaleLayerParams   *message);
size_t core_ml__specification__scale_layer_params__pack
                     (const CoreML__Specification__ScaleLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__scale_layer_params__pack_to_buffer
                     (const CoreML__Specification__ScaleLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ScaleLayerParams *
       core_ml__specification__scale_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__scale_layer_params__free_unpacked
                     (CoreML__Specification__ScaleLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LoadConstantLayerParams methods */
void   core_ml__specification__load_constant_layer_params__init
                     (CoreML__Specification__LoadConstantLayerParams         *message);
size_t core_ml__specification__load_constant_layer_params__get_packed_size
                     (const CoreML__Specification__LoadConstantLayerParams   *message);
size_t core_ml__specification__load_constant_layer_params__pack
                     (const CoreML__Specification__LoadConstantLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__load_constant_layer_params__pack_to_buffer
                     (const CoreML__Specification__LoadConstantLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LoadConstantLayerParams *
       core_ml__specification__load_constant_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__load_constant_layer_params__free_unpacked
                     (CoreML__Specification__LoadConstantLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__L2NormalizeLayerParams methods */
void   core_ml__specification__l2_normalize_layer_params__init
                     (CoreML__Specification__L2NormalizeLayerParams         *message);
size_t core_ml__specification__l2_normalize_layer_params__get_packed_size
                     (const CoreML__Specification__L2NormalizeLayerParams   *message);
size_t core_ml__specification__l2_normalize_layer_params__pack
                     (const CoreML__Specification__L2NormalizeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__l2_normalize_layer_params__pack_to_buffer
                     (const CoreML__Specification__L2NormalizeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__L2NormalizeLayerParams *
       core_ml__specification__l2_normalize_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__l2_normalize_layer_params__free_unpacked
                     (CoreML__Specification__L2NormalizeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FlattenLayerParams methods */
void   core_ml__specification__flatten_layer_params__init
                     (CoreML__Specification__FlattenLayerParams         *message);
size_t core_ml__specification__flatten_layer_params__get_packed_size
                     (const CoreML__Specification__FlattenLayerParams   *message);
size_t core_ml__specification__flatten_layer_params__pack
                     (const CoreML__Specification__FlattenLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__flatten_layer_params__pack_to_buffer
                     (const CoreML__Specification__FlattenLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FlattenLayerParams *
       core_ml__specification__flatten_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__flatten_layer_params__free_unpacked
                     (CoreML__Specification__FlattenLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReshapeLayerParams methods */
void   core_ml__specification__reshape_layer_params__init
                     (CoreML__Specification__ReshapeLayerParams         *message);
size_t core_ml__specification__reshape_layer_params__get_packed_size
                     (const CoreML__Specification__ReshapeLayerParams   *message);
size_t core_ml__specification__reshape_layer_params__pack
                     (const CoreML__Specification__ReshapeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reshape_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReshapeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReshapeLayerParams *
       core_ml__specification__reshape_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reshape_layer_params__free_unpacked
                     (CoreML__Specification__ReshapeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__PermuteLayerParams methods */
void   core_ml__specification__permute_layer_params__init
                     (CoreML__Specification__PermuteLayerParams         *message);
size_t core_ml__specification__permute_layer_params__get_packed_size
                     (const CoreML__Specification__PermuteLayerParams   *message);
size_t core_ml__specification__permute_layer_params__pack
                     (const CoreML__Specification__PermuteLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__permute_layer_params__pack_to_buffer
                     (const CoreML__Specification__PermuteLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__PermuteLayerParams *
       core_ml__specification__permute_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__permute_layer_params__free_unpacked
                     (CoreML__Specification__PermuteLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReorganizeDataLayerParams methods */
void   core_ml__specification__reorganize_data_layer_params__init
                     (CoreML__Specification__ReorganizeDataLayerParams         *message);
size_t core_ml__specification__reorganize_data_layer_params__get_packed_size
                     (const CoreML__Specification__ReorganizeDataLayerParams   *message);
size_t core_ml__specification__reorganize_data_layer_params__pack
                     (const CoreML__Specification__ReorganizeDataLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reorganize_data_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReorganizeDataLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReorganizeDataLayerParams *
       core_ml__specification__reorganize_data_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reorganize_data_layer_params__free_unpacked
                     (CoreML__Specification__ReorganizeDataLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SliceLayerParams methods */
void   core_ml__specification__slice_layer_params__init
                     (CoreML__Specification__SliceLayerParams         *message);
size_t core_ml__specification__slice_layer_params__get_packed_size
                     (const CoreML__Specification__SliceLayerParams   *message);
size_t core_ml__specification__slice_layer_params__pack
                     (const CoreML__Specification__SliceLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__slice_layer_params__pack_to_buffer
                     (const CoreML__Specification__SliceLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SliceLayerParams *
       core_ml__specification__slice_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__slice_layer_params__free_unpacked
                     (CoreML__Specification__SliceLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceLayerParams methods */
void   core_ml__specification__reduce_layer_params__init
                     (CoreML__Specification__ReduceLayerParams         *message);
size_t core_ml__specification__reduce_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceLayerParams   *message);
size_t core_ml__specification__reduce_layer_params__pack
                     (const CoreML__Specification__ReduceLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceLayerParams *
       core_ml__specification__reduce_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_layer_params__free_unpacked
                     (CoreML__Specification__ReduceLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CropLayerParams methods */
void   core_ml__specification__crop_layer_params__init
                     (CoreML__Specification__CropLayerParams         *message);
size_t core_ml__specification__crop_layer_params__get_packed_size
                     (const CoreML__Specification__CropLayerParams   *message);
size_t core_ml__specification__crop_layer_params__pack
                     (const CoreML__Specification__CropLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__crop_layer_params__pack_to_buffer
                     (const CoreML__Specification__CropLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CropLayerParams *
       core_ml__specification__crop_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__crop_layer_params__free_unpacked
                     (CoreML__Specification__CropLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AverageLayerParams methods */
void   core_ml__specification__average_layer_params__init
                     (CoreML__Specification__AverageLayerParams         *message);
size_t core_ml__specification__average_layer_params__get_packed_size
                     (const CoreML__Specification__AverageLayerParams   *message);
size_t core_ml__specification__average_layer_params__pack
                     (const CoreML__Specification__AverageLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__average_layer_params__pack_to_buffer
                     (const CoreML__Specification__AverageLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AverageLayerParams *
       core_ml__specification__average_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__average_layer_params__free_unpacked
                     (CoreML__Specification__AverageLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MaxLayerParams methods */
void   core_ml__specification__max_layer_params__init
                     (CoreML__Specification__MaxLayerParams         *message);
size_t core_ml__specification__max_layer_params__get_packed_size
                     (const CoreML__Specification__MaxLayerParams   *message);
size_t core_ml__specification__max_layer_params__pack
                     (const CoreML__Specification__MaxLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__max_layer_params__pack_to_buffer
                     (const CoreML__Specification__MaxLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MaxLayerParams *
       core_ml__specification__max_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__max_layer_params__free_unpacked
                     (CoreML__Specification__MaxLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MinLayerParams methods */
void   core_ml__specification__min_layer_params__init
                     (CoreML__Specification__MinLayerParams         *message);
size_t core_ml__specification__min_layer_params__get_packed_size
                     (const CoreML__Specification__MinLayerParams   *message);
size_t core_ml__specification__min_layer_params__pack
                     (const CoreML__Specification__MinLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__min_layer_params__pack_to_buffer
                     (const CoreML__Specification__MinLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MinLayerParams *
       core_ml__specification__min_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__min_layer_params__free_unpacked
                     (CoreML__Specification__MinLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__DotProductLayerParams methods */
void   core_ml__specification__dot_product_layer_params__init
                     (CoreML__Specification__DotProductLayerParams         *message);
size_t core_ml__specification__dot_product_layer_params__get_packed_size
                     (const CoreML__Specification__DotProductLayerParams   *message);
size_t core_ml__specification__dot_product_layer_params__pack
                     (const CoreML__Specification__DotProductLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__dot_product_layer_params__pack_to_buffer
                     (const CoreML__Specification__DotProductLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__DotProductLayerParams *
       core_ml__specification__dot_product_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__dot_product_layer_params__free_unpacked
                     (CoreML__Specification__DotProductLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MeanVarianceNormalizeLayerParams methods */
void   core_ml__specification__mean_variance_normalize_layer_params__init
                     (CoreML__Specification__MeanVarianceNormalizeLayerParams         *message);
size_t core_ml__specification__mean_variance_normalize_layer_params__get_packed_size
                     (const CoreML__Specification__MeanVarianceNormalizeLayerParams   *message);
size_t core_ml__specification__mean_variance_normalize_layer_params__pack
                     (const CoreML__Specification__MeanVarianceNormalizeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__mean_variance_normalize_layer_params__pack_to_buffer
                     (const CoreML__Specification__MeanVarianceNormalizeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MeanVarianceNormalizeLayerParams *
       core_ml__specification__mean_variance_normalize_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__mean_variance_normalize_layer_params__free_unpacked
                     (CoreML__Specification__MeanVarianceNormalizeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SequenceRepeatLayerParams methods */
void   core_ml__specification__sequence_repeat_layer_params__init
                     (CoreML__Specification__SequenceRepeatLayerParams         *message);
size_t core_ml__specification__sequence_repeat_layer_params__get_packed_size
                     (const CoreML__Specification__SequenceRepeatLayerParams   *message);
size_t core_ml__specification__sequence_repeat_layer_params__pack
                     (const CoreML__Specification__SequenceRepeatLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__sequence_repeat_layer_params__pack_to_buffer
                     (const CoreML__Specification__SequenceRepeatLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SequenceRepeatLayerParams *
       core_ml__specification__sequence_repeat_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sequence_repeat_layer_params__free_unpacked
                     (CoreML__Specification__SequenceRepeatLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SimpleRecurrentLayerParams methods */
void   core_ml__specification__simple_recurrent_layer_params__init
                     (CoreML__Specification__SimpleRecurrentLayerParams         *message);
size_t core_ml__specification__simple_recurrent_layer_params__get_packed_size
                     (const CoreML__Specification__SimpleRecurrentLayerParams   *message);
size_t core_ml__specification__simple_recurrent_layer_params__pack
                     (const CoreML__Specification__SimpleRecurrentLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__simple_recurrent_layer_params__pack_to_buffer
                     (const CoreML__Specification__SimpleRecurrentLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SimpleRecurrentLayerParams *
       core_ml__specification__simple_recurrent_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__simple_recurrent_layer_params__free_unpacked
                     (CoreML__Specification__SimpleRecurrentLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GRULayerParams methods */
void   core_ml__specification__grulayer_params__init
                     (CoreML__Specification__GRULayerParams         *message);
size_t core_ml__specification__grulayer_params__get_packed_size
                     (const CoreML__Specification__GRULayerParams   *message);
size_t core_ml__specification__grulayer_params__pack
                     (const CoreML__Specification__GRULayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__grulayer_params__pack_to_buffer
                     (const CoreML__Specification__GRULayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GRULayerParams *
       core_ml__specification__grulayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__grulayer_params__free_unpacked
                     (CoreML__Specification__GRULayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LSTMParams methods */
void   core_ml__specification__lstmparams__init
                     (CoreML__Specification__LSTMParams         *message);
size_t core_ml__specification__lstmparams__get_packed_size
                     (const CoreML__Specification__LSTMParams   *message);
size_t core_ml__specification__lstmparams__pack
                     (const CoreML__Specification__LSTMParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__lstmparams__pack_to_buffer
                     (const CoreML__Specification__LSTMParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LSTMParams *
       core_ml__specification__lstmparams__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__lstmparams__free_unpacked
                     (CoreML__Specification__LSTMParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LSTMWeightParams methods */
void   core_ml__specification__lstmweight_params__init
                     (CoreML__Specification__LSTMWeightParams         *message);
size_t core_ml__specification__lstmweight_params__get_packed_size
                     (const CoreML__Specification__LSTMWeightParams   *message);
size_t core_ml__specification__lstmweight_params__pack
                     (const CoreML__Specification__LSTMWeightParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__lstmweight_params__pack_to_buffer
                     (const CoreML__Specification__LSTMWeightParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LSTMWeightParams *
       core_ml__specification__lstmweight_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__lstmweight_params__free_unpacked
                     (CoreML__Specification__LSTMWeightParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__UniDirectionalLSTMLayerParams methods */
void   core_ml__specification__uni_directional_lstmlayer_params__init
                     (CoreML__Specification__UniDirectionalLSTMLayerParams         *message);
size_t core_ml__specification__uni_directional_lstmlayer_params__get_packed_size
                     (const CoreML__Specification__UniDirectionalLSTMLayerParams   *message);
size_t core_ml__specification__uni_directional_lstmlayer_params__pack
                     (const CoreML__Specification__UniDirectionalLSTMLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__uni_directional_lstmlayer_params__pack_to_buffer
                     (const CoreML__Specification__UniDirectionalLSTMLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__UniDirectionalLSTMLayerParams *
       core_ml__specification__uni_directional_lstmlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__uni_directional_lstmlayer_params__free_unpacked
                     (CoreML__Specification__UniDirectionalLSTMLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BiDirectionalLSTMLayerParams methods */
void   core_ml__specification__bi_directional_lstmlayer_params__init
                     (CoreML__Specification__BiDirectionalLSTMLayerParams         *message);
size_t core_ml__specification__bi_directional_lstmlayer_params__get_packed_size
                     (const CoreML__Specification__BiDirectionalLSTMLayerParams   *message);
size_t core_ml__specification__bi_directional_lstmlayer_params__pack
                     (const CoreML__Specification__BiDirectionalLSTMLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__bi_directional_lstmlayer_params__pack_to_buffer
                     (const CoreML__Specification__BiDirectionalLSTMLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BiDirectionalLSTMLayerParams *
       core_ml__specification__bi_directional_lstmlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__bi_directional_lstmlayer_params__free_unpacked
                     (CoreML__Specification__BiDirectionalLSTMLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CustomLayerParams__CustomLayerParamValue methods */
void   core_ml__specification__custom_layer_params__custom_layer_param_value__init
                     (CoreML__Specification__CustomLayerParams__CustomLayerParamValue         *message);
/* CoreML__Specification__CustomLayerParams__ParametersEntry methods */
void   core_ml__specification__custom_layer_params__parameters_entry__init
                     (CoreML__Specification__CustomLayerParams__ParametersEntry         *message);
/* CoreML__Specification__CustomLayerParams methods */
void   core_ml__specification__custom_layer_params__init
                     (CoreML__Specification__CustomLayerParams         *message);
size_t core_ml__specification__custom_layer_params__get_packed_size
                     (const CoreML__Specification__CustomLayerParams   *message);
size_t core_ml__specification__custom_layer_params__pack
                     (const CoreML__Specification__CustomLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__custom_layer_params__pack_to_buffer
                     (const CoreML__Specification__CustomLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CustomLayerParams *
       core_ml__specification__custom_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__custom_layer_params__free_unpacked
                     (CoreML__Specification__CustomLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__TransposeLayerParams methods */
void   core_ml__specification__transpose_layer_params__init
                     (CoreML__Specification__TransposeLayerParams         *message);
size_t core_ml__specification__transpose_layer_params__get_packed_size
                     (const CoreML__Specification__TransposeLayerParams   *message);
size_t core_ml__specification__transpose_layer_params__pack
                     (const CoreML__Specification__TransposeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__transpose_layer_params__pack_to_buffer
                     (const CoreML__Specification__TransposeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__TransposeLayerParams *
       core_ml__specification__transpose_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__transpose_layer_params__free_unpacked
                     (CoreML__Specification__TransposeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BatchedMatMulLayerParams methods */
void   core_ml__specification__batched_mat_mul_layer_params__init
                     (CoreML__Specification__BatchedMatMulLayerParams         *message);
size_t core_ml__specification__batched_mat_mul_layer_params__get_packed_size
                     (const CoreML__Specification__BatchedMatMulLayerParams   *message);
size_t core_ml__specification__batched_mat_mul_layer_params__pack
                     (const CoreML__Specification__BatchedMatMulLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__batched_mat_mul_layer_params__pack_to_buffer
                     (const CoreML__Specification__BatchedMatMulLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BatchedMatMulLayerParams *
       core_ml__specification__batched_mat_mul_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__batched_mat_mul_layer_params__free_unpacked
                     (CoreML__Specification__BatchedMatMulLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ConcatNDLayerParams methods */
void   core_ml__specification__concat_ndlayer_params__init
                     (CoreML__Specification__ConcatNDLayerParams         *message);
size_t core_ml__specification__concat_ndlayer_params__get_packed_size
                     (const CoreML__Specification__ConcatNDLayerParams   *message);
size_t core_ml__specification__concat_ndlayer_params__pack
                     (const CoreML__Specification__ConcatNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__concat_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__ConcatNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ConcatNDLayerParams *
       core_ml__specification__concat_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__concat_ndlayer_params__free_unpacked
                     (CoreML__Specification__ConcatNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SoftmaxNDLayerParams methods */
void   core_ml__specification__softmax_ndlayer_params__init
                     (CoreML__Specification__SoftmaxNDLayerParams         *message);
size_t core_ml__specification__softmax_ndlayer_params__get_packed_size
                     (const CoreML__Specification__SoftmaxNDLayerParams   *message);
size_t core_ml__specification__softmax_ndlayer_params__pack
                     (const CoreML__Specification__SoftmaxNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__softmax_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__SoftmaxNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SoftmaxNDLayerParams *
       core_ml__specification__softmax_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__softmax_ndlayer_params__free_unpacked
                     (CoreML__Specification__SoftmaxNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReverseLayerParams methods */
void   core_ml__specification__reverse_layer_params__init
                     (CoreML__Specification__ReverseLayerParams         *message);
size_t core_ml__specification__reverse_layer_params__get_packed_size
                     (const CoreML__Specification__ReverseLayerParams   *message);
size_t core_ml__specification__reverse_layer_params__pack
                     (const CoreML__Specification__ReverseLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reverse_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReverseLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReverseLayerParams *
       core_ml__specification__reverse_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reverse_layer_params__free_unpacked
                     (CoreML__Specification__ReverseLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReverseSeqLayerParams methods */
void   core_ml__specification__reverse_seq_layer_params__init
                     (CoreML__Specification__ReverseSeqLayerParams         *message);
size_t core_ml__specification__reverse_seq_layer_params__get_packed_size
                     (const CoreML__Specification__ReverseSeqLayerParams   *message);
size_t core_ml__specification__reverse_seq_layer_params__pack
                     (const CoreML__Specification__ReverseSeqLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reverse_seq_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReverseSeqLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReverseSeqLayerParams *
       core_ml__specification__reverse_seq_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reverse_seq_layer_params__free_unpacked
                     (CoreML__Specification__ReverseSeqLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LoadConstantNDLayerParams methods */
void   core_ml__specification__load_constant_ndlayer_params__init
                     (CoreML__Specification__LoadConstantNDLayerParams         *message);
size_t core_ml__specification__load_constant_ndlayer_params__get_packed_size
                     (const CoreML__Specification__LoadConstantNDLayerParams   *message);
size_t core_ml__specification__load_constant_ndlayer_params__pack
                     (const CoreML__Specification__LoadConstantNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__load_constant_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__LoadConstantNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LoadConstantNDLayerParams *
       core_ml__specification__load_constant_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__load_constant_ndlayer_params__free_unpacked
                     (CoreML__Specification__LoadConstantNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FillLikeLayerParams methods */
void   core_ml__specification__fill_like_layer_params__init
                     (CoreML__Specification__FillLikeLayerParams         *message);
size_t core_ml__specification__fill_like_layer_params__get_packed_size
                     (const CoreML__Specification__FillLikeLayerParams   *message);
size_t core_ml__specification__fill_like_layer_params__pack
                     (const CoreML__Specification__FillLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__fill_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__FillLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FillLikeLayerParams *
       core_ml__specification__fill_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__fill_like_layer_params__free_unpacked
                     (CoreML__Specification__FillLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FillStaticLayerParams methods */
void   core_ml__specification__fill_static_layer_params__init
                     (CoreML__Specification__FillStaticLayerParams         *message);
size_t core_ml__specification__fill_static_layer_params__get_packed_size
                     (const CoreML__Specification__FillStaticLayerParams   *message);
size_t core_ml__specification__fill_static_layer_params__pack
                     (const CoreML__Specification__FillStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__fill_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__FillStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FillStaticLayerParams *
       core_ml__specification__fill_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__fill_static_layer_params__free_unpacked
                     (CoreML__Specification__FillStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FillDynamicLayerParams methods */
void   core_ml__specification__fill_dynamic_layer_params__init
                     (CoreML__Specification__FillDynamicLayerParams         *message);
size_t core_ml__specification__fill_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__FillDynamicLayerParams   *message);
size_t core_ml__specification__fill_dynamic_layer_params__pack
                     (const CoreML__Specification__FillDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__fill_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__FillDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FillDynamicLayerParams *
       core_ml__specification__fill_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__fill_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__FillDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__WhereBroadcastableLayerParams methods */
void   core_ml__specification__where_broadcastable_layer_params__init
                     (CoreML__Specification__WhereBroadcastableLayerParams         *message);
size_t core_ml__specification__where_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__WhereBroadcastableLayerParams   *message);
size_t core_ml__specification__where_broadcastable_layer_params__pack
                     (const CoreML__Specification__WhereBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__where_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__WhereBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__WhereBroadcastableLayerParams *
       core_ml__specification__where_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__where_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__WhereBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SinLayerParams methods */
void   core_ml__specification__sin_layer_params__init
                     (CoreML__Specification__SinLayerParams         *message);
size_t core_ml__specification__sin_layer_params__get_packed_size
                     (const CoreML__Specification__SinLayerParams   *message);
size_t core_ml__specification__sin_layer_params__pack
                     (const CoreML__Specification__SinLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__sin_layer_params__pack_to_buffer
                     (const CoreML__Specification__SinLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SinLayerParams *
       core_ml__specification__sin_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sin_layer_params__free_unpacked
                     (CoreML__Specification__SinLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CosLayerParams methods */
void   core_ml__specification__cos_layer_params__init
                     (CoreML__Specification__CosLayerParams         *message);
size_t core_ml__specification__cos_layer_params__get_packed_size
                     (const CoreML__Specification__CosLayerParams   *message);
size_t core_ml__specification__cos_layer_params__pack
                     (const CoreML__Specification__CosLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__cos_layer_params__pack_to_buffer
                     (const CoreML__Specification__CosLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CosLayerParams *
       core_ml__specification__cos_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__cos_layer_params__free_unpacked
                     (CoreML__Specification__CosLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__TanLayerParams methods */
void   core_ml__specification__tan_layer_params__init
                     (CoreML__Specification__TanLayerParams         *message);
size_t core_ml__specification__tan_layer_params__get_packed_size
                     (const CoreML__Specification__TanLayerParams   *message);
size_t core_ml__specification__tan_layer_params__pack
                     (const CoreML__Specification__TanLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__tan_layer_params__pack_to_buffer
                     (const CoreML__Specification__TanLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__TanLayerParams *
       core_ml__specification__tan_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__tan_layer_params__free_unpacked
                     (CoreML__Specification__TanLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AsinLayerParams methods */
void   core_ml__specification__asin_layer_params__init
                     (CoreML__Specification__AsinLayerParams         *message);
size_t core_ml__specification__asin_layer_params__get_packed_size
                     (const CoreML__Specification__AsinLayerParams   *message);
size_t core_ml__specification__asin_layer_params__pack
                     (const CoreML__Specification__AsinLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__asin_layer_params__pack_to_buffer
                     (const CoreML__Specification__AsinLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AsinLayerParams *
       core_ml__specification__asin_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__asin_layer_params__free_unpacked
                     (CoreML__Specification__AsinLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AcosLayerParams methods */
void   core_ml__specification__acos_layer_params__init
                     (CoreML__Specification__AcosLayerParams         *message);
size_t core_ml__specification__acos_layer_params__get_packed_size
                     (const CoreML__Specification__AcosLayerParams   *message);
size_t core_ml__specification__acos_layer_params__pack
                     (const CoreML__Specification__AcosLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__acos_layer_params__pack_to_buffer
                     (const CoreML__Specification__AcosLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AcosLayerParams *
       core_ml__specification__acos_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__acos_layer_params__free_unpacked
                     (CoreML__Specification__AcosLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AtanLayerParams methods */
void   core_ml__specification__atan_layer_params__init
                     (CoreML__Specification__AtanLayerParams         *message);
size_t core_ml__specification__atan_layer_params__get_packed_size
                     (const CoreML__Specification__AtanLayerParams   *message);
size_t core_ml__specification__atan_layer_params__pack
                     (const CoreML__Specification__AtanLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__atan_layer_params__pack_to_buffer
                     (const CoreML__Specification__AtanLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AtanLayerParams *
       core_ml__specification__atan_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__atan_layer_params__free_unpacked
                     (CoreML__Specification__AtanLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SinhLayerParams methods */
void   core_ml__specification__sinh_layer_params__init
                     (CoreML__Specification__SinhLayerParams         *message);
size_t core_ml__specification__sinh_layer_params__get_packed_size
                     (const CoreML__Specification__SinhLayerParams   *message);
size_t core_ml__specification__sinh_layer_params__pack
                     (const CoreML__Specification__SinhLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__sinh_layer_params__pack_to_buffer
                     (const CoreML__Specification__SinhLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SinhLayerParams *
       core_ml__specification__sinh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sinh_layer_params__free_unpacked
                     (CoreML__Specification__SinhLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CoshLayerParams methods */
void   core_ml__specification__cosh_layer_params__init
                     (CoreML__Specification__CoshLayerParams         *message);
size_t core_ml__specification__cosh_layer_params__get_packed_size
                     (const CoreML__Specification__CoshLayerParams   *message);
size_t core_ml__specification__cosh_layer_params__pack
                     (const CoreML__Specification__CoshLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__cosh_layer_params__pack_to_buffer
                     (const CoreML__Specification__CoshLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CoshLayerParams *
       core_ml__specification__cosh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__cosh_layer_params__free_unpacked
                     (CoreML__Specification__CoshLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__TanhLayerParams methods */
void   core_ml__specification__tanh_layer_params__init
                     (CoreML__Specification__TanhLayerParams         *message);
size_t core_ml__specification__tanh_layer_params__get_packed_size
                     (const CoreML__Specification__TanhLayerParams   *message);
size_t core_ml__specification__tanh_layer_params__pack
                     (const CoreML__Specification__TanhLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__tanh_layer_params__pack_to_buffer
                     (const CoreML__Specification__TanhLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__TanhLayerParams *
       core_ml__specification__tanh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__tanh_layer_params__free_unpacked
                     (CoreML__Specification__TanhLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AsinhLayerParams methods */
void   core_ml__specification__asinh_layer_params__init
                     (CoreML__Specification__AsinhLayerParams         *message);
size_t core_ml__specification__asinh_layer_params__get_packed_size
                     (const CoreML__Specification__AsinhLayerParams   *message);
size_t core_ml__specification__asinh_layer_params__pack
                     (const CoreML__Specification__AsinhLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__asinh_layer_params__pack_to_buffer
                     (const CoreML__Specification__AsinhLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AsinhLayerParams *
       core_ml__specification__asinh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__asinh_layer_params__free_unpacked
                     (CoreML__Specification__AsinhLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AcoshLayerParams methods */
void   core_ml__specification__acosh_layer_params__init
                     (CoreML__Specification__AcoshLayerParams         *message);
size_t core_ml__specification__acosh_layer_params__get_packed_size
                     (const CoreML__Specification__AcoshLayerParams   *message);
size_t core_ml__specification__acosh_layer_params__pack
                     (const CoreML__Specification__AcoshLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__acosh_layer_params__pack_to_buffer
                     (const CoreML__Specification__AcoshLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AcoshLayerParams *
       core_ml__specification__acosh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__acosh_layer_params__free_unpacked
                     (CoreML__Specification__AcoshLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AtanhLayerParams methods */
void   core_ml__specification__atanh_layer_params__init
                     (CoreML__Specification__AtanhLayerParams         *message);
size_t core_ml__specification__atanh_layer_params__get_packed_size
                     (const CoreML__Specification__AtanhLayerParams   *message);
size_t core_ml__specification__atanh_layer_params__pack
                     (const CoreML__Specification__AtanhLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__atanh_layer_params__pack_to_buffer
                     (const CoreML__Specification__AtanhLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AtanhLayerParams *
       core_ml__specification__atanh_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__atanh_layer_params__free_unpacked
                     (CoreML__Specification__AtanhLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__PowBroadcastableLayerParams methods */
void   core_ml__specification__pow_broadcastable_layer_params__init
                     (CoreML__Specification__PowBroadcastableLayerParams         *message);
size_t core_ml__specification__pow_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__PowBroadcastableLayerParams   *message);
size_t core_ml__specification__pow_broadcastable_layer_params__pack
                     (const CoreML__Specification__PowBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__pow_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__PowBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__PowBroadcastableLayerParams *
       core_ml__specification__pow_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__pow_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__PowBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__Exp2LayerParams methods */
void   core_ml__specification__exp2_layer_params__init
                     (CoreML__Specification__Exp2LayerParams         *message);
size_t core_ml__specification__exp2_layer_params__get_packed_size
                     (const CoreML__Specification__Exp2LayerParams   *message);
size_t core_ml__specification__exp2_layer_params__pack
                     (const CoreML__Specification__Exp2LayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__exp2_layer_params__pack_to_buffer
                     (const CoreML__Specification__Exp2LayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__Exp2LayerParams *
       core_ml__specification__exp2_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__exp2_layer_params__free_unpacked
                     (CoreML__Specification__Exp2LayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__WhereNonZeroLayerParams methods */
void   core_ml__specification__where_non_zero_layer_params__init
                     (CoreML__Specification__WhereNonZeroLayerParams         *message);
size_t core_ml__specification__where_non_zero_layer_params__get_packed_size
                     (const CoreML__Specification__WhereNonZeroLayerParams   *message);
size_t core_ml__specification__where_non_zero_layer_params__pack
                     (const CoreML__Specification__WhereNonZeroLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__where_non_zero_layer_params__pack_to_buffer
                     (const CoreML__Specification__WhereNonZeroLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__WhereNonZeroLayerParams *
       core_ml__specification__where_non_zero_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__where_non_zero_layer_params__free_unpacked
                     (CoreML__Specification__WhereNonZeroLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MatrixBandPartLayerParams methods */
void   core_ml__specification__matrix_band_part_layer_params__init
                     (CoreML__Specification__MatrixBandPartLayerParams         *message);
size_t core_ml__specification__matrix_band_part_layer_params__get_packed_size
                     (const CoreML__Specification__MatrixBandPartLayerParams   *message);
size_t core_ml__specification__matrix_band_part_layer_params__pack
                     (const CoreML__Specification__MatrixBandPartLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__matrix_band_part_layer_params__pack_to_buffer
                     (const CoreML__Specification__MatrixBandPartLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MatrixBandPartLayerParams *
       core_ml__specification__matrix_band_part_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__matrix_band_part_layer_params__free_unpacked
                     (CoreML__Specification__MatrixBandPartLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__UpperTriangularLayerParams methods */
void   core_ml__specification__upper_triangular_layer_params__init
                     (CoreML__Specification__UpperTriangularLayerParams         *message);
size_t core_ml__specification__upper_triangular_layer_params__get_packed_size
                     (const CoreML__Specification__UpperTriangularLayerParams   *message);
size_t core_ml__specification__upper_triangular_layer_params__pack
                     (const CoreML__Specification__UpperTriangularLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__upper_triangular_layer_params__pack_to_buffer
                     (const CoreML__Specification__UpperTriangularLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__UpperTriangularLayerParams *
       core_ml__specification__upper_triangular_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__upper_triangular_layer_params__free_unpacked
                     (CoreML__Specification__UpperTriangularLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LowerTriangularLayerParams methods */
void   core_ml__specification__lower_triangular_layer_params__init
                     (CoreML__Specification__LowerTriangularLayerParams         *message);
size_t core_ml__specification__lower_triangular_layer_params__get_packed_size
                     (const CoreML__Specification__LowerTriangularLayerParams   *message);
size_t core_ml__specification__lower_triangular_layer_params__pack
                     (const CoreML__Specification__LowerTriangularLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__lower_triangular_layer_params__pack_to_buffer
                     (const CoreML__Specification__LowerTriangularLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LowerTriangularLayerParams *
       core_ml__specification__lower_triangular_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__lower_triangular_layer_params__free_unpacked
                     (CoreML__Specification__LowerTriangularLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BroadcastToLikeLayerParams methods */
void   core_ml__specification__broadcast_to_like_layer_params__init
                     (CoreML__Specification__BroadcastToLikeLayerParams         *message);
size_t core_ml__specification__broadcast_to_like_layer_params__get_packed_size
                     (const CoreML__Specification__BroadcastToLikeLayerParams   *message);
size_t core_ml__specification__broadcast_to_like_layer_params__pack
                     (const CoreML__Specification__BroadcastToLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__broadcast_to_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__BroadcastToLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BroadcastToLikeLayerParams *
       core_ml__specification__broadcast_to_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__broadcast_to_like_layer_params__free_unpacked
                     (CoreML__Specification__BroadcastToLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BroadcastToStaticLayerParams methods */
void   core_ml__specification__broadcast_to_static_layer_params__init
                     (CoreML__Specification__BroadcastToStaticLayerParams         *message);
size_t core_ml__specification__broadcast_to_static_layer_params__get_packed_size
                     (const CoreML__Specification__BroadcastToStaticLayerParams   *message);
size_t core_ml__specification__broadcast_to_static_layer_params__pack
                     (const CoreML__Specification__BroadcastToStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__broadcast_to_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__BroadcastToStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BroadcastToStaticLayerParams *
       core_ml__specification__broadcast_to_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__broadcast_to_static_layer_params__free_unpacked
                     (CoreML__Specification__BroadcastToStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__BroadcastToDynamicLayerParams methods */
void   core_ml__specification__broadcast_to_dynamic_layer_params__init
                     (CoreML__Specification__BroadcastToDynamicLayerParams         *message);
size_t core_ml__specification__broadcast_to_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__BroadcastToDynamicLayerParams   *message);
size_t core_ml__specification__broadcast_to_dynamic_layer_params__pack
                     (const CoreML__Specification__BroadcastToDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__broadcast_to_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__BroadcastToDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__BroadcastToDynamicLayerParams *
       core_ml__specification__broadcast_to_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__broadcast_to_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__BroadcastToDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AddBroadcastableLayerParams methods */
void   core_ml__specification__add_broadcastable_layer_params__init
                     (CoreML__Specification__AddBroadcastableLayerParams         *message);
size_t core_ml__specification__add_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__AddBroadcastableLayerParams   *message);
size_t core_ml__specification__add_broadcastable_layer_params__pack
                     (const CoreML__Specification__AddBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__add_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__AddBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AddBroadcastableLayerParams *
       core_ml__specification__add_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__add_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__AddBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MaxBroadcastableLayerParams methods */
void   core_ml__specification__max_broadcastable_layer_params__init
                     (CoreML__Specification__MaxBroadcastableLayerParams         *message);
size_t core_ml__specification__max_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__MaxBroadcastableLayerParams   *message);
size_t core_ml__specification__max_broadcastable_layer_params__pack
                     (const CoreML__Specification__MaxBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__max_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__MaxBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MaxBroadcastableLayerParams *
       core_ml__specification__max_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__max_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__MaxBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MinBroadcastableLayerParams methods */
void   core_ml__specification__min_broadcastable_layer_params__init
                     (CoreML__Specification__MinBroadcastableLayerParams         *message);
size_t core_ml__specification__min_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__MinBroadcastableLayerParams   *message);
size_t core_ml__specification__min_broadcastable_layer_params__pack
                     (const CoreML__Specification__MinBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__min_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__MinBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MinBroadcastableLayerParams *
       core_ml__specification__min_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__min_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__MinBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ModBroadcastableLayerParams methods */
void   core_ml__specification__mod_broadcastable_layer_params__init
                     (CoreML__Specification__ModBroadcastableLayerParams         *message);
size_t core_ml__specification__mod_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__ModBroadcastableLayerParams   *message);
size_t core_ml__specification__mod_broadcastable_layer_params__pack
                     (const CoreML__Specification__ModBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__mod_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__ModBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ModBroadcastableLayerParams *
       core_ml__specification__mod_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__mod_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__ModBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FloorDivBroadcastableLayerParams methods */
void   core_ml__specification__floor_div_broadcastable_layer_params__init
                     (CoreML__Specification__FloorDivBroadcastableLayerParams         *message);
size_t core_ml__specification__floor_div_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__FloorDivBroadcastableLayerParams   *message);
size_t core_ml__specification__floor_div_broadcastable_layer_params__pack
                     (const CoreML__Specification__FloorDivBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__floor_div_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__FloorDivBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FloorDivBroadcastableLayerParams *
       core_ml__specification__floor_div_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__floor_div_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__FloorDivBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SubtractBroadcastableLayerParams methods */
void   core_ml__specification__subtract_broadcastable_layer_params__init
                     (CoreML__Specification__SubtractBroadcastableLayerParams         *message);
size_t core_ml__specification__subtract_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__SubtractBroadcastableLayerParams   *message);
size_t core_ml__specification__subtract_broadcastable_layer_params__pack
                     (const CoreML__Specification__SubtractBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__subtract_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__SubtractBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SubtractBroadcastableLayerParams *
       core_ml__specification__subtract_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__subtract_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__SubtractBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MultiplyBroadcastableLayerParams methods */
void   core_ml__specification__multiply_broadcastable_layer_params__init
                     (CoreML__Specification__MultiplyBroadcastableLayerParams         *message);
size_t core_ml__specification__multiply_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__MultiplyBroadcastableLayerParams   *message);
size_t core_ml__specification__multiply_broadcastable_layer_params__pack
                     (const CoreML__Specification__MultiplyBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__multiply_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__MultiplyBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MultiplyBroadcastableLayerParams *
       core_ml__specification__multiply_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__multiply_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__MultiplyBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__DivideBroadcastableLayerParams methods */
void   core_ml__specification__divide_broadcastable_layer_params__init
                     (CoreML__Specification__DivideBroadcastableLayerParams         *message);
size_t core_ml__specification__divide_broadcastable_layer_params__get_packed_size
                     (const CoreML__Specification__DivideBroadcastableLayerParams   *message);
size_t core_ml__specification__divide_broadcastable_layer_params__pack
                     (const CoreML__Specification__DivideBroadcastableLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__divide_broadcastable_layer_params__pack_to_buffer
                     (const CoreML__Specification__DivideBroadcastableLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__DivideBroadcastableLayerParams *
       core_ml__specification__divide_broadcastable_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__divide_broadcastable_layer_params__free_unpacked
                     (CoreML__Specification__DivideBroadcastableLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GatherLayerParams methods */
void   core_ml__specification__gather_layer_params__init
                     (CoreML__Specification__GatherLayerParams         *message);
size_t core_ml__specification__gather_layer_params__get_packed_size
                     (const CoreML__Specification__GatherLayerParams   *message);
size_t core_ml__specification__gather_layer_params__pack
                     (const CoreML__Specification__GatherLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__gather_layer_params__pack_to_buffer
                     (const CoreML__Specification__GatherLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GatherLayerParams *
       core_ml__specification__gather_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__gather_layer_params__free_unpacked
                     (CoreML__Specification__GatherLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ScatterLayerParams methods */
void   core_ml__specification__scatter_layer_params__init
                     (CoreML__Specification__ScatterLayerParams         *message);
size_t core_ml__specification__scatter_layer_params__get_packed_size
                     (const CoreML__Specification__ScatterLayerParams   *message);
size_t core_ml__specification__scatter_layer_params__pack
                     (const CoreML__Specification__ScatterLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__scatter_layer_params__pack_to_buffer
                     (const CoreML__Specification__ScatterLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ScatterLayerParams *
       core_ml__specification__scatter_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__scatter_layer_params__free_unpacked
                     (CoreML__Specification__ScatterLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GatherNDLayerParams methods */
void   core_ml__specification__gather_ndlayer_params__init
                     (CoreML__Specification__GatherNDLayerParams         *message);
size_t core_ml__specification__gather_ndlayer_params__get_packed_size
                     (const CoreML__Specification__GatherNDLayerParams   *message);
size_t core_ml__specification__gather_ndlayer_params__pack
                     (const CoreML__Specification__GatherNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__gather_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__GatherNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GatherNDLayerParams *
       core_ml__specification__gather_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__gather_ndlayer_params__free_unpacked
                     (CoreML__Specification__GatherNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ScatterNDLayerParams methods */
void   core_ml__specification__scatter_ndlayer_params__init
                     (CoreML__Specification__ScatterNDLayerParams         *message);
size_t core_ml__specification__scatter_ndlayer_params__get_packed_size
                     (const CoreML__Specification__ScatterNDLayerParams   *message);
size_t core_ml__specification__scatter_ndlayer_params__pack
                     (const CoreML__Specification__ScatterNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__scatter_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__ScatterNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ScatterNDLayerParams *
       core_ml__specification__scatter_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__scatter_ndlayer_params__free_unpacked
                     (CoreML__Specification__ScatterNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GatherAlongAxisLayerParams methods */
void   core_ml__specification__gather_along_axis_layer_params__init
                     (CoreML__Specification__GatherAlongAxisLayerParams         *message);
size_t core_ml__specification__gather_along_axis_layer_params__get_packed_size
                     (const CoreML__Specification__GatherAlongAxisLayerParams   *message);
size_t core_ml__specification__gather_along_axis_layer_params__pack
                     (const CoreML__Specification__GatherAlongAxisLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__gather_along_axis_layer_params__pack_to_buffer
                     (const CoreML__Specification__GatherAlongAxisLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GatherAlongAxisLayerParams *
       core_ml__specification__gather_along_axis_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__gather_along_axis_layer_params__free_unpacked
                     (CoreML__Specification__GatherAlongAxisLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ScatterAlongAxisLayerParams methods */
void   core_ml__specification__scatter_along_axis_layer_params__init
                     (CoreML__Specification__ScatterAlongAxisLayerParams         *message);
size_t core_ml__specification__scatter_along_axis_layer_params__get_packed_size
                     (const CoreML__Specification__ScatterAlongAxisLayerParams   *message);
size_t core_ml__specification__scatter_along_axis_layer_params__pack
                     (const CoreML__Specification__ScatterAlongAxisLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__scatter_along_axis_layer_params__pack_to_buffer
                     (const CoreML__Specification__ScatterAlongAxisLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ScatterAlongAxisLayerParams *
       core_ml__specification__scatter_along_axis_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__scatter_along_axis_layer_params__free_unpacked
                     (CoreML__Specification__ScatterAlongAxisLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__StackLayerParams methods */
void   core_ml__specification__stack_layer_params__init
                     (CoreML__Specification__StackLayerParams         *message);
size_t core_ml__specification__stack_layer_params__get_packed_size
                     (const CoreML__Specification__StackLayerParams   *message);
size_t core_ml__specification__stack_layer_params__pack
                     (const CoreML__Specification__StackLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__stack_layer_params__pack_to_buffer
                     (const CoreML__Specification__StackLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__StackLayerParams *
       core_ml__specification__stack_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__stack_layer_params__free_unpacked
                     (CoreML__Specification__StackLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RankPreservingReshapeLayerParams methods */
void   core_ml__specification__rank_preserving_reshape_layer_params__init
                     (CoreML__Specification__RankPreservingReshapeLayerParams         *message);
size_t core_ml__specification__rank_preserving_reshape_layer_params__get_packed_size
                     (const CoreML__Specification__RankPreservingReshapeLayerParams   *message);
size_t core_ml__specification__rank_preserving_reshape_layer_params__pack
                     (const CoreML__Specification__RankPreservingReshapeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__rank_preserving_reshape_layer_params__pack_to_buffer
                     (const CoreML__Specification__RankPreservingReshapeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RankPreservingReshapeLayerParams *
       core_ml__specification__rank_preserving_reshape_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__rank_preserving_reshape_layer_params__free_unpacked
                     (CoreML__Specification__RankPreservingReshapeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ConstantPaddingLayerParams methods */
void   core_ml__specification__constant_padding_layer_params__init
                     (CoreML__Specification__ConstantPaddingLayerParams         *message);
size_t core_ml__specification__constant_padding_layer_params__get_packed_size
                     (const CoreML__Specification__ConstantPaddingLayerParams   *message);
size_t core_ml__specification__constant_padding_layer_params__pack
                     (const CoreML__Specification__ConstantPaddingLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__constant_padding_layer_params__pack_to_buffer
                     (const CoreML__Specification__ConstantPaddingLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ConstantPaddingLayerParams *
       core_ml__specification__constant_padding_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__constant_padding_layer_params__free_unpacked
                     (CoreML__Specification__ConstantPaddingLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomNormalLikeLayerParams methods */
void   core_ml__specification__random_normal_like_layer_params__init
                     (CoreML__Specification__RandomNormalLikeLayerParams         *message);
size_t core_ml__specification__random_normal_like_layer_params__get_packed_size
                     (const CoreML__Specification__RandomNormalLikeLayerParams   *message);
size_t core_ml__specification__random_normal_like_layer_params__pack
                     (const CoreML__Specification__RandomNormalLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_normal_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomNormalLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomNormalLikeLayerParams *
       core_ml__specification__random_normal_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_normal_like_layer_params__free_unpacked
                     (CoreML__Specification__RandomNormalLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomNormalStaticLayerParams methods */
void   core_ml__specification__random_normal_static_layer_params__init
                     (CoreML__Specification__RandomNormalStaticLayerParams         *message);
size_t core_ml__specification__random_normal_static_layer_params__get_packed_size
                     (const CoreML__Specification__RandomNormalStaticLayerParams   *message);
size_t core_ml__specification__random_normal_static_layer_params__pack
                     (const CoreML__Specification__RandomNormalStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_normal_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomNormalStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomNormalStaticLayerParams *
       core_ml__specification__random_normal_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_normal_static_layer_params__free_unpacked
                     (CoreML__Specification__RandomNormalStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomNormalDynamicLayerParams methods */
void   core_ml__specification__random_normal_dynamic_layer_params__init
                     (CoreML__Specification__RandomNormalDynamicLayerParams         *message);
size_t core_ml__specification__random_normal_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__RandomNormalDynamicLayerParams   *message);
size_t core_ml__specification__random_normal_dynamic_layer_params__pack
                     (const CoreML__Specification__RandomNormalDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_normal_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomNormalDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomNormalDynamicLayerParams *
       core_ml__specification__random_normal_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_normal_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__RandomNormalDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomUniformLikeLayerParams methods */
void   core_ml__specification__random_uniform_like_layer_params__init
                     (CoreML__Specification__RandomUniformLikeLayerParams         *message);
size_t core_ml__specification__random_uniform_like_layer_params__get_packed_size
                     (const CoreML__Specification__RandomUniformLikeLayerParams   *message);
size_t core_ml__specification__random_uniform_like_layer_params__pack
                     (const CoreML__Specification__RandomUniformLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_uniform_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomUniformLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomUniformLikeLayerParams *
       core_ml__specification__random_uniform_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_uniform_like_layer_params__free_unpacked
                     (CoreML__Specification__RandomUniformLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomUniformStaticLayerParams methods */
void   core_ml__specification__random_uniform_static_layer_params__init
                     (CoreML__Specification__RandomUniformStaticLayerParams         *message);
size_t core_ml__specification__random_uniform_static_layer_params__get_packed_size
                     (const CoreML__Specification__RandomUniformStaticLayerParams   *message);
size_t core_ml__specification__random_uniform_static_layer_params__pack
                     (const CoreML__Specification__RandomUniformStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_uniform_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomUniformStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomUniformStaticLayerParams *
       core_ml__specification__random_uniform_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_uniform_static_layer_params__free_unpacked
                     (CoreML__Specification__RandomUniformStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomUniformDynamicLayerParams methods */
void   core_ml__specification__random_uniform_dynamic_layer_params__init
                     (CoreML__Specification__RandomUniformDynamicLayerParams         *message);
size_t core_ml__specification__random_uniform_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__RandomUniformDynamicLayerParams   *message);
size_t core_ml__specification__random_uniform_dynamic_layer_params__pack
                     (const CoreML__Specification__RandomUniformDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_uniform_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomUniformDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomUniformDynamicLayerParams *
       core_ml__specification__random_uniform_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_uniform_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__RandomUniformDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomBernoulliLikeLayerParams methods */
void   core_ml__specification__random_bernoulli_like_layer_params__init
                     (CoreML__Specification__RandomBernoulliLikeLayerParams         *message);
size_t core_ml__specification__random_bernoulli_like_layer_params__get_packed_size
                     (const CoreML__Specification__RandomBernoulliLikeLayerParams   *message);
size_t core_ml__specification__random_bernoulli_like_layer_params__pack
                     (const CoreML__Specification__RandomBernoulliLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_bernoulli_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomBernoulliLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomBernoulliLikeLayerParams *
       core_ml__specification__random_bernoulli_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_bernoulli_like_layer_params__free_unpacked
                     (CoreML__Specification__RandomBernoulliLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomBernoulliStaticLayerParams methods */
void   core_ml__specification__random_bernoulli_static_layer_params__init
                     (CoreML__Specification__RandomBernoulliStaticLayerParams         *message);
size_t core_ml__specification__random_bernoulli_static_layer_params__get_packed_size
                     (const CoreML__Specification__RandomBernoulliStaticLayerParams   *message);
size_t core_ml__specification__random_bernoulli_static_layer_params__pack
                     (const CoreML__Specification__RandomBernoulliStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_bernoulli_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomBernoulliStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomBernoulliStaticLayerParams *
       core_ml__specification__random_bernoulli_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_bernoulli_static_layer_params__free_unpacked
                     (CoreML__Specification__RandomBernoulliStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RandomBernoulliDynamicLayerParams methods */
void   core_ml__specification__random_bernoulli_dynamic_layer_params__init
                     (CoreML__Specification__RandomBernoulliDynamicLayerParams         *message);
size_t core_ml__specification__random_bernoulli_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__RandomBernoulliDynamicLayerParams   *message);
size_t core_ml__specification__random_bernoulli_dynamic_layer_params__pack
                     (const CoreML__Specification__RandomBernoulliDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__random_bernoulli_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__RandomBernoulliDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RandomBernoulliDynamicLayerParams *
       core_ml__specification__random_bernoulli_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__random_bernoulli_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__RandomBernoulliDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CategoricalDistributionLayerParams methods */
void   core_ml__specification__categorical_distribution_layer_params__init
                     (CoreML__Specification__CategoricalDistributionLayerParams         *message);
size_t core_ml__specification__categorical_distribution_layer_params__get_packed_size
                     (const CoreML__Specification__CategoricalDistributionLayerParams   *message);
size_t core_ml__specification__categorical_distribution_layer_params__pack
                     (const CoreML__Specification__CategoricalDistributionLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__categorical_distribution_layer_params__pack_to_buffer
                     (const CoreML__Specification__CategoricalDistributionLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CategoricalDistributionLayerParams *
       core_ml__specification__categorical_distribution_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__categorical_distribution_layer_params__free_unpacked
                     (CoreML__Specification__CategoricalDistributionLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceL1LayerParams methods */
void   core_ml__specification__reduce_l1_layer_params__init
                     (CoreML__Specification__ReduceL1LayerParams         *message);
size_t core_ml__specification__reduce_l1_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceL1LayerParams   *message);
size_t core_ml__specification__reduce_l1_layer_params__pack
                     (const CoreML__Specification__ReduceL1LayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_l1_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceL1LayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceL1LayerParams *
       core_ml__specification__reduce_l1_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_l1_layer_params__free_unpacked
                     (CoreML__Specification__ReduceL1LayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceL2LayerParams methods */
void   core_ml__specification__reduce_l2_layer_params__init
                     (CoreML__Specification__ReduceL2LayerParams         *message);
size_t core_ml__specification__reduce_l2_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceL2LayerParams   *message);
size_t core_ml__specification__reduce_l2_layer_params__pack
                     (const CoreML__Specification__ReduceL2LayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_l2_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceL2LayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceL2LayerParams *
       core_ml__specification__reduce_l2_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_l2_layer_params__free_unpacked
                     (CoreML__Specification__ReduceL2LayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceMaxLayerParams methods */
void   core_ml__specification__reduce_max_layer_params__init
                     (CoreML__Specification__ReduceMaxLayerParams         *message);
size_t core_ml__specification__reduce_max_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceMaxLayerParams   *message);
size_t core_ml__specification__reduce_max_layer_params__pack
                     (const CoreML__Specification__ReduceMaxLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_max_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceMaxLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceMaxLayerParams *
       core_ml__specification__reduce_max_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_max_layer_params__free_unpacked
                     (CoreML__Specification__ReduceMaxLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceMinLayerParams methods */
void   core_ml__specification__reduce_min_layer_params__init
                     (CoreML__Specification__ReduceMinLayerParams         *message);
size_t core_ml__specification__reduce_min_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceMinLayerParams   *message);
size_t core_ml__specification__reduce_min_layer_params__pack
                     (const CoreML__Specification__ReduceMinLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_min_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceMinLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceMinLayerParams *
       core_ml__specification__reduce_min_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_min_layer_params__free_unpacked
                     (CoreML__Specification__ReduceMinLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceSumLayerParams methods */
void   core_ml__specification__reduce_sum_layer_params__init
                     (CoreML__Specification__ReduceSumLayerParams         *message);
size_t core_ml__specification__reduce_sum_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceSumLayerParams   *message);
size_t core_ml__specification__reduce_sum_layer_params__pack
                     (const CoreML__Specification__ReduceSumLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_sum_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceSumLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceSumLayerParams *
       core_ml__specification__reduce_sum_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_sum_layer_params__free_unpacked
                     (CoreML__Specification__ReduceSumLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceProdLayerParams methods */
void   core_ml__specification__reduce_prod_layer_params__init
                     (CoreML__Specification__ReduceProdLayerParams         *message);
size_t core_ml__specification__reduce_prod_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceProdLayerParams   *message);
size_t core_ml__specification__reduce_prod_layer_params__pack
                     (const CoreML__Specification__ReduceProdLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_prod_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceProdLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceProdLayerParams *
       core_ml__specification__reduce_prod_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_prod_layer_params__free_unpacked
                     (CoreML__Specification__ReduceProdLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceMeanLayerParams methods */
void   core_ml__specification__reduce_mean_layer_params__init
                     (CoreML__Specification__ReduceMeanLayerParams         *message);
size_t core_ml__specification__reduce_mean_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceMeanLayerParams   *message);
size_t core_ml__specification__reduce_mean_layer_params__pack
                     (const CoreML__Specification__ReduceMeanLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_mean_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceMeanLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceMeanLayerParams *
       core_ml__specification__reduce_mean_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_mean_layer_params__free_unpacked
                     (CoreML__Specification__ReduceMeanLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceLogSumLayerParams methods */
void   core_ml__specification__reduce_log_sum_layer_params__init
                     (CoreML__Specification__ReduceLogSumLayerParams         *message);
size_t core_ml__specification__reduce_log_sum_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceLogSumLayerParams   *message);
size_t core_ml__specification__reduce_log_sum_layer_params__pack
                     (const CoreML__Specification__ReduceLogSumLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_log_sum_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceLogSumLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceLogSumLayerParams *
       core_ml__specification__reduce_log_sum_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_log_sum_layer_params__free_unpacked
                     (CoreML__Specification__ReduceLogSumLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceSumSquareLayerParams methods */
void   core_ml__specification__reduce_sum_square_layer_params__init
                     (CoreML__Specification__ReduceSumSquareLayerParams         *message);
size_t core_ml__specification__reduce_sum_square_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceSumSquareLayerParams   *message);
size_t core_ml__specification__reduce_sum_square_layer_params__pack
                     (const CoreML__Specification__ReduceSumSquareLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_sum_square_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceSumSquareLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceSumSquareLayerParams *
       core_ml__specification__reduce_sum_square_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_sum_square_layer_params__free_unpacked
                     (CoreML__Specification__ReduceSumSquareLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReduceLogSumExpLayerParams methods */
void   core_ml__specification__reduce_log_sum_exp_layer_params__init
                     (CoreML__Specification__ReduceLogSumExpLayerParams         *message);
size_t core_ml__specification__reduce_log_sum_exp_layer_params__get_packed_size
                     (const CoreML__Specification__ReduceLogSumExpLayerParams   *message);
size_t core_ml__specification__reduce_log_sum_exp_layer_params__pack
                     (const CoreML__Specification__ReduceLogSumExpLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reduce_log_sum_exp_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReduceLogSumExpLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReduceLogSumExpLayerParams *
       core_ml__specification__reduce_log_sum_exp_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reduce_log_sum_exp_layer_params__free_unpacked
                     (CoreML__Specification__ReduceLogSumExpLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ExpandDimsLayerParams methods */
void   core_ml__specification__expand_dims_layer_params__init
                     (CoreML__Specification__ExpandDimsLayerParams         *message);
size_t core_ml__specification__expand_dims_layer_params__get_packed_size
                     (const CoreML__Specification__ExpandDimsLayerParams   *message);
size_t core_ml__specification__expand_dims_layer_params__pack
                     (const CoreML__Specification__ExpandDimsLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__expand_dims_layer_params__pack_to_buffer
                     (const CoreML__Specification__ExpandDimsLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ExpandDimsLayerParams *
       core_ml__specification__expand_dims_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__expand_dims_layer_params__free_unpacked
                     (CoreML__Specification__ExpandDimsLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FlattenTo2DLayerParams methods */
void   core_ml__specification__flatten_to2_dlayer_params__init
                     (CoreML__Specification__FlattenTo2DLayerParams         *message);
size_t core_ml__specification__flatten_to2_dlayer_params__get_packed_size
                     (const CoreML__Specification__FlattenTo2DLayerParams   *message);
size_t core_ml__specification__flatten_to2_dlayer_params__pack
                     (const CoreML__Specification__FlattenTo2DLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__flatten_to2_dlayer_params__pack_to_buffer
                     (const CoreML__Specification__FlattenTo2DLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FlattenTo2DLayerParams *
       core_ml__specification__flatten_to2_dlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__flatten_to2_dlayer_params__free_unpacked
                     (CoreML__Specification__FlattenTo2DLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReshapeStaticLayerParams methods */
void   core_ml__specification__reshape_static_layer_params__init
                     (CoreML__Specification__ReshapeStaticLayerParams         *message);
size_t core_ml__specification__reshape_static_layer_params__get_packed_size
                     (const CoreML__Specification__ReshapeStaticLayerParams   *message);
size_t core_ml__specification__reshape_static_layer_params__pack
                     (const CoreML__Specification__ReshapeStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reshape_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReshapeStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReshapeStaticLayerParams *
       core_ml__specification__reshape_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reshape_static_layer_params__free_unpacked
                     (CoreML__Specification__ReshapeStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReshapeLikeLayerParams methods */
void   core_ml__specification__reshape_like_layer_params__init
                     (CoreML__Specification__ReshapeLikeLayerParams         *message);
size_t core_ml__specification__reshape_like_layer_params__get_packed_size
                     (const CoreML__Specification__ReshapeLikeLayerParams   *message);
size_t core_ml__specification__reshape_like_layer_params__pack
                     (const CoreML__Specification__ReshapeLikeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reshape_like_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReshapeLikeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReshapeLikeLayerParams *
       core_ml__specification__reshape_like_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reshape_like_layer_params__free_unpacked
                     (CoreML__Specification__ReshapeLikeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ReshapeDynamicLayerParams methods */
void   core_ml__specification__reshape_dynamic_layer_params__init
                     (CoreML__Specification__ReshapeDynamicLayerParams         *message);
size_t core_ml__specification__reshape_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__ReshapeDynamicLayerParams   *message);
size_t core_ml__specification__reshape_dynamic_layer_params__pack
                     (const CoreML__Specification__ReshapeDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__reshape_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__ReshapeDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ReshapeDynamicLayerParams *
       core_ml__specification__reshape_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__reshape_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__ReshapeDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SqueezeLayerParams methods */
void   core_ml__specification__squeeze_layer_params__init
                     (CoreML__Specification__SqueezeLayerParams         *message);
size_t core_ml__specification__squeeze_layer_params__get_packed_size
                     (const CoreML__Specification__SqueezeLayerParams   *message);
size_t core_ml__specification__squeeze_layer_params__pack
                     (const CoreML__Specification__SqueezeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__squeeze_layer_params__pack_to_buffer
                     (const CoreML__Specification__SqueezeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SqueezeLayerParams *
       core_ml__specification__squeeze_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__squeeze_layer_params__free_unpacked
                     (CoreML__Specification__SqueezeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__TopKLayerParams methods */
void   core_ml__specification__top_klayer_params__init
                     (CoreML__Specification__TopKLayerParams         *message);
size_t core_ml__specification__top_klayer_params__get_packed_size
                     (const CoreML__Specification__TopKLayerParams   *message);
size_t core_ml__specification__top_klayer_params__pack
                     (const CoreML__Specification__TopKLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__top_klayer_params__pack_to_buffer
                     (const CoreML__Specification__TopKLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__TopKLayerParams *
       core_ml__specification__top_klayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__top_klayer_params__free_unpacked
                     (CoreML__Specification__TopKLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ArgMaxLayerParams methods */
void   core_ml__specification__arg_max_layer_params__init
                     (CoreML__Specification__ArgMaxLayerParams         *message);
size_t core_ml__specification__arg_max_layer_params__get_packed_size
                     (const CoreML__Specification__ArgMaxLayerParams   *message);
size_t core_ml__specification__arg_max_layer_params__pack
                     (const CoreML__Specification__ArgMaxLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__arg_max_layer_params__pack_to_buffer
                     (const CoreML__Specification__ArgMaxLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ArgMaxLayerParams *
       core_ml__specification__arg_max_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__arg_max_layer_params__free_unpacked
                     (CoreML__Specification__ArgMaxLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ArgMinLayerParams methods */
void   core_ml__specification__arg_min_layer_params__init
                     (CoreML__Specification__ArgMinLayerParams         *message);
size_t core_ml__specification__arg_min_layer_params__get_packed_size
                     (const CoreML__Specification__ArgMinLayerParams   *message);
size_t core_ml__specification__arg_min_layer_params__pack
                     (const CoreML__Specification__ArgMinLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__arg_min_layer_params__pack_to_buffer
                     (const CoreML__Specification__ArgMinLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ArgMinLayerParams *
       core_ml__specification__arg_min_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__arg_min_layer_params__free_unpacked
                     (CoreML__Specification__ArgMinLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SplitNDLayerParams methods */
void   core_ml__specification__split_ndlayer_params__init
                     (CoreML__Specification__SplitNDLayerParams         *message);
size_t core_ml__specification__split_ndlayer_params__get_packed_size
                     (const CoreML__Specification__SplitNDLayerParams   *message);
size_t core_ml__specification__split_ndlayer_params__pack
                     (const CoreML__Specification__SplitNDLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__split_ndlayer_params__pack_to_buffer
                     (const CoreML__Specification__SplitNDLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SplitNDLayerParams *
       core_ml__specification__split_ndlayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__split_ndlayer_params__free_unpacked
                     (CoreML__Specification__SplitNDLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CeilLayerParams methods */
void   core_ml__specification__ceil_layer_params__init
                     (CoreML__Specification__CeilLayerParams         *message);
size_t core_ml__specification__ceil_layer_params__get_packed_size
                     (const CoreML__Specification__CeilLayerParams   *message);
size_t core_ml__specification__ceil_layer_params__pack
                     (const CoreML__Specification__CeilLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__ceil_layer_params__pack_to_buffer
                     (const CoreML__Specification__CeilLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CeilLayerParams *
       core_ml__specification__ceil_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__ceil_layer_params__free_unpacked
                     (CoreML__Specification__CeilLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RoundLayerParams methods */
void   core_ml__specification__round_layer_params__init
                     (CoreML__Specification__RoundLayerParams         *message);
size_t core_ml__specification__round_layer_params__get_packed_size
                     (const CoreML__Specification__RoundLayerParams   *message);
size_t core_ml__specification__round_layer_params__pack
                     (const CoreML__Specification__RoundLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__round_layer_params__pack_to_buffer
                     (const CoreML__Specification__RoundLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RoundLayerParams *
       core_ml__specification__round_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__round_layer_params__free_unpacked
                     (CoreML__Specification__RoundLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__FloorLayerParams methods */
void   core_ml__specification__floor_layer_params__init
                     (CoreML__Specification__FloorLayerParams         *message);
size_t core_ml__specification__floor_layer_params__get_packed_size
                     (const CoreML__Specification__FloorLayerParams   *message);
size_t core_ml__specification__floor_layer_params__pack
                     (const CoreML__Specification__FloorLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__floor_layer_params__pack_to_buffer
                     (const CoreML__Specification__FloorLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__FloorLayerParams *
       core_ml__specification__floor_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__floor_layer_params__free_unpacked
                     (CoreML__Specification__FloorLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SignLayerParams methods */
void   core_ml__specification__sign_layer_params__init
                     (CoreML__Specification__SignLayerParams         *message);
size_t core_ml__specification__sign_layer_params__get_packed_size
                     (const CoreML__Specification__SignLayerParams   *message);
size_t core_ml__specification__sign_layer_params__pack
                     (const CoreML__Specification__SignLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__sign_layer_params__pack_to_buffer
                     (const CoreML__Specification__SignLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SignLayerParams *
       core_ml__specification__sign_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sign_layer_params__free_unpacked
                     (CoreML__Specification__SignLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ClipLayerParams methods */
void   core_ml__specification__clip_layer_params__init
                     (CoreML__Specification__ClipLayerParams         *message);
size_t core_ml__specification__clip_layer_params__get_packed_size
                     (const CoreML__Specification__ClipLayerParams   *message);
size_t core_ml__specification__clip_layer_params__pack
                     (const CoreML__Specification__ClipLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__clip_layer_params__pack_to_buffer
                     (const CoreML__Specification__ClipLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ClipLayerParams *
       core_ml__specification__clip_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__clip_layer_params__free_unpacked
                     (CoreML__Specification__ClipLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SliceStaticLayerParams methods */
void   core_ml__specification__slice_static_layer_params__init
                     (CoreML__Specification__SliceStaticLayerParams         *message);
size_t core_ml__specification__slice_static_layer_params__get_packed_size
                     (const CoreML__Specification__SliceStaticLayerParams   *message);
size_t core_ml__specification__slice_static_layer_params__pack
                     (const CoreML__Specification__SliceStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__slice_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__SliceStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SliceStaticLayerParams *
       core_ml__specification__slice_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__slice_static_layer_params__free_unpacked
                     (CoreML__Specification__SliceStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SliceDynamicLayerParams methods */
void   core_ml__specification__slice_dynamic_layer_params__init
                     (CoreML__Specification__SliceDynamicLayerParams         *message);
size_t core_ml__specification__slice_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__SliceDynamicLayerParams   *message);
size_t core_ml__specification__slice_dynamic_layer_params__pack
                     (const CoreML__Specification__SliceDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__slice_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__SliceDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SliceDynamicLayerParams *
       core_ml__specification__slice_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__slice_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__SliceDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__TileLayerParams methods */
void   core_ml__specification__tile_layer_params__init
                     (CoreML__Specification__TileLayerParams         *message);
size_t core_ml__specification__tile_layer_params__get_packed_size
                     (const CoreML__Specification__TileLayerParams   *message);
size_t core_ml__specification__tile_layer_params__pack
                     (const CoreML__Specification__TileLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__tile_layer_params__pack_to_buffer
                     (const CoreML__Specification__TileLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__TileLayerParams *
       core_ml__specification__tile_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__tile_layer_params__free_unpacked
                     (CoreML__Specification__TileLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GetShapeLayerParams methods */
void   core_ml__specification__get_shape_layer_params__init
                     (CoreML__Specification__GetShapeLayerParams         *message);
size_t core_ml__specification__get_shape_layer_params__get_packed_size
                     (const CoreML__Specification__GetShapeLayerParams   *message);
size_t core_ml__specification__get_shape_layer_params__pack
                     (const CoreML__Specification__GetShapeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__get_shape_layer_params__pack_to_buffer
                     (const CoreML__Specification__GetShapeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GetShapeLayerParams *
       core_ml__specification__get_shape_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__get_shape_layer_params__free_unpacked
                     (CoreML__Specification__GetShapeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ErfLayerParams methods */
void   core_ml__specification__erf_layer_params__init
                     (CoreML__Specification__ErfLayerParams         *message);
size_t core_ml__specification__erf_layer_params__get_packed_size
                     (const CoreML__Specification__ErfLayerParams   *message);
size_t core_ml__specification__erf_layer_params__pack
                     (const CoreML__Specification__ErfLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__erf_layer_params__pack_to_buffer
                     (const CoreML__Specification__ErfLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ErfLayerParams *
       core_ml__specification__erf_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__erf_layer_params__free_unpacked
                     (CoreML__Specification__ErfLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__GeluLayerParams methods */
void   core_ml__specification__gelu_layer_params__init
                     (CoreML__Specification__GeluLayerParams         *message);
size_t core_ml__specification__gelu_layer_params__get_packed_size
                     (const CoreML__Specification__GeluLayerParams   *message);
size_t core_ml__specification__gelu_layer_params__pack
                     (const CoreML__Specification__GeluLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__gelu_layer_params__pack_to_buffer
                     (const CoreML__Specification__GeluLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__GeluLayerParams *
       core_ml__specification__gelu_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__gelu_layer_params__free_unpacked
                     (CoreML__Specification__GeluLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RangeStaticLayerParams methods */
void   core_ml__specification__range_static_layer_params__init
                     (CoreML__Specification__RangeStaticLayerParams         *message);
size_t core_ml__specification__range_static_layer_params__get_packed_size
                     (const CoreML__Specification__RangeStaticLayerParams   *message);
size_t core_ml__specification__range_static_layer_params__pack
                     (const CoreML__Specification__RangeStaticLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__range_static_layer_params__pack_to_buffer
                     (const CoreML__Specification__RangeStaticLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RangeStaticLayerParams *
       core_ml__specification__range_static_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__range_static_layer_params__free_unpacked
                     (CoreML__Specification__RangeStaticLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__RangeDynamicLayerParams methods */
void   core_ml__specification__range_dynamic_layer_params__init
                     (CoreML__Specification__RangeDynamicLayerParams         *message);
size_t core_ml__specification__range_dynamic_layer_params__get_packed_size
                     (const CoreML__Specification__RangeDynamicLayerParams   *message);
size_t core_ml__specification__range_dynamic_layer_params__pack
                     (const CoreML__Specification__RangeDynamicLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__range_dynamic_layer_params__pack_to_buffer
                     (const CoreML__Specification__RangeDynamicLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__RangeDynamicLayerParams *
       core_ml__specification__range_dynamic_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__range_dynamic_layer_params__free_unpacked
                     (CoreML__Specification__RangeDynamicLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SlidingWindowsLayerParams methods */
void   core_ml__specification__sliding_windows_layer_params__init
                     (CoreML__Specification__SlidingWindowsLayerParams         *message);
size_t core_ml__specification__sliding_windows_layer_params__get_packed_size
                     (const CoreML__Specification__SlidingWindowsLayerParams   *message);
size_t core_ml__specification__sliding_windows_layer_params__pack
                     (const CoreML__Specification__SlidingWindowsLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__sliding_windows_layer_params__pack_to_buffer
                     (const CoreML__Specification__SlidingWindowsLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SlidingWindowsLayerParams *
       core_ml__specification__sliding_windows_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sliding_windows_layer_params__free_unpacked
                     (CoreML__Specification__SlidingWindowsLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LayerNormalizationLayerParams methods */
void   core_ml__specification__layer_normalization_layer_params__init
                     (CoreML__Specification__LayerNormalizationLayerParams         *message);
size_t core_ml__specification__layer_normalization_layer_params__get_packed_size
                     (const CoreML__Specification__LayerNormalizationLayerParams   *message);
size_t core_ml__specification__layer_normalization_layer_params__pack
                     (const CoreML__Specification__LayerNormalizationLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__layer_normalization_layer_params__pack_to_buffer
                     (const CoreML__Specification__LayerNormalizationLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LayerNormalizationLayerParams *
       core_ml__specification__layer_normalization_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__layer_normalization_layer_params__free_unpacked
                     (CoreML__Specification__LayerNormalizationLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NonMaximumSuppressionLayerParams methods */
void   core_ml__specification__non_maximum_suppression_layer_params__init
                     (CoreML__Specification__NonMaximumSuppressionLayerParams         *message);
size_t core_ml__specification__non_maximum_suppression_layer_params__get_packed_size
                     (const CoreML__Specification__NonMaximumSuppressionLayerParams   *message);
size_t core_ml__specification__non_maximum_suppression_layer_params__pack
                     (const CoreML__Specification__NonMaximumSuppressionLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__non_maximum_suppression_layer_params__pack_to_buffer
                     (const CoreML__Specification__NonMaximumSuppressionLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NonMaximumSuppressionLayerParams *
       core_ml__specification__non_maximum_suppression_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__non_maximum_suppression_layer_params__free_unpacked
                     (CoreML__Specification__NonMaximumSuppressionLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ClampedReLULayerParams methods */
void   core_ml__specification__clamped_re_lulayer_params__init
                     (CoreML__Specification__ClampedReLULayerParams         *message);
size_t core_ml__specification__clamped_re_lulayer_params__get_packed_size
                     (const CoreML__Specification__ClampedReLULayerParams   *message);
size_t core_ml__specification__clamped_re_lulayer_params__pack
                     (const CoreML__Specification__ClampedReLULayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__clamped_re_lulayer_params__pack_to_buffer
                     (const CoreML__Specification__ClampedReLULayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ClampedReLULayerParams *
       core_ml__specification__clamped_re_lulayer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__clamped_re_lulayer_params__free_unpacked
                     (CoreML__Specification__ClampedReLULayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__ArgSortLayerParams methods */
void   core_ml__specification__arg_sort_layer_params__init
                     (CoreML__Specification__ArgSortLayerParams         *message);
size_t core_ml__specification__arg_sort_layer_params__get_packed_size
                     (const CoreML__Specification__ArgSortLayerParams   *message);
size_t core_ml__specification__arg_sort_layer_params__pack
                     (const CoreML__Specification__ArgSortLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__arg_sort_layer_params__pack_to_buffer
                     (const CoreML__Specification__ArgSortLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__ArgSortLayerParams *
       core_ml__specification__arg_sort_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__arg_sort_layer_params__free_unpacked
                     (CoreML__Specification__ArgSortLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SliceBySizeLayerParams methods */
void   core_ml__specification__slice_by_size_layer_params__init
                     (CoreML__Specification__SliceBySizeLayerParams         *message);
size_t core_ml__specification__slice_by_size_layer_params__get_packed_size
                     (const CoreML__Specification__SliceBySizeLayerParams   *message);
size_t core_ml__specification__slice_by_size_layer_params__pack
                     (const CoreML__Specification__SliceBySizeLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__slice_by_size_layer_params__pack_to_buffer
                     (const CoreML__Specification__SliceBySizeLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SliceBySizeLayerParams *
       core_ml__specification__slice_by_size_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__slice_by_size_layer_params__free_unpacked
                     (CoreML__Specification__SliceBySizeLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkClassifier methods */
void   core_ml__specification__neural_network_classifier__init
                     (CoreML__Specification__NeuralNetworkClassifier         *message);
size_t core_ml__specification__neural_network_classifier__get_packed_size
                     (const CoreML__Specification__NeuralNetworkClassifier   *message);
size_t core_ml__specification__neural_network_classifier__pack
                     (const CoreML__Specification__NeuralNetworkClassifier   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_classifier__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkClassifier   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkClassifier *
       core_ml__specification__neural_network_classifier__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_classifier__free_unpacked
                     (CoreML__Specification__NeuralNetworkClassifier *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__OneHotLayerParams methods */
void   core_ml__specification__one_hot_layer_params__init
                     (CoreML__Specification__OneHotLayerParams         *message);
size_t core_ml__specification__one_hot_layer_params__get_packed_size
                     (const CoreML__Specification__OneHotLayerParams   *message);
size_t core_ml__specification__one_hot_layer_params__pack
                     (const CoreML__Specification__OneHotLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__one_hot_layer_params__pack_to_buffer
                     (const CoreML__Specification__OneHotLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__OneHotLayerParams *
       core_ml__specification__one_hot_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__one_hot_layer_params__free_unpacked
                     (CoreML__Specification__OneHotLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CumSumLayerParams methods */
void   core_ml__specification__cum_sum_layer_params__init
                     (CoreML__Specification__CumSumLayerParams         *message);
size_t core_ml__specification__cum_sum_layer_params__get_packed_size
                     (const CoreML__Specification__CumSumLayerParams   *message);
size_t core_ml__specification__cum_sum_layer_params__pack
                     (const CoreML__Specification__CumSumLayerParams   *message,
                      uint8_t             *out);
size_t core_ml__specification__cum_sum_layer_params__pack_to_buffer
                     (const CoreML__Specification__CumSumLayerParams   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CumSumLayerParams *
       core_ml__specification__cum_sum_layer_params__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__cum_sum_layer_params__free_unpacked
                     (CoreML__Specification__CumSumLayerParams *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NeuralNetworkRegressor methods */
void   core_ml__specification__neural_network_regressor__init
                     (CoreML__Specification__NeuralNetworkRegressor         *message);
size_t core_ml__specification__neural_network_regressor__get_packed_size
                     (const CoreML__Specification__NeuralNetworkRegressor   *message);
size_t core_ml__specification__neural_network_regressor__pack
                     (const CoreML__Specification__NeuralNetworkRegressor   *message,
                      uint8_t             *out);
size_t core_ml__specification__neural_network_regressor__pack_to_buffer
                     (const CoreML__Specification__NeuralNetworkRegressor   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NeuralNetworkRegressor *
       core_ml__specification__neural_network_regressor__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__neural_network_regressor__free_unpacked
                     (CoreML__Specification__NeuralNetworkRegressor *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__NetworkUpdateParameters methods */
void   core_ml__specification__network_update_parameters__init
                     (CoreML__Specification__NetworkUpdateParameters         *message);
size_t core_ml__specification__network_update_parameters__get_packed_size
                     (const CoreML__Specification__NetworkUpdateParameters   *message);
size_t core_ml__specification__network_update_parameters__pack
                     (const CoreML__Specification__NetworkUpdateParameters   *message,
                      uint8_t             *out);
size_t core_ml__specification__network_update_parameters__pack_to_buffer
                     (const CoreML__Specification__NetworkUpdateParameters   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__NetworkUpdateParameters *
       core_ml__specification__network_update_parameters__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__network_update_parameters__free_unpacked
                     (CoreML__Specification__NetworkUpdateParameters *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__LossLayer methods */
void   core_ml__specification__loss_layer__init
                     (CoreML__Specification__LossLayer         *message);
size_t core_ml__specification__loss_layer__get_packed_size
                     (const CoreML__Specification__LossLayer   *message);
size_t core_ml__specification__loss_layer__pack
                     (const CoreML__Specification__LossLayer   *message,
                      uint8_t             *out);
size_t core_ml__specification__loss_layer__pack_to_buffer
                     (const CoreML__Specification__LossLayer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__LossLayer *
       core_ml__specification__loss_layer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__loss_layer__free_unpacked
                     (CoreML__Specification__LossLayer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__CategoricalCrossEntropyLossLayer methods */
void   core_ml__specification__categorical_cross_entropy_loss_layer__init
                     (CoreML__Specification__CategoricalCrossEntropyLossLayer         *message);
size_t core_ml__specification__categorical_cross_entropy_loss_layer__get_packed_size
                     (const CoreML__Specification__CategoricalCrossEntropyLossLayer   *message);
size_t core_ml__specification__categorical_cross_entropy_loss_layer__pack
                     (const CoreML__Specification__CategoricalCrossEntropyLossLayer   *message,
                      uint8_t             *out);
size_t core_ml__specification__categorical_cross_entropy_loss_layer__pack_to_buffer
                     (const CoreML__Specification__CategoricalCrossEntropyLossLayer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__CategoricalCrossEntropyLossLayer *
       core_ml__specification__categorical_cross_entropy_loss_layer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__categorical_cross_entropy_loss_layer__free_unpacked
                     (CoreML__Specification__CategoricalCrossEntropyLossLayer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__MeanSquaredErrorLossLayer methods */
void   core_ml__specification__mean_squared_error_loss_layer__init
                     (CoreML__Specification__MeanSquaredErrorLossLayer         *message);
size_t core_ml__specification__mean_squared_error_loss_layer__get_packed_size
                     (const CoreML__Specification__MeanSquaredErrorLossLayer   *message);
size_t core_ml__specification__mean_squared_error_loss_layer__pack
                     (const CoreML__Specification__MeanSquaredErrorLossLayer   *message,
                      uint8_t             *out);
size_t core_ml__specification__mean_squared_error_loss_layer__pack_to_buffer
                     (const CoreML__Specification__MeanSquaredErrorLossLayer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__MeanSquaredErrorLossLayer *
       core_ml__specification__mean_squared_error_loss_layer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__mean_squared_error_loss_layer__free_unpacked
                     (CoreML__Specification__MeanSquaredErrorLossLayer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__Optimizer methods */
void   core_ml__specification__optimizer__init
                     (CoreML__Specification__Optimizer         *message);
size_t core_ml__specification__optimizer__get_packed_size
                     (const CoreML__Specification__Optimizer   *message);
size_t core_ml__specification__optimizer__pack
                     (const CoreML__Specification__Optimizer   *message,
                      uint8_t             *out);
size_t core_ml__specification__optimizer__pack_to_buffer
                     (const CoreML__Specification__Optimizer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__Optimizer *
       core_ml__specification__optimizer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__optimizer__free_unpacked
                     (CoreML__Specification__Optimizer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__SGDOptimizer methods */
void   core_ml__specification__sgdoptimizer__init
                     (CoreML__Specification__SGDOptimizer         *message);
size_t core_ml__specification__sgdoptimizer__get_packed_size
                     (const CoreML__Specification__SGDOptimizer   *message);
size_t core_ml__specification__sgdoptimizer__pack
                     (const CoreML__Specification__SGDOptimizer   *message,
                      uint8_t             *out);
size_t core_ml__specification__sgdoptimizer__pack_to_buffer
                     (const CoreML__Specification__SGDOptimizer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__SGDOptimizer *
       core_ml__specification__sgdoptimizer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__sgdoptimizer__free_unpacked
                     (CoreML__Specification__SGDOptimizer *message,
                      ProtobufCAllocator *allocator);
/* CoreML__Specification__AdamOptimizer methods */
void   core_ml__specification__adam_optimizer__init
                     (CoreML__Specification__AdamOptimizer         *message);
size_t core_ml__specification__adam_optimizer__get_packed_size
                     (const CoreML__Specification__AdamOptimizer   *message);
size_t core_ml__specification__adam_optimizer__pack
                     (const CoreML__Specification__AdamOptimizer   *message,
                      uint8_t             *out);
size_t core_ml__specification__adam_optimizer__pack_to_buffer
                     (const CoreML__Specification__AdamOptimizer   *message,
                      ProtobufCBuffer     *buffer);
CoreML__Specification__AdamOptimizer *
       core_ml__specification__adam_optimizer__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data);
void   core_ml__specification__adam_optimizer__free_unpacked
                     (CoreML__Specification__AdamOptimizer *message,
                      ProtobufCAllocator *allocator);
/* --- per-message closures --- */

typedef void (*CoreML__Specification__NeuralNetwork_Closure)
                 (const CoreML__Specification__NeuralNetwork *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkImageScaler_Closure)
                 (const CoreML__Specification__NeuralNetworkImageScaler *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkMeanImage_Closure)
                 (const CoreML__Specification__NeuralNetworkMeanImage *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkPreprocessing_Closure)
                 (const CoreML__Specification__NeuralNetworkPreprocessing *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationReLU_Closure)
                 (const CoreML__Specification__ActivationReLU *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationLeakyReLU_Closure)
                 (const CoreML__Specification__ActivationLeakyReLU *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationTanh_Closure)
                 (const CoreML__Specification__ActivationTanh *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationScaledTanh_Closure)
                 (const CoreML__Specification__ActivationScaledTanh *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationSigmoid_Closure)
                 (const CoreML__Specification__ActivationSigmoid *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationLinear_Closure)
                 (const CoreML__Specification__ActivationLinear *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationSigmoidHard_Closure)
                 (const CoreML__Specification__ActivationSigmoidHard *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationPReLU_Closure)
                 (const CoreML__Specification__ActivationPReLU *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationELU_Closure)
                 (const CoreML__Specification__ActivationELU *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationThresholdedReLU_Closure)
                 (const CoreML__Specification__ActivationThresholdedReLU *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationSoftsign_Closure)
                 (const CoreML__Specification__ActivationSoftsign *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationSoftplus_Closure)
                 (const CoreML__Specification__ActivationSoftplus *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationParametricSoftplus_Closure)
                 (const CoreML__Specification__ActivationParametricSoftplus *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ActivationParams_Closure)
                 (const CoreML__Specification__ActivationParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__Tensor_Closure)
                 (const CoreML__Specification__Tensor *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkLayer_Closure)
                 (const CoreML__Specification__NeuralNetworkLayer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BranchLayerParams_Closure)
                 (const CoreML__Specification__BranchLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LoopLayerParams_Closure)
                 (const CoreML__Specification__LoopLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LoopBreakLayerParams_Closure)
                 (const CoreML__Specification__LoopBreakLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LoopContinueLayerParams_Closure)
                 (const CoreML__Specification__LoopContinueLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CopyLayerParams_Closure)
                 (const CoreML__Specification__CopyLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GreaterThanLayerParams_Closure)
                 (const CoreML__Specification__GreaterThanLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GreaterEqualLayerParams_Closure)
                 (const CoreML__Specification__GreaterEqualLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LessThanLayerParams_Closure)
                 (const CoreML__Specification__LessThanLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LessEqualLayerParams_Closure)
                 (const CoreML__Specification__LessEqualLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__EqualLayerParams_Closure)
                 (const CoreML__Specification__EqualLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NotEqualLayerParams_Closure)
                 (const CoreML__Specification__NotEqualLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LogicalAndLayerParams_Closure)
                 (const CoreML__Specification__LogicalAndLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LogicalOrLayerParams_Closure)
                 (const CoreML__Specification__LogicalOrLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LogicalXorLayerParams_Closure)
                 (const CoreML__Specification__LogicalXorLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LogicalNotLayerParams_Closure)
                 (const CoreML__Specification__LogicalNotLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BorderAmounts__EdgeSizes_Closure)
                 (const CoreML__Specification__BorderAmounts__EdgeSizes *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BorderAmounts_Closure)
                 (const CoreML__Specification__BorderAmounts *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ValidPadding_Closure)
                 (const CoreML__Specification__ValidPadding *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SamePadding_Closure)
                 (const CoreML__Specification__SamePadding *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SamplingMode_Closure)
                 (const CoreML__Specification__SamplingMode *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BoxCoordinatesMode_Closure)
                 (const CoreML__Specification__BoxCoordinatesMode *message,
                  void *closure_data);
typedef void (*CoreML__Specification__WeightParams_Closure)
                 (const CoreML__Specification__WeightParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__QuantizationParams_Closure)
                 (const CoreML__Specification__QuantizationParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LinearQuantizationParams_Closure)
                 (const CoreML__Specification__LinearQuantizationParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LookUpTableQuantizationParams_Closure)
                 (const CoreML__Specification__LookUpTableQuantizationParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ConvolutionLayerParams_Closure)
                 (const CoreML__Specification__ConvolutionLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__Convolution3DLayerParams_Closure)
                 (const CoreML__Specification__Convolution3DLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__InnerProductLayerParams_Closure)
                 (const CoreML__Specification__InnerProductLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__EmbeddingLayerParams_Closure)
                 (const CoreML__Specification__EmbeddingLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__EmbeddingNDLayerParams_Closure)
                 (const CoreML__Specification__EmbeddingNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BatchnormLayerParams_Closure)
                 (const CoreML__Specification__BatchnormLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PoolingLayerParams__ValidCompletePadding_Closure)
                 (const CoreML__Specification__PoolingLayerParams__ValidCompletePadding *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PoolingLayerParams_Closure)
                 (const CoreML__Specification__PoolingLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__Pooling3DLayerParams_Closure)
                 (const CoreML__Specification__Pooling3DLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GlobalPooling3DLayerParams_Closure)
                 (const CoreML__Specification__GlobalPooling3DLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PaddingLayerParams__PaddingConstant_Closure)
                 (const CoreML__Specification__PaddingLayerParams__PaddingConstant *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PaddingLayerParams__PaddingReflection_Closure)
                 (const CoreML__Specification__PaddingLayerParams__PaddingReflection *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PaddingLayerParams__PaddingReplication_Closure)
                 (const CoreML__Specification__PaddingLayerParams__PaddingReplication *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PaddingLayerParams_Closure)
                 (const CoreML__Specification__PaddingLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ConcatLayerParams_Closure)
                 (const CoreML__Specification__ConcatLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LRNLayerParams_Closure)
                 (const CoreML__Specification__LRNLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SoftmaxLayerParams_Closure)
                 (const CoreML__Specification__SoftmaxLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SplitLayerParams_Closure)
                 (const CoreML__Specification__SplitLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AddLayerParams_Closure)
                 (const CoreML__Specification__AddLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MultiplyLayerParams_Closure)
                 (const CoreML__Specification__MultiplyLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__UnaryFunctionLayerParams_Closure)
                 (const CoreML__Specification__UnaryFunctionLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__UpsampleLayerParams_Closure)
                 (const CoreML__Specification__UpsampleLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ResizeBilinearLayerParams_Closure)
                 (const CoreML__Specification__ResizeBilinearLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CropResizeLayerParams_Closure)
                 (const CoreML__Specification__CropResizeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BiasLayerParams_Closure)
                 (const CoreML__Specification__BiasLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ScaleLayerParams_Closure)
                 (const CoreML__Specification__ScaleLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LoadConstantLayerParams_Closure)
                 (const CoreML__Specification__LoadConstantLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__L2NormalizeLayerParams_Closure)
                 (const CoreML__Specification__L2NormalizeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FlattenLayerParams_Closure)
                 (const CoreML__Specification__FlattenLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReshapeLayerParams_Closure)
                 (const CoreML__Specification__ReshapeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PermuteLayerParams_Closure)
                 (const CoreML__Specification__PermuteLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReorganizeDataLayerParams_Closure)
                 (const CoreML__Specification__ReorganizeDataLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SliceLayerParams_Closure)
                 (const CoreML__Specification__SliceLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceLayerParams_Closure)
                 (const CoreML__Specification__ReduceLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CropLayerParams_Closure)
                 (const CoreML__Specification__CropLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AverageLayerParams_Closure)
                 (const CoreML__Specification__AverageLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MaxLayerParams_Closure)
                 (const CoreML__Specification__MaxLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MinLayerParams_Closure)
                 (const CoreML__Specification__MinLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__DotProductLayerParams_Closure)
                 (const CoreML__Specification__DotProductLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MeanVarianceNormalizeLayerParams_Closure)
                 (const CoreML__Specification__MeanVarianceNormalizeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SequenceRepeatLayerParams_Closure)
                 (const CoreML__Specification__SequenceRepeatLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SimpleRecurrentLayerParams_Closure)
                 (const CoreML__Specification__SimpleRecurrentLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GRULayerParams_Closure)
                 (const CoreML__Specification__GRULayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LSTMParams_Closure)
                 (const CoreML__Specification__LSTMParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LSTMWeightParams_Closure)
                 (const CoreML__Specification__LSTMWeightParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__UniDirectionalLSTMLayerParams_Closure)
                 (const CoreML__Specification__UniDirectionalLSTMLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BiDirectionalLSTMLayerParams_Closure)
                 (const CoreML__Specification__BiDirectionalLSTMLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CustomLayerParams__CustomLayerParamValue_Closure)
                 (const CoreML__Specification__CustomLayerParams__CustomLayerParamValue *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CustomLayerParams__ParametersEntry_Closure)
                 (const CoreML__Specification__CustomLayerParams__ParametersEntry *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CustomLayerParams_Closure)
                 (const CoreML__Specification__CustomLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__TransposeLayerParams_Closure)
                 (const CoreML__Specification__TransposeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BatchedMatMulLayerParams_Closure)
                 (const CoreML__Specification__BatchedMatMulLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ConcatNDLayerParams_Closure)
                 (const CoreML__Specification__ConcatNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SoftmaxNDLayerParams_Closure)
                 (const CoreML__Specification__SoftmaxNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReverseLayerParams_Closure)
                 (const CoreML__Specification__ReverseLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReverseSeqLayerParams_Closure)
                 (const CoreML__Specification__ReverseSeqLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LoadConstantNDLayerParams_Closure)
                 (const CoreML__Specification__LoadConstantNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FillLikeLayerParams_Closure)
                 (const CoreML__Specification__FillLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FillStaticLayerParams_Closure)
                 (const CoreML__Specification__FillStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FillDynamicLayerParams_Closure)
                 (const CoreML__Specification__FillDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__WhereBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__WhereBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SinLayerParams_Closure)
                 (const CoreML__Specification__SinLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CosLayerParams_Closure)
                 (const CoreML__Specification__CosLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__TanLayerParams_Closure)
                 (const CoreML__Specification__TanLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AsinLayerParams_Closure)
                 (const CoreML__Specification__AsinLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AcosLayerParams_Closure)
                 (const CoreML__Specification__AcosLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AtanLayerParams_Closure)
                 (const CoreML__Specification__AtanLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SinhLayerParams_Closure)
                 (const CoreML__Specification__SinhLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CoshLayerParams_Closure)
                 (const CoreML__Specification__CoshLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__TanhLayerParams_Closure)
                 (const CoreML__Specification__TanhLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AsinhLayerParams_Closure)
                 (const CoreML__Specification__AsinhLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AcoshLayerParams_Closure)
                 (const CoreML__Specification__AcoshLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AtanhLayerParams_Closure)
                 (const CoreML__Specification__AtanhLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__PowBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__PowBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__Exp2LayerParams_Closure)
                 (const CoreML__Specification__Exp2LayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__WhereNonZeroLayerParams_Closure)
                 (const CoreML__Specification__WhereNonZeroLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MatrixBandPartLayerParams_Closure)
                 (const CoreML__Specification__MatrixBandPartLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__UpperTriangularLayerParams_Closure)
                 (const CoreML__Specification__UpperTriangularLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LowerTriangularLayerParams_Closure)
                 (const CoreML__Specification__LowerTriangularLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BroadcastToLikeLayerParams_Closure)
                 (const CoreML__Specification__BroadcastToLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BroadcastToStaticLayerParams_Closure)
                 (const CoreML__Specification__BroadcastToStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__BroadcastToDynamicLayerParams_Closure)
                 (const CoreML__Specification__BroadcastToDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AddBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__AddBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MaxBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__MaxBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MinBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__MinBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ModBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__ModBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FloorDivBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__FloorDivBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SubtractBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__SubtractBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MultiplyBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__MultiplyBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__DivideBroadcastableLayerParams_Closure)
                 (const CoreML__Specification__DivideBroadcastableLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GatherLayerParams_Closure)
                 (const CoreML__Specification__GatherLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ScatterLayerParams_Closure)
                 (const CoreML__Specification__ScatterLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GatherNDLayerParams_Closure)
                 (const CoreML__Specification__GatherNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ScatterNDLayerParams_Closure)
                 (const CoreML__Specification__ScatterNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GatherAlongAxisLayerParams_Closure)
                 (const CoreML__Specification__GatherAlongAxisLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ScatterAlongAxisLayerParams_Closure)
                 (const CoreML__Specification__ScatterAlongAxisLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__StackLayerParams_Closure)
                 (const CoreML__Specification__StackLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RankPreservingReshapeLayerParams_Closure)
                 (const CoreML__Specification__RankPreservingReshapeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ConstantPaddingLayerParams_Closure)
                 (const CoreML__Specification__ConstantPaddingLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomNormalLikeLayerParams_Closure)
                 (const CoreML__Specification__RandomNormalLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomNormalStaticLayerParams_Closure)
                 (const CoreML__Specification__RandomNormalStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomNormalDynamicLayerParams_Closure)
                 (const CoreML__Specification__RandomNormalDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomUniformLikeLayerParams_Closure)
                 (const CoreML__Specification__RandomUniformLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomUniformStaticLayerParams_Closure)
                 (const CoreML__Specification__RandomUniformStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomUniformDynamicLayerParams_Closure)
                 (const CoreML__Specification__RandomUniformDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomBernoulliLikeLayerParams_Closure)
                 (const CoreML__Specification__RandomBernoulliLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomBernoulliStaticLayerParams_Closure)
                 (const CoreML__Specification__RandomBernoulliStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RandomBernoulliDynamicLayerParams_Closure)
                 (const CoreML__Specification__RandomBernoulliDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CategoricalDistributionLayerParams_Closure)
                 (const CoreML__Specification__CategoricalDistributionLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceL1LayerParams_Closure)
                 (const CoreML__Specification__ReduceL1LayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceL2LayerParams_Closure)
                 (const CoreML__Specification__ReduceL2LayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceMaxLayerParams_Closure)
                 (const CoreML__Specification__ReduceMaxLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceMinLayerParams_Closure)
                 (const CoreML__Specification__ReduceMinLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceSumLayerParams_Closure)
                 (const CoreML__Specification__ReduceSumLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceProdLayerParams_Closure)
                 (const CoreML__Specification__ReduceProdLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceMeanLayerParams_Closure)
                 (const CoreML__Specification__ReduceMeanLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceLogSumLayerParams_Closure)
                 (const CoreML__Specification__ReduceLogSumLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceSumSquareLayerParams_Closure)
                 (const CoreML__Specification__ReduceSumSquareLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReduceLogSumExpLayerParams_Closure)
                 (const CoreML__Specification__ReduceLogSumExpLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ExpandDimsLayerParams_Closure)
                 (const CoreML__Specification__ExpandDimsLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FlattenTo2DLayerParams_Closure)
                 (const CoreML__Specification__FlattenTo2DLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReshapeStaticLayerParams_Closure)
                 (const CoreML__Specification__ReshapeStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReshapeLikeLayerParams_Closure)
                 (const CoreML__Specification__ReshapeLikeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ReshapeDynamicLayerParams_Closure)
                 (const CoreML__Specification__ReshapeDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SqueezeLayerParams_Closure)
                 (const CoreML__Specification__SqueezeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__TopKLayerParams_Closure)
                 (const CoreML__Specification__TopKLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ArgMaxLayerParams_Closure)
                 (const CoreML__Specification__ArgMaxLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ArgMinLayerParams_Closure)
                 (const CoreML__Specification__ArgMinLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SplitNDLayerParams_Closure)
                 (const CoreML__Specification__SplitNDLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CeilLayerParams_Closure)
                 (const CoreML__Specification__CeilLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RoundLayerParams_Closure)
                 (const CoreML__Specification__RoundLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__FloorLayerParams_Closure)
                 (const CoreML__Specification__FloorLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SignLayerParams_Closure)
                 (const CoreML__Specification__SignLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ClipLayerParams_Closure)
                 (const CoreML__Specification__ClipLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SliceStaticLayerParams_Closure)
                 (const CoreML__Specification__SliceStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SliceDynamicLayerParams_Closure)
                 (const CoreML__Specification__SliceDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__TileLayerParams_Closure)
                 (const CoreML__Specification__TileLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GetShapeLayerParams_Closure)
                 (const CoreML__Specification__GetShapeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ErfLayerParams_Closure)
                 (const CoreML__Specification__ErfLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__GeluLayerParams_Closure)
                 (const CoreML__Specification__GeluLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RangeStaticLayerParams_Closure)
                 (const CoreML__Specification__RangeStaticLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__RangeDynamicLayerParams_Closure)
                 (const CoreML__Specification__RangeDynamicLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SlidingWindowsLayerParams_Closure)
                 (const CoreML__Specification__SlidingWindowsLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LayerNormalizationLayerParams_Closure)
                 (const CoreML__Specification__LayerNormalizationLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NonMaximumSuppressionLayerParams_Closure)
                 (const CoreML__Specification__NonMaximumSuppressionLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ClampedReLULayerParams_Closure)
                 (const CoreML__Specification__ClampedReLULayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__ArgSortLayerParams_Closure)
                 (const CoreML__Specification__ArgSortLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SliceBySizeLayerParams_Closure)
                 (const CoreML__Specification__SliceBySizeLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkClassifier_Closure)
                 (const CoreML__Specification__NeuralNetworkClassifier *message,
                  void *closure_data);
typedef void (*CoreML__Specification__OneHotLayerParams_Closure)
                 (const CoreML__Specification__OneHotLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CumSumLayerParams_Closure)
                 (const CoreML__Specification__CumSumLayerParams *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NeuralNetworkRegressor_Closure)
                 (const CoreML__Specification__NeuralNetworkRegressor *message,
                  void *closure_data);
typedef void (*CoreML__Specification__NetworkUpdateParameters_Closure)
                 (const CoreML__Specification__NetworkUpdateParameters *message,
                  void *closure_data);
typedef void (*CoreML__Specification__LossLayer_Closure)
                 (const CoreML__Specification__LossLayer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__CategoricalCrossEntropyLossLayer_Closure)
                 (const CoreML__Specification__CategoricalCrossEntropyLossLayer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__MeanSquaredErrorLossLayer_Closure)
                 (const CoreML__Specification__MeanSquaredErrorLossLayer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__Optimizer_Closure)
                 (const CoreML__Specification__Optimizer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__SGDOptimizer_Closure)
                 (const CoreML__Specification__SGDOptimizer *message,
                  void *closure_data);
typedef void (*CoreML__Specification__AdamOptimizer_Closure)
                 (const CoreML__Specification__AdamOptimizer *message,
                  void *closure_data);

/* --- services --- */


/* --- descriptors --- */

extern const ProtobufCEnumDescriptor    core_ml__specification__neural_network_multi_array_shape_mapping__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__neural_network_image_shape_mapping__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__scatter_mode__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_image_scaler__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_mean_image__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_preprocessing__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_re_lu__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_leaky_re_lu__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_tanh__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_scaled_tanh__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_sigmoid__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_linear__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_sigmoid_hard__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_pre_lu__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_elu__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_thresholded_re_lu__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_softsign__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_softplus__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_parametric_softplus__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__activation_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__tensor__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_layer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__branch_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__loop_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__loop_break_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__loop_continue_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__copy_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__greater_than_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__greater_equal_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__less_than_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__less_equal_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__equal_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__not_equal_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__logical_and_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__logical_or_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__logical_xor_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__logical_not_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__border_amounts__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__border_amounts__edge_sizes__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__valid_padding__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__same_padding__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__same_padding__same_padding_mode__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sampling_mode__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__sampling_mode__method__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__box_coordinates_mode__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__box_coordinates_mode__coordinates__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__weight_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__quantization_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__linear_quantization_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__look_up_table_quantization_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__convolution_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__convolution3_dlayer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__convolution3_dlayer_params__padding_type__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__inner_product_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__embedding_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__embedding_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__batchnorm_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__pooling_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__pooling_layer_params__valid_complete_padding__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__pooling_layer_params__pooling_type__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__pooling3_dlayer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__pooling3_dlayer_params__pooling_type3_d__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__pooling3_dlayer_params__pooling3_dpadding_type__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__global_pooling3_dlayer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__global_pooling3_dlayer_params__global_pooling_type3_d__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__padding_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__padding_layer_params__padding_constant__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__padding_layer_params__padding_reflection__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__padding_layer_params__padding_replication__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__concat_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__lrnlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__softmax_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__split_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__add_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__multiply_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__unary_function_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__unary_function_layer_params__operation__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__upsample_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__upsample_layer_params__interpolation_mode__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__upsample_layer_params__linear_upsample_mode__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__resize_bilinear_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__crop_resize_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__bias_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__scale_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__load_constant_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__l2_normalize_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__flatten_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__flatten_layer_params__flatten_order__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reshape_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__reshape_layer_params__reshape_order__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__permute_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reorganize_data_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__reorganize_data_layer_params__reorganization_type__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__slice_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__slice_layer_params__slice_axis__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__reduce_layer_params__reduce_operation__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__reduce_layer_params__reduce_axis__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__crop_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__average_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__max_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__min_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__dot_product_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__mean_variance_normalize_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sequence_repeat_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__simple_recurrent_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__grulayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__lstmparams__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__lstmweight_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__uni_directional_lstmlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__bi_directional_lstmlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__custom_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__custom_layer_params__custom_layer_param_value__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__custom_layer_params__parameters_entry__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__transpose_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__batched_mat_mul_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__concat_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__softmax_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reverse_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reverse_seq_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__load_constant_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__fill_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__fill_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__fill_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__where_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sin_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__cos_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__tan_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__asin_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__acos_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__atan_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sinh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__cosh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__tanh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__asinh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__acosh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__atanh_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__pow_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__exp2_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__where_non_zero_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__matrix_band_part_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__upper_triangular_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__lower_triangular_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__broadcast_to_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__broadcast_to_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__broadcast_to_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__add_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__max_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__min_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__mod_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__floor_div_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__subtract_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__multiply_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__divide_broadcastable_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__gather_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__scatter_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__gather_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__scatter_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__gather_along_axis_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__scatter_along_axis_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__stack_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__rank_preserving_reshape_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__constant_padding_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_normal_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_normal_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_normal_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_uniform_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_uniform_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_uniform_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_bernoulli_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_bernoulli_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__random_bernoulli_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__categorical_distribution_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_l1_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_l2_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_max_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_min_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_sum_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_prod_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_mean_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_log_sum_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_sum_square_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reduce_log_sum_exp_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__expand_dims_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__flatten_to2_dlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reshape_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reshape_like_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__reshape_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__squeeze_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__top_klayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__arg_max_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__arg_min_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__split_ndlayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__ceil_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__round_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__floor_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sign_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__clip_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__slice_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__slice_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__tile_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__get_shape_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__erf_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__gelu_layer_params__descriptor;
extern const ProtobufCEnumDescriptor    core_ml__specification__gelu_layer_params__gelu_mode__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__range_static_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__range_dynamic_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sliding_windows_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__layer_normalization_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__non_maximum_suppression_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__clamped_re_lulayer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__arg_sort_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__slice_by_size_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_classifier__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__one_hot_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__cum_sum_layer_params__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__neural_network_regressor__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__network_update_parameters__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__loss_layer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__categorical_cross_entropy_loss_layer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__mean_squared_error_loss_layer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__optimizer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__sgdoptimizer__descriptor;
extern const ProtobufCMessageDescriptor core_ml__specification__adam_optimizer__descriptor;

PROTOBUF_C__END_DECLS


#endif  /* PROTOBUF_C_NeuralNetwork_2eproto__INCLUDED */

//
//  Executor.hpp
//  MNN
//
//  Created by MNN on 2019/07/25.
//  Copyright Â© 2018, Alibaba Group Holding Limited
//
#ifndef Executor_hpp
#define Executor_hpp
#include <MNN/ErrorCode.hpp>
#include <MNN/expr/Expr.hpp>
#include <MNN/Tensor.hpp>
#include <vector>
#include <mutex>
#include <set>
#include <MNN/MNNForwardType.h>
namespace MNN {
class Backend;
class Execution;
namespace Express {
class MNN_PUBLIC Executor {
public:
    class ComputeCache {
    public:
        void setShapeDirty();
        void setContentDirty();
        
        ErrorCode compute();
        ErrorCode resize();
        Tensor* output(EXPRP outputExpr, int index, bool host = true) const;
        void dup(EXPRP src, EXPRP dst);
        void recycle(Expr* expr);
        struct TensorContent {
            std::shared_ptr<Tensor> tensor;
            int refCount = 0;
            void reset();
        };
        struct Unit {
            std::vector<Tensor*> inputs;
            std::vector<bool> inputFromCache;
            std::vector<Tensor*> outputs;
            const Expr* origin;
            std::shared_ptr<Execution> exe;
        };
        static void create(const std::vector<EXPRP>& outputs, std::map<EXPRP, ComputeCache::Unit>& units, std::set<std::shared_ptr<Executor::ComputeCache>>&& inputCaches, std::vector<ComputeCache::TensorContent>&& tensors, std::shared_ptr<Backend> bn, std::shared_ptr<Backend> backendBn);

        ~ ComputeCache();
        void addLink(std::shared_ptr<ComputeCache> cache);
        bool valid() const {
            return !mOutputTensors.empty();
        }
    private:
        ComputeCache(){};
        std::set<std::shared_ptr<ComputeCache>> mInputs;
        // First is Host Tensor, Second is Device Tensor
        std::map<Expr*, std::vector<std::pair<Tensor*, Tensor*>>> mOutputTensors;
        std::vector<TensorContent> mTensors;
        std::vector<Unit> mUnits;
        std::vector<std::weak_ptr<ComputeCache>> mLinks;
        bool mContentDirty = true;
        bool mShapeDirty = true;
        std::shared_ptr<Backend> mBackend;
        std::shared_ptr<Backend> mBackupBackend;
    };
    struct Requirement {
        std::vector<bool> contentNeedContent;
        std::vector<bool> shapeNeedContent;
        std::vector<bool> supportError;
    };
    ~Executor();
    Requirement getRequirement(Expr* expr) const;
    ErrorCode computeInfo(Expr* expr);
    void makeCache(std::vector<EXPRP> expr);
    ErrorCode runCache(std::shared_ptr<ComputeCache> cache);
    void setGlobalExecutorConfig(MNNForwardType type, const BackendConfig& config, int numberThread);
    enum GCFlag {
        FULL,
        PART
    };
    void gc(GCFlag flag = FULL);
    static std::shared_ptr<Executor> getGlobalExecutor();
    void resetProfile();
    void dumpProfile();
    void addOpCostTime(int op, float costTime);
    class Profiler;
private:
    void _addToCache(const std::vector<std::shared_ptr<ComputeCache>>& caches);
    void _resetCache();
    void _visit(EXPRP expr, std::map<EXPRP, ComputeCache::Unit>& units, std::set<std::shared_ptr<Executor::ComputeCache>>& inputCaches, std::vector<ComputeCache::TensorContent>& tensors);

    Executor(std::shared_ptr<Backend> backend);
    std::shared_ptr<Backend> mBackend;
    std::shared_ptr<Backend> mBackupBackend;
    std::mutex mMutex;
    std::vector<std::shared_ptr<Tensor>> mStack;
    std::vector<Tensor*> mInputs;
    std::vector<Tensor*> mOutputs;
    std::shared_ptr<Profiler> mProfiler;
};
} // namespace Express
} // namespace MNN
#endif
